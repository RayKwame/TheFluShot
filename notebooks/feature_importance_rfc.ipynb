{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# adding to the path variables the one folder higher (locally, not changing system variables)\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import mlflow\n",
    "from modeling.config import TRACKING_URI, EXPERIMENT_NAME\n",
    "\n",
    "RSEED = 42\n",
    "# Modeling Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, cross_validate\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives of this notebook\n",
    "- Implement feature importance by using SHAP approach \n",
    "- Using the results of our random forest model \n",
    "- Data that are used: cleaned data of second iteration (including all missing values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/Flu_Shot_Data_cleaned_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26707 entries, 0 to 26706\n",
      "Data columns (total 38 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   Unnamed: 0                   26707 non-null  int64  \n",
      " 1   h1n1_vaccine                 26707 non-null  int64  \n",
      " 2   seasonal_vaccine             26707 non-null  int64  \n",
      " 3   h1n1_concern                 26615 non-null  float64\n",
      " 4   h1n1_knowledge               26591 non-null  float64\n",
      " 5   behavioral_antiviral_meds    26636 non-null  float64\n",
      " 6   behavioral_avoidance         26499 non-null  float64\n",
      " 7   behavioral_face_mask         26688 non-null  float64\n",
      " 8   behavioral_wash_hands        26665 non-null  float64\n",
      " 9   behavioral_large_gatherings  26620 non-null  float64\n",
      " 10  behavioral_outside_home      26625 non-null  float64\n",
      " 11  behavioral_touch_face        26579 non-null  float64\n",
      " 12  doctor_recc_h1n1             24547 non-null  float64\n",
      " 13  doctor_recc_seasonal         24547 non-null  float64\n",
      " 14  chronic_med_condition        25736 non-null  float64\n",
      " 15  child_under_6_months         25887 non-null  float64\n",
      " 16  health_worker                25903 non-null  float64\n",
      " 17  health_insurance             14433 non-null  float64\n",
      " 18  opinion_h1n1_vacc_effective  26316 non-null  float64\n",
      " 19  opinion_h1n1_risk            26319 non-null  float64\n",
      " 20  opinion_h1n1_sick_from_vacc  26312 non-null  float64\n",
      " 21  opinion_seas_vacc_effective  26245 non-null  float64\n",
      " 22  opinion_seas_risk            26193 non-null  float64\n",
      " 23  opinion_seas_sick_from_vacc  26170 non-null  float64\n",
      " 24  age_group                    26707 non-null  object \n",
      " 25  education                    25300 non-null  object \n",
      " 26  race                         26707 non-null  object \n",
      " 27  sex                          26707 non-null  object \n",
      " 28  income_poverty               22284 non-null  object \n",
      " 29  marital_status               25299 non-null  object \n",
      " 30  rent_or_own                  24665 non-null  object \n",
      " 31  employment_status            25244 non-null  object \n",
      " 32  hhs_geo_region               26707 non-null  object \n",
      " 33  census_msa                   26707 non-null  object \n",
      " 34  household_adults             26458 non-null  float64\n",
      " 35  household_children           26458 non-null  float64\n",
      " 36  employment_industry          13377 non-null  object \n",
      " 37  employment_occupation        13237 non-null  object \n",
      "dtypes: float64(23), int64(3), object(12)\n",
      "memory usage: 7.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column 'unnamed: 0' is another index and we will drop it \n",
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26707 entries, 0 to 26706\n",
      "Data columns (total 37 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   h1n1_vaccine                 26707 non-null  int64  \n",
      " 1   seasonal_vaccine             26707 non-null  int64  \n",
      " 2   h1n1_concern                 26615 non-null  float64\n",
      " 3   h1n1_knowledge               26591 non-null  float64\n",
      " 4   behavioral_antiviral_meds    26636 non-null  float64\n",
      " 5   behavioral_avoidance         26499 non-null  float64\n",
      " 6   behavioral_face_mask         26688 non-null  float64\n",
      " 7   behavioral_wash_hands        26665 non-null  float64\n",
      " 8   behavioral_large_gatherings  26620 non-null  float64\n",
      " 9   behavioral_outside_home      26625 non-null  float64\n",
      " 10  behavioral_touch_face        26579 non-null  float64\n",
      " 11  doctor_recc_h1n1             24547 non-null  float64\n",
      " 12  doctor_recc_seasonal         24547 non-null  float64\n",
      " 13  chronic_med_condition        25736 non-null  float64\n",
      " 14  child_under_6_months         25887 non-null  float64\n",
      " 15  health_worker                25903 non-null  float64\n",
      " 16  health_insurance             14433 non-null  float64\n",
      " 17  opinion_h1n1_vacc_effective  26316 non-null  float64\n",
      " 18  opinion_h1n1_risk            26319 non-null  float64\n",
      " 19  opinion_h1n1_sick_from_vacc  26312 non-null  float64\n",
      " 20  opinion_seas_vacc_effective  26245 non-null  float64\n",
      " 21  opinion_seas_risk            26193 non-null  float64\n",
      " 22  opinion_seas_sick_from_vacc  26170 non-null  float64\n",
      " 23  age_group                    26707 non-null  object \n",
      " 24  education                    25300 non-null  object \n",
      " 25  race                         26707 non-null  object \n",
      " 26  sex                          26707 non-null  object \n",
      " 27  income_poverty               22284 non-null  object \n",
      " 28  marital_status               25299 non-null  object \n",
      " 29  rent_or_own                  24665 non-null  object \n",
      " 30  employment_status            25244 non-null  object \n",
      " 31  hhs_geo_region               26707 non-null  object \n",
      " 32  census_msa                   26707 non-null  object \n",
      " 33  household_adults             26458 non-null  float64\n",
      " 34  household_children           26458 non-null  float64\n",
      " 35  employment_industry          13377 non-null  object \n",
      " 36  employment_occupation        13237 non-null  object \n",
      "dtypes: float64(23), int64(2), object(12)\n",
      "memory usage: 7.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting features to numerical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup = {\"age_group\": {\"18 - 34 Years\": 1, \"35 - 44 Years\": 2, \"45 - 54 Years\": 3, \"55 - 64 Years\": 4,\n",
    "                                  \"65+ Years\": 5},\n",
    "            \"education\": {\"< 12 Years\": 1, \"12 Years\": 2, \"Some College\": 3, \"College Graduate\": 4},\n",
    "            \"race\": {\"White\": 1, \"Black\": 2, \"Hispanic\": 3, \"Other or Multiple\": 4},\n",
    "            \"sex\" : {\"Female\": 1, \"Male\": 2},\n",
    "            \"rent_or_own\" : {\"Own\": 1, \"Rent\": 2},\n",
    "            \"hhs_geo_region\" : {\"lzgpxyit\": 1, \"fpwskwrf\": 2, \"qufhixun\": 3, \"bhuqouqj\": 4, \"oxchjgsf\": 5, \"kbazzjca\": 6, \"mlyzmhmf\": 7, \"atmpeygn\": 8, \"lrircsnp\": 9, \"dqpwygqj\": 10},\n",
    "            \"census_msa\" : {\"MSA, Not Principle  City\": 1, \"MSA, Principle City\": 2, \"Non-MSA\": 3},\n",
    "            \"income_poverty\" : {\"Below Poverty\": 1, \"<= $75,000, Above Poverty\": 2, \"> $75,000\": 3},\n",
    "            \"employment_industry\" : {\"fcxhlnwr\": 1, \"wxleyezf\": 2, \"ldnlellj\": 3, \"pxcmvdjn\": 4, \"atmlpfrs\": 5, \"arjwrbjb\": 6, \"xicduogh\": 7, \"mfikgejo\": 8, \"vjjrobsf\": 9,\n",
    "                                    \"rucpziij\": 10, \"xqicxuve\": 11, \"saaquncn\": 12, \"cfqqtusy\": 13, \"nduyfdeo\": 14, \"mcubkhph\": 15, \"wlfvacwt\": 16, \"dotnnunm\": 17, \"haxffmxo\": 18, \"msuufmds\": 19, \"phxvnwax\": 20,\n",
    "                                    \"qnlwzans\": 21},\n",
    "           \"employment_occupation\" : {\"xtkaffoo\": 1, \"mxkfnird\": 2, \"emcorrxb\": 3, \"cmhcxjea\": 4, \"xgwztkwe\": 5, \"hfxkjkmi\": 6, \"qxajmpny\": 7, \"xqwwgdyp\": 8, \"kldqjyjy\": 9,\n",
    "                                    \"uqqtjvyb\": 10, \"tfqavkke\": 11, \"ukymxvdu\": 12, \"vlluhbov\": 13, \"oijqvulv\": 14, \"ccgxvspp\": 15, \"bxpfxfdn\": 16, \"haliazsg\": 17, \"rcertsgn\": 18, \"xzmlyyjv\": 19, \"dlvbwzss\": 20,\n",
    "                                    \"hodpvpew\": 21, \"dcjcmpih\": 22, \"pvmttkik\": 23},\n",
    "           \"marital_status\" : {\"Married\": 1, \"Not Married\": 2},\n",
    "           \"employment_status\" : {\"Employed\": 1, \"Not in Labor Force\": 2, \"Unemployed\": 3}\n",
    "                                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = df.replace(cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num_cols = df_num.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling in null values with a dummy value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_const = SimpleImputer(strategy='constant', fill_value=-999)\n",
    "df_num = imp_const.fit_transform(df_num)\n",
    "df_num = pd.DataFrame(df_num, columns=df_num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the model\n",
    "- Preparing data \n",
    "- Encoding the categorical variables \n",
    "- Instatiating the Random Forest model \n",
    "- sklearn preprocessing cannot be uses because it does not fit with the SHAP implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H1N1 prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up target variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_h1n1 = df_num['h1n1_vaccine'].copy()\n",
    "y_h1n1 = y_h1n1.to_numpy()\n",
    "y_h1n1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_num.drop(columns=['h1n1_vaccine', 'seasonal_vaccine'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up categorical features for preprocessor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h1n1_concern',\n",
       " 'h1n1_knowledge',\n",
       " 'behavioral_antiviral_meds',\n",
       " 'behavioral_avoidance',\n",
       " 'behavioral_face_mask',\n",
       " 'behavioral_wash_hands',\n",
       " 'behavioral_large_gatherings',\n",
       " 'behavioral_outside_home',\n",
       " 'behavioral_touch_face',\n",
       " 'doctor_recc_h1n1',\n",
       " 'doctor_recc_seasonal',\n",
       " 'chronic_med_condition',\n",
       " 'child_under_6_months',\n",
       " 'health_worker',\n",
       " 'health_insurance',\n",
       " 'opinion_h1n1_vacc_effective',\n",
       " 'opinion_h1n1_risk',\n",
       " 'opinion_h1n1_sick_from_vacc',\n",
       " 'opinion_seas_vacc_effective',\n",
       " 'opinion_seas_risk',\n",
       " 'opinion_seas_sick_from_vacc',\n",
       " 'age_group',\n",
       " 'education',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'income_poverty',\n",
       " 'marital_status',\n",
       " 'rent_or_own',\n",
       " 'employment_status',\n",
       " 'hhs_geo_region',\n",
       " 'census_msa',\n",
       " 'household_adults',\n",
       " 'household_children',\n",
       " 'employment_industry',\n",
       " 'employment_occupation']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for categorical features\n",
    "# This stays the same for everything\n",
    "cat_pipeline = Pipeline([\n",
    "    ('1hot', OneHotEncoder(handle_unknown='error', drop='first'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', cat_pipeline, cat_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forst= RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forst_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", rand_forst),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('cat',\n",
       "                                                  Pipeline(steps=[('1hot',\n",
       "                                                                   OneHotEncoder(drop='first'))]),\n",
       "                                                  ['h1n1_concern',\n",
       "                                                   'h1n1_knowledge',\n",
       "                                                   'behavioral_antiviral_meds',\n",
       "                                                   'behavioral_avoidance',\n",
       "                                                   'behavioral_face_mask',\n",
       "                                                   'behavioral_wash_hands',\n",
       "                                                   'behavioral_large_gatherings',\n",
       "                                                   'behavioral_outside_home',\n",
       "                                                   'behavioral_touch_face',\n",
       "                                                   'doctor_recc_...\n",
       "                                                   'health_insurance',\n",
       "                                                   'opinion_h1n1_vacc_effective',\n",
       "                                                   'opinion_h1n1_risk',\n",
       "                                                   'opinion_h1n1_sick_from_vacc',\n",
       "                                                   'opinion_seas_vacc_effective',\n",
       "                                                   'opinion_seas_risk',\n",
       "                                                   'opinion_seas_sick_from_vacc',\n",
       "                                                   'age_group', 'education',\n",
       "                                                   'race', 'sex',\n",
       "                                                   'income_poverty',\n",
       "                                                   'marital_status',\n",
       "                                                   'rent_or_own',\n",
       "                                                   'employment_status',\n",
       "                                                   'hhs_geo_region', ...])])),\n",
       "                ('estimators', RandomForestClassifier())])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_forst_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split for h1n1_vaccine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_h1n1_train, y_h1n1_test = train_test_split(X, y_h1n1, stratify = y_h1n1, test_size=0.2, random_state=RSEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (21365, 35)\n",
      "X_test shape: (5342, 35)\n",
      "y_h1n1_train: (21365,)\n",
      "y_h1n1_test: (5342,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_h1n1_train:', y_h1n1_train.shape)\n",
    "print('y_h1n1_test:', y_h1n1_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting model and predicting for H1N1 vaccine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forst_h1n1_model = rand_forst_pipeline.fit(X_train, y_h1n1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on train data\n",
    "rand_forst_h1n1_train_pred = rand_forst_h1n1_model.predict(X_train)\n",
    "\n",
    "# Predictions on test data\n",
    "rand_forst_h1n1_test_pred = rand_forst_h1n1_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.703702974589236\n"
     ]
    }
   ],
   "source": [
    "# H1N1 ROC train data\n",
    "print(roc_auc_score(y_h1n1_train, rand_forst_h1n1_train_pred))\n",
    "\n",
    "# H1N1 ROC test data\n",
    "print(roc_auc_score(y_h1n1_test, rand_forst_h1n1_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonal prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up target variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., ..., 1., 0., 0.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_seasonal = df_num['seasonal_vaccine'].copy()\n",
    "y_seasonal = y_seasonal.to_numpy()\n",
    "y_seasonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_num.drop(columns=['h1n1_vaccine', 'seasonal_vaccine'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up categorical features for preprocessor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h1n1_concern',\n",
       " 'h1n1_knowledge',\n",
       " 'behavioral_antiviral_meds',\n",
       " 'behavioral_avoidance',\n",
       " 'behavioral_face_mask',\n",
       " 'behavioral_wash_hands',\n",
       " 'behavioral_large_gatherings',\n",
       " 'behavioral_outside_home',\n",
       " 'behavioral_touch_face',\n",
       " 'doctor_recc_h1n1',\n",
       " 'doctor_recc_seasonal',\n",
       " 'chronic_med_condition',\n",
       " 'child_under_6_months',\n",
       " 'health_worker',\n",
       " 'health_insurance',\n",
       " 'opinion_h1n1_vacc_effective',\n",
       " 'opinion_h1n1_risk',\n",
       " 'opinion_h1n1_sick_from_vacc',\n",
       " 'opinion_seas_vacc_effective',\n",
       " 'opinion_seas_risk',\n",
       " 'opinion_seas_sick_from_vacc',\n",
       " 'age_group',\n",
       " 'education',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'income_poverty',\n",
       " 'marital_status',\n",
       " 'rent_or_own',\n",
       " 'employment_status',\n",
       " 'hhs_geo_region',\n",
       " 'census_msa',\n",
       " 'household_adults',\n",
       " 'household_children',\n",
       " 'employment_industry',\n",
       " 'employment_occupation']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for categorical features\n",
    "# This stays the same for everything\n",
    "cat_pipeline = Pipeline([\n",
    "    ('1hot', OneHotEncoder(handle_unknown='error', drop='first'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', cat_pipeline, cat_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forst= RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forst_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", rand_forst),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('cat',\n",
       "                                                  Pipeline(steps=[('1hot',\n",
       "                                                                   OneHotEncoder(drop='first'))]),\n",
       "                                                  ['h1n1_concern',\n",
       "                                                   'h1n1_knowledge',\n",
       "                                                   'behavioral_antiviral_meds',\n",
       "                                                   'behavioral_avoidance',\n",
       "                                                   'behavioral_face_mask',\n",
       "                                                   'behavioral_wash_hands',\n",
       "                                                   'behavioral_large_gatherings',\n",
       "                                                   'behavioral_outside_home',\n",
       "                                                   'behavioral_touch_face',\n",
       "                                                   'doctor_recc_...\n",
       "                                                   'health_insurance',\n",
       "                                                   'opinion_h1n1_vacc_effective',\n",
       "                                                   'opinion_h1n1_risk',\n",
       "                                                   'opinion_h1n1_sick_from_vacc',\n",
       "                                                   'opinion_seas_vacc_effective',\n",
       "                                                   'opinion_seas_risk',\n",
       "                                                   'opinion_seas_sick_from_vacc',\n",
       "                                                   'age_group', 'education',\n",
       "                                                   'race', 'sex',\n",
       "                                                   'income_poverty',\n",
       "                                                   'marital_status',\n",
       "                                                   'rent_or_own',\n",
       "                                                   'employment_status',\n",
       "                                                   'hhs_geo_region', ...])])),\n",
       "                ('estimators', RandomForestClassifier())])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_forst_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split for seasonal vaccine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_seas_train, y_seas_test = train_test_split(X, y_seasonal, stratify = y_seasonal, test_size=0.2, random_state=RSEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (21365, 35)\n",
      "X_test shape: (5342, 35)\n",
      "y_seas_train: (21365,)\n",
      "y_seas_test: (5342,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_seas_train:', y_seas_train.shape)\n",
    "print('y_seas_test:', y_seas_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting model and predicting for seasonal vaccine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_forst_seas_model = rand_forst_pipeline.fit(X_train, y_seas_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on train data\n",
    "rand_forst_seas_train_pred = rand_forst_seas_model.predict(X_train)\n",
    "\n",
    "# Predictions on test data\n",
    "rand_forst_seas_test_pred = rand_forst_seas_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.7764883171828008\n"
     ]
    }
   ],
   "source": [
    "# seasonal ROC train data\n",
    "print(roc_auc_score(y_seas_train, rand_forst_seas_train_pred))\n",
    "\n",
    "# seasonal ROC test data\n",
    "print(roc_auc_score(y_seas_test, rand_forst_seas_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.7794833395731936\n"
     ]
    }
   ],
   "source": [
    "# seasonal ROC train data\n",
    "print(accuracy_score(y_seas_train, rand_forst_seas_train_pred))\n",
    "\n",
    "# seasonal ROC test data\n",
    "print(accuracy_score(y_seas_test, rand_forst_seas_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.7558043117744611\n"
     ]
    }
   ],
   "source": [
    "# seasonal ROC train data\n",
    "print(f1_score(y_seas_train, rand_forst_seas_train_pred))\n",
    "\n",
    "# seasonal ROC test data\n",
    "print(f1_score(y_seas_test, rand_forst_seas_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.7800599058622165\n"
     ]
    }
   ],
   "source": [
    "# seasonal ROC train data\n",
    "print(precision_score(y_seas_train, rand_forst_seas_train_pred))\n",
    "\n",
    "# seasonal ROC test data\n",
    "print(precision_score(y_seas_test, rand_forst_seas_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.7330116606353035\n"
     ]
    }
   ],
   "source": [
    "# seasonal ROC train data\n",
    "print(recall_score(y_seas_train, rand_forst_seas_train_pred))\n",
    "\n",
    "# seasonal ROC test data\n",
    "print(recall_score(y_seas_test, rand_forst_seas_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**H1N1 feature importance with eli5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 35 features, but DecisionTreeClassifier is expecting 148 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wg/qvgqr4_90653dyqmcf1s20lw0000gn/T/ipykernel_6637/2339572328.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0meli5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPermutationImportance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mperm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPermutationImportance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrand_forst_seas_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_seas_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0meli5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages/eli5/sklearn/permutation_importance.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0msi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cv_scores_importances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0msi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_non_cv_scores_importances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages/eli5/sklearn/permutation_importance.py\u001b[0m in \u001b[0;36m_non_cv_scores_importances\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_non_cv_scores_importances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mscore_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscorer_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrapped_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0mbase_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_score_importances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbase_score\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimportances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages/eli5/sklearn/permutation_importance.py\u001b[0m in \u001b[0;36m_get_score_importances\u001b[0;34m(self, score_func, X, y)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_score_importances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         return get_score_importances(score_func, X, y, n_iter=self.n_iter,\n\u001b[0m\u001b[1;32m    237\u001b[0m                                      random_state=self.rng_)\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages/eli5/permutation_importance.py\u001b[0m in \u001b[0;36mget_score_importances\u001b[0;34m(score_func, X, y, n_iter, columns_to_shuffle, random_state)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m     85\u001b[0m     \u001b[0mrng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mbase_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mscores_decreases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages/eli5/sklearn/permutation_importance.py\u001b[0m in \u001b[0;36mpd_scorer\u001b[0;34m(model, X, y)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mpd_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mbase_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpd_scorer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_passthrough_scorer\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_passthrough_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;34m\"\"\"Function that wraps estimator.score\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    498\u001b[0m         \"\"\"\n\u001b[1;32m    499\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \"\"\"\n\u001b[0;32m--> 630\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;34m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             X = self._validate_data(X, dtype=DTYPE, accept_sparse=\"csr\",\n\u001b[0m\u001b[1;32m    408\u001b[0m                                     reset=False)\n\u001b[1;32m    409\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n",
      "\u001b[0;32m~/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ensure_2d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    366\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                 f\"is expecting {self.n_features_in_} features as input.\")\n",
      "\u001b[0;31mValueError\u001b[0m: X has 35 features, but DecisionTreeClassifier is expecting 148 features as input."
     ]
    }
   ],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(rand_forst_seas_model.steps[1][1], random_state=1).fit(X_test, y_seas_test)\n",
    "eli5.show_weights(perm, top=None, feature_names = X_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seasonal feature importance with eli5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seas_model = rand_forst_seas_model.steps[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seas_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install eli5\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(seas_model, random_state=RSEED).fit(X_test, y_seas_test)\n",
    "eli5.show_weights(perm, feature_names = X_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_names(column_transformer):\n",
    "    \"\"\"Get feature names from all transformers.\n",
    "    Returns\n",
    "    -------\n",
    "    feature_names : list of strings\n",
    "        Names of the features produced by transform.\n",
    "    \"\"\"\n",
    "    # Remove the internal helper function\n",
    "    #check_is_fitted(column_transformer)\n",
    "    \n",
    "    # Turn loopkup into function for better handling with pipeline later\n",
    "    def get_names(trans):\n",
    "        # >> Original get_feature_names() method\n",
    "        if trans == 'drop' or (\n",
    "                hasattr(column, '__len__') and not len(column)):\n",
    "            return []\n",
    "        if trans == 'passthrough':\n",
    "            if hasattr(column_transformer, '_df_columns'):\n",
    "                if ((not isinstance(column, slice))\n",
    "                        and all(isinstance(col, str) for col in column)):\n",
    "                    return column\n",
    "                else:\n",
    "                    return column_transformer._df_columns[column]\n",
    "            else:\n",
    "                indices = np.arange(column_transformer._n_features)\n",
    "                return ['x%d' % i for i in indices[column]]\n",
    "        if not hasattr(trans, 'get_feature_names'):\n",
    "        # >>> Change: Return input column names if no method avaiable\n",
    "            # Turn error into a warning\n",
    "            warnings.warn(\"Transformer %s (type %s) does not \"\n",
    "                                 \"provide get_feature_names. \"\n",
    "                                 \"Will return input column names if available\"\n",
    "                                 % (str(name), type(trans).__name__))\n",
    "            # For transformers without a get_features_names method, use the input\n",
    "            # names to the column transformer\n",
    "            if column is None:\n",
    "                return []\n",
    "            else:\n",
    "                return [name + \"__\" + f for f in column]\n",
    "\n",
    "        return [name + \"__\" + f for f in trans.get_feature_names()]\n",
    "    \n",
    "    ### Start of processing\n",
    "    feature_names = []\n",
    "    \n",
    "    # Allow transformers to be pipelines. Pipeline steps are named differently, so preprocessing is needed\n",
    "    if type(column_transformer) == sklearn.pipeline.Pipeline:\n",
    "        l_transformers = [(name, trans, None, None) for step, name, trans in column_transformer._iter()]\n",
    "    else:\n",
    "        # For column transformers, follow the original method\n",
    "        l_transformers = list(column_transformer._iter(fitted=True))\n",
    "    \n",
    "    \n",
    "    for name, trans, column, _ in l_transformers: \n",
    "        if type(trans) == sklearn.pipeline.Pipeline:\n",
    "            # Recursive call on pipeline\n",
    "            _names = get_feature_names(trans)\n",
    "            # if pipeline has no transformer that returns names\n",
    "            if len(_names)==0:\n",
    "                _names = [name + \"__\" + f for f in column]\n",
    "            feature_names.extend(_names)\n",
    "        else:\n",
    "            feature_names.extend(get_names(trans))\n",
    "    \n",
    "    return feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_feature_names(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bdc0c931d2d4c1e254c9b407be81fb640f6c2f032b4d6ab78d09bb2272bcd9af"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
