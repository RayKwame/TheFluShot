{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Notes on MLFlow:\n",
    "- 'Run name' field: model name, type of output (multilabel vs unilabel), which vaccine (for multiclass only)\n",
    "- 'Parameters' field: methods applied for data (data cleaning, data balancing, hyperparameters)--insert feature engineering info here, if relevant?\n",
    "- 'Tags' field: details about the features used for the run (is one of the vaccines in the features?)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "source": [
    "import sys\n",
    "# adding to the path variables the one folder higher (locally, not changing system variables)\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "#mlflow import\n",
    "import mlflow\n",
    "from modeling.config import EXPERIMENT_NAME_multilabel, EXPERIMENT_NAME_h1n1, EXPERIMENT_NAME_seasonal, EXPERIMENT_NAME_multiclass\n",
    "TRACKING_URI = open(\"../.mlflow_uri\").read().strip()\n",
    "\n",
    "RSEED = 42\n",
    "\n",
    "# Modeling Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "!pip install plotly\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, cross_validate\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# for resampling (data balancing)\n",
    "from sklearn.utils import resample\n",
    "!pip install -U imbalanced-learn\n",
    "from imblearn.over_sampling import SMOTE"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: plotly in /Users/christinarudolf/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages (5.1.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/christinarudolf/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages (from plotly) (8.0.1)\n",
      "Requirement already satisfied: six in /Users/christinarudolf/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages (from plotly) (1.16.0)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.8.0-py3-none-any.whl (206 kB)\n",
      "\u001b[K     |████████████████████████████████| 206 kB 2.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /Users/christinarudolf/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages (from imbalanced-learn) (1.20.1)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in /Users/christinarudolf/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages (from imbalanced-learn) (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/christinarudolf/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages (from imbalanced-learn) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /Users/christinarudolf/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages (from imbalanced-learn) (1.6.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/christinarudolf/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages (from scikit-learn>=0.24->imbalanced-learn) (2.1.0)\n",
      "Installing collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.8.0\n"
     ]
    }
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Import data from a previously prepared dataframe:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df = pd.read_csv('../data/Flu_Shot_Data_cleaned_2.csv')"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0  h1n1_vaccine  seasonal_vaccine  h1n1_concern  h1n1_knowledge  \\\n",
       "0           0             0                 0           1.0             0.0   \n",
       "1           1             0                 1           3.0             2.0   \n",
       "2           2             0                 0           1.0             1.0   \n",
       "3           3             0                 1           1.0             1.0   \n",
       "4           4             0                 0           2.0             1.0   \n",
       "\n",
       "   behavioral_antiviral_meds  behavioral_avoidance  behavioral_face_mask  \\\n",
       "0                        0.0                   0.0                   0.0   \n",
       "1                        0.0                   1.0                   0.0   \n",
       "2                        0.0                   1.0                   0.0   \n",
       "3                        0.0                   1.0                   0.0   \n",
       "4                        0.0                   1.0                   0.0   \n",
       "\n",
       "   behavioral_wash_hands  behavioral_large_gatherings  ...  \\\n",
       "0                    0.0                          0.0  ...   \n",
       "1                    1.0                          0.0  ...   \n",
       "2                    0.0                          0.0  ...   \n",
       "3                    1.0                          1.0  ...   \n",
       "4                    1.0                          1.0  ...   \n",
       "\n",
       "              income_poverty  marital_status  rent_or_own   employment_status  \\\n",
       "0              Below Poverty     Not Married          Own  Not in Labor Force   \n",
       "1              Below Poverty     Not Married         Rent            Employed   \n",
       "2  <= $75,000, Above Poverty     Not Married          Own            Employed   \n",
       "3              Below Poverty     Not Married         Rent  Not in Labor Force   \n",
       "4  <= $75,000, Above Poverty         Married          Own            Employed   \n",
       "\n",
       "   hhs_geo_region                census_msa  household_adults  \\\n",
       "0        oxchjgsf                   Non-MSA               0.0   \n",
       "1        bhuqouqj  MSA, Not Principle  City               0.0   \n",
       "2        qufhixun  MSA, Not Principle  City               2.0   \n",
       "3        lrircsnp       MSA, Principle City               0.0   \n",
       "4        qufhixun  MSA, Not Principle  City               1.0   \n",
       "\n",
       "   household_children  employment_industry  employment_occupation  \n",
       "0                 0.0                  NaN                    NaN  \n",
       "1                 0.0             pxcmvdjn               xgwztkwe  \n",
       "2                 0.0             rucpziij               xtkaffoo  \n",
       "3                 0.0                  NaN                    NaN  \n",
       "4                 0.0             wxleyezf               emcorrxb  \n",
       "\n",
       "[5 rows x 38 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>h1n1_vaccine</th>\n",
       "      <th>seasonal_vaccine</th>\n",
       "      <th>h1n1_concern</th>\n",
       "      <th>h1n1_knowledge</th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>...</th>\n",
       "      <th>income_poverty</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>rent_or_own</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>hhs_geo_region</th>\n",
       "      <th>census_msa</th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "      <th>employment_industry</th>\n",
       "      <th>employment_occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>oxchjgsf</td>\n",
       "      <td>Non-MSA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Employed</td>\n",
       "      <td>bhuqouqj</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pxcmvdjn</td>\n",
       "      <td>xgwztkwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;= $75,000, Above Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Employed</td>\n",
       "      <td>qufhixun</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rucpziij</td>\n",
       "      <td>xtkaffoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>lrircsnp</td>\n",
       "      <td>MSA, Principle City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;= $75,000, Above Poverty</td>\n",
       "      <td>Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Employed</td>\n",
       "      <td>qufhixun</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>wxleyezf</td>\n",
       "      <td>emcorrxb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dropping the strange 'Unnamed: 0' column:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "df.drop('Unnamed: 0', axis=1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(26707, 37)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set up for modelling (stays the same for all experiemnts)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set up of pipeline preprocessor:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Pipeline for categorical features\n",
    "# This stays the same for everything\n",
    "cat_pipeline = Pipeline([\n",
    "    ('1hot', OneHotEncoder(handle_unknown='error', drop='first'))\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "cat_features = list(df.columns)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instantiating the models:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# for Logistic Regression\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# for KNN\n",
    "knn= KNeighborsClassifier()\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst= RandomForestClassifier()\n",
    "\n",
    "# for SVM\n",
    "svm= svm.SVC(kernel='rbf')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TheFluShot_multilabel: Multilabel prediction (both vaccinations)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Removal of target variables from cat_features list (this needs to be adjusted for each dataset):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "cat_features_no_vacc = cat_features.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "cat_features_no_vacc.remove('h1n1_vaccine')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "cat_features_no_vacc.remove('seasonal_vaccine')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "cat_features_no_vacc"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['h1n1_concern',\n",
       " 'h1n1_knowledge',\n",
       " 'behavioral_antiviral_meds',\n",
       " 'behavioral_avoidance',\n",
       " 'behavioral_face_mask',\n",
       " 'behavioral_wash_hands',\n",
       " 'behavioral_large_gatherings',\n",
       " 'behavioral_outside_home',\n",
       " 'behavioral_touch_face',\n",
       " 'doctor_recc_h1n1',\n",
       " 'doctor_recc_seasonal',\n",
       " 'chronic_med_condition',\n",
       " 'child_under_6_months',\n",
       " 'health_worker',\n",
       " 'health_insurance',\n",
       " 'opinion_h1n1_vacc_effective',\n",
       " 'opinion_h1n1_risk',\n",
       " 'opinion_h1n1_sick_from_vacc',\n",
       " 'opinion_seas_vacc_effective',\n",
       " 'opinion_seas_risk',\n",
       " 'opinion_seas_sick_from_vacc',\n",
       " 'age_group',\n",
       " 'education',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'income_poverty',\n",
       " 'marital_status',\n",
       " 'rent_or_own',\n",
       " 'employment_status',\n",
       " 'hhs_geo_region',\n",
       " 'census_msa',\n",
       " 'household_adults',\n",
       " 'household_children',\n",
       " 'employment_industry',\n",
       " 'employment_occupation']"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Rename the features and target to 'X' and 'y', to make the test-train split easier:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "y_both_vacc = df[['h1n1_vaccine', 'seasonal_vaccine']].copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "y_both_vacc = y_both_vacc.to_numpy()\n",
    "y_both_vacc"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       ...,\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 0]])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "#NB: dropping the 'h1n1_vaccine' and 'seasonal_vaccine' columns\n",
    "X_no_vacc = df.drop(columns=['h1n1_vaccine', 'seasonal_vaccine'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Performing test-train split (the same data can be used for each model in multilabelling):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "X_no_vacc_train, X_no_vacc_test, y_both_vacc_train, y_both_vacc_test = train_test_split(X_no_vacc, y_both_vacc, stratify = y_both_vacc, test_size=0.2, random_state=RSEED)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "print('X_no_vacc_train shape:', X_no_vacc_train.shape)\n",
    "print('X_no_vacc_test shape:', X_no_vacc_test.shape)\n",
    "print('y_both_vacc_train:', y_both_vacc_train.shape)\n",
    "print('y_both_vacc_test:', y_both_vacc_test.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X_no_vacc_train shape: (21365, 35)\n",
      "X_no_vacc_test shape: (5342, 35)\n",
      "y_both_vacc_train: (21365, 2)\n",
      "y_both_vacc_test: (5342, 2)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setting up the preprocessor (the same one can be used for each modelling in multilabelling):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', cat_pipeline, cat_features_no_vacc)\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setting up the multilabel estimators for each model:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# for logistic regression\n",
    "multilabel_est_logreg = MultiOutputClassifier(\n",
    "    estimator=logreg\n",
    ")\n",
    "\n",
    "# for KNN\n",
    "multilabel_est_knn= MultiOutputClassifier(\n",
    "    estimator=knn\n",
    ")\n",
    "\n",
    "# for Random Forest\n",
    "multilabel_est_rand_forst= MultiOutputClassifier(\n",
    "    estimator=rand_forst\n",
    ")\n",
    "\n",
    "\n",
    "# for SVM\n",
    "multilabel_est_SVC= MultiOutputClassifier(\n",
    "    estimator=svm\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setting up the pipeline for each model:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# for logreg\n",
    "logreg_multilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", multilabel_est_logreg),\n",
    "])\n",
    "\n",
    "# for KNN\n",
    "knn_multilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", multilabel_est_knn),\n",
    "])\n",
    "\n",
    "# for Random Forest\n",
    "\n",
    "rand_forst_multilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", multilabel_est_rand_forst),\n",
    "])\n",
    "\n",
    "#for SVM\n",
    "svm_multilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", multilabel_est_SVC),\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training the models:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for logreg\n",
    "logreg_multilabel = logreg_multilabel_pipeline.fit(X_no_vacc_train,  y_both_vacc_train)\n",
    "\n",
    "# for KNN\n",
    "knn_multilabel = knn_multilabel_pipeline.fit(X_no_vacc_train,  y_both_vacc_train)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_multilabel = rand_forst_multilabel_pipeline.fit(X_no_vacc_train,  y_both_vacc_train)\n",
    "\n",
    "#for SVM\n",
    "svm_multilabel = svm_multilabel_pipeline.fit(X_no_vacc_train,  y_both_vacc_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Figure out later what this does and if we want to use it\n",
    "\n",
    "\n",
    "#y_train_predicted = cross_val_predict(full_pipeline, X_train, y_train, cv=5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Making predictions based on train and test data:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for logreg\n",
    "logreg_multilabel_trainpreds = logreg_multilabel.predict(X_no_vacc_train)\n",
    "logreg_multilabel_testpreds = logreg_multilabel.predict(X_no_vacc_test)\n",
    "\n",
    "# for KNN\n",
    "knn_multilabel_trainpreds = knn_multilabel.predict(X_no_vacc_train)\n",
    "knn_multilabel_testpreds = knn_multilabel.predict(X_no_vacc_test)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_multilabel_trainpreds = rand_forst_multilabel.predict(X_no_vacc_train)\n",
    "rand_forst_multilabel_testpreds = rand_forst_multilabel.predict(X_no_vacc_test)\n",
    "\n",
    "# for SVM\n",
    "svm_multilabel_trainpreds = svm_multilabel.predict(X_no_vacc_train)\n",
    "svm_multilabel_testpreds = svm_multilabel.predict(X_no_vacc_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model evaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Logreg--Train data evaluation Metrics for H1N1 Vaccines\n",
    "h1n1_logreg_multilabel_train_acc = accuracy_score(y_both_vacc_train[:, 0], logreg_multilabel_trainpreds[:, 0])\n",
    "h1n1_logreg_multilabel_train_recall = recall_score(y_both_vacc_train[:, 0], logreg_multilabel_trainpreds[:, 0])\n",
    "h1n1_logreg_multilabel_train_precision = precision_score(y_both_vacc_train[:, 0], logreg_multilabel_trainpreds[:, 0])\n",
    "h1n1_logreg_multilabel_train_f1 = f1_score(y_both_vacc_train[:, 0], logreg_multilabel_trainpreds[:, 0])\n",
    "h1n1_logreg_multilabel_train_roc = roc_auc_score(y_both_vacc_train[:, 0], logreg_multilabel_trainpreds[:, 0])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_train[:, 0], logreg_multilabel_trainpreds[:, 0])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_train[:, 0], logreg_multilabel_trainpreds[:, 0])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_train[:, 0], logreg_multilabel_trainpreds[:, 0])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_train[:, 0], logreg_multilabel_trainpreds[:, 0])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_train[:, 0], logreg_multilabel_trainpreds[:, 0])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Logreg--Train data Evaluation Metrics for seasonal Vaccines\n",
    "seasonal_logreg_multilabel_train_acc = accuracy_score(y_both_vacc_train[:, 1], logreg_multilabel_trainpreds[:, 1])\n",
    "seasonal_logreg_multilabel_train_recall = recall_score(y_both_vacc_train[:, 1], logreg_multilabel_trainpreds[:, 1])\n",
    "seasonal_logreg_multilabel_train_precision = precision_score(y_both_vacc_train[:, 1], logreg_multilabel_trainpreds[:, 1])\n",
    "seasonal_logreg_multilabel_train_f1 = f1_score(y_both_vacc_train[:, 1], logreg_multilabel_trainpreds[:, 1])\n",
    "seasonal_logreg_multilabel_train_roc = roc_auc_score(y_both_vacc_train[:, 1], logreg_multilabel_trainpreds[:, 1])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_train[:, 1], logreg_multilabel_trainpreds[:, 1])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_train[:, 1], logreg_multilabel_trainpreds[:, 1])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_train[:, 1], logreg_multilabel_trainpreds[:, 1])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_train[:, 1], logreg_multilabel_trainpreds[:, 1])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_train[:, 1], logreg_multilabel_trainpreds[:, 1])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# KNN--Train data evaluation Metrics for H1N1 Vaccines\n",
    "h1n1_knn_multilabel_train_acc = accuracy_score(y_both_vacc_train[:, 0], knn_multilabel_trainpreds[:, 0])\n",
    "h1n1_knn_multilabel_train_recall = recall_score(y_both_vacc_train[:, 0], knn_multilabel_trainpreds[:, 0])\n",
    "h1n1_knn_multilabel_train_precision = precision_score(y_both_vacc_train[:, 0], knn_multilabel_trainpreds[:, 0])\n",
    "h1n1_knn_multilabel_train_f1 = f1_score(y_both_vacc_train[:, 0], knn_multilabel_trainpreds[:, 0])\n",
    "h1n1_knn_multilabel_train_roc = roc_auc_score(y_both_vacc_train[:, 0], knn_multilabel_trainpreds[:, 0])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_train[:, 0], knn_multilabel_trainpreds[:, 0])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_train[:, 0], knn_multilabel_trainpreds[:, 0])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_train[:, 0], knn_multilabel_trainpreds[:, 0])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_train[:, 0], knn_multilabel_trainpreds[:, 0])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_train[:, 0], knn_multilabel_trainpreds[:, 0])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# KNN--Train data Evaluation Metrics for seasonal Vaccines\n",
    "seasonal_knn_multilabel_train_acc = accuracy_score(y_both_vacc_train[:, 1], knn_multilabel_trainpreds[:, 1])\n",
    "seasonal_knn_multilabel_train_recall = recall_score(y_both_vacc_train[:, 1], knn_multilabel_trainpreds[:, 1])\n",
    "seasonal_knn_multilabel_train_precision = precision_score(y_both_vacc_train[:, 1], knn_multilabel_trainpreds[:, 1])\n",
    "seasonal_knn_multilabel_train_f1 = f1_score(y_both_vacc_train[:, 1], knn_multilabel_trainpreds[:, 1])\n",
    "seasonal_knn_multilabel_train_roc = roc_auc_score(y_both_vacc_train[:, 1], knn_multilabel_trainpreds[:, 1])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_train[:, 1], knn_multilabel_trainpreds[:, 1])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_train[:, 1], knn_multilabel_trainpreds[:, 1])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_train[:, 1], knn_multilabel_trainpreds[:, 1])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_train[:, 1], knn_multilabel_trainpreds[:, 1])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_train[:, 1], knn_multilabel_trainpreds[:, 1])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Random Forest--Train data evaluation Metrics for H1N1 Vaccines\n",
    "# THESE RESULTS ARE SLIGHTLY OFF FROM PREVIOUS NOTEBOOK (BY 0.01)--CHECK WHAT'S AT PLAY. VARIATION COMING FROM TEST-TRAIN SPLIT? EXPORT TEST-TRAIN DATA AS CSV AND TRY AGAIN\n",
    "#IS IT BECAUSE IT'S RANDOM FOREST? DIFFERENT STARTING STUMP EACH TIME?\n",
    "h1n1_rand_forst_multilabel_train_acc = accuracy_score(y_both_vacc_train[:, 0], rand_forst_multilabel_trainpreds[:, 0])\n",
    "h1n1_rand_forst_multilabel_train_recall = recall_score(y_both_vacc_train[:, 0], rand_forst_multilabel_trainpreds[:, 0])\n",
    "h1n1_rand_forst_multilabel_train_precision = precision_score(y_both_vacc_train[:, 0], rand_forst_multilabel_trainpreds[:, 0])\n",
    "h1n1_rand_forst_multilabel_train_f1 = f1_score(y_both_vacc_train[:, 0], rand_forst_multilabel_trainpreds[:, 0])\n",
    "h1n1_rand_forst_multilabel_train_roc = roc_auc_score(y_both_vacc_train[:, 0], rand_forst_multilabel_trainpreds[:, 0])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_train[:, 0], rand_forst_multilabel_trainpreds[:, 0])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_train[:, 0], rand_forst_multilabel_trainpreds[:, 0])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_train[:, 0], rand_forst_multilabel_trainpreds[:, 0])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_train[:, 0], rand_forst_multilabel_trainpreds[:, 0])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_train[:, 0], rand_forst_multilabel_trainpreds[:, 0])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Random Forest--Train data Evaluation Metrics for seasonal Vaccines\n",
    "# THESE RESULTS ARE SLIGHTLY OFF FROM PREVIOUS NOTEBOOK (BY 0.01)--CHECK WHAT'S AT PLAY. VARIATION COMING FROM TEST-TRAIN SPLIT? EXPORT TEST-TRAIN DATA AS CSV AND TRY AGAIN\n",
    "#IS IT BECAUSE IT'S RANDOM FOREST? DIFFERENT STARTING STUMP EACH TIME?\n",
    "seasonal_rand_forst_multilabel_train_acc = accuracy_score(y_both_vacc_train[:, 1], rand_forst_multilabel_trainpreds[:, 1])\n",
    "seasonal_rand_forst_multilabel_train_recall = recall_score(y_both_vacc_train[:, 1], rand_forst_multilabel_trainpreds[:, 1])\n",
    "seasonal_rand_forst_multilabel_train_precision = precision_score(y_both_vacc_train[:, 1], rand_forst_multilabel_trainpreds[:, 1])\n",
    "seasonal_rand_forst_multilabel_train_f1 = f1_score(y_both_vacc_train[:, 1], rand_forst_multilabel_trainpreds[:, 1])\n",
    "seasonal_rand_forst_multilabel_train_roc = roc_auc_score(y_both_vacc_train[:, 1], rand_forst_multilabel_trainpreds[:, 1])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_train[:, 1], rand_forst_multilabel_trainpreds[:, 1])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_train[:, 1], rand_forst_multilabel_trainpreds[:, 1])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_train[:, 1], rand_forst_multilabel_trainpreds[:, 1])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_train[:, 1], rand_forst_multilabel_trainpreds[:, 1])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_train[:, 1], rand_forst_multilabel_trainpreds[:, 1])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SVM--Train data evaluation Metrics for H1N1 Vaccines\n",
    "h1n1_svm_multilabel_train_acc = accuracy_score(y_both_vacc_train[:, 0], svm_multilabel_trainpreds[:, 0])\n",
    "h1n1_svm_multilabel_train_recall = recall_score(y_both_vacc_train[:, 0], svm_multilabel_trainpreds[:, 0])\n",
    "h1n1_svm_multilabel_train_precision = precision_score(y_both_vacc_train[:, 0], svm_multilabel_trainpreds[:, 0])\n",
    "h1n1_svm_multilabel_train_f1 = f1_score(y_both_vacc_train[:, 0], svm_multilabel_trainpreds[:, 0])\n",
    "h1n1_svm_multilabel_train_roc = roc_auc_score(y_both_vacc_train[:, 0], svm_multilabel_trainpreds[:, 0])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_train[:, 0], svm_multilabel_trainpreds[:, 0])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_train[:, 0], svm_multilabel_trainpreds[:, 0])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_train[:, 0], svm_multilabel_trainpreds[:, 0])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_train[:, 0], svm_multilabel_trainpreds[:, 0])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_train[:, 0], svm_multilabel_trainpreds[:, 0])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SVM--Train data Evaluation Metrics for seasonal Vaccines\n",
    "seasonal_svm_multilabel_train_acc = accuracy_score(y_both_vacc_train[:, 1], svm_multilabel_trainpreds[:, 1])\n",
    "seasonal_svm_multilabel_train_recall = recall_score(y_both_vacc_train[:, 1], svm_multilabel_trainpreds[:, 1])\n",
    "seasonal_svm_multilabel_train_precision = precision_score(y_both_vacc_train[:, 1], svm_multilabel_trainpreds[:, 1])\n",
    "seasonal_svm_multilabel_train_f1 = f1_score(y_both_vacc_train[:, 1], svm_multilabel_trainpreds[:, 1])\n",
    "seasonal_svm_multilabel_train_roc = roc_auc_score(y_both_vacc_train[:, 1], svm_multilabel_trainpreds[:, 1])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_train[:, 1], svm_multilabel_trainpreds[:, 1])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_train[:, 1], svm_multilabel_trainpreds[:, 1])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_train[:, 1], svm_multilabel_trainpreds[:, 1])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_train[:, 1], svm_multilabel_trainpreds[:, 1])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_train[:, 1], svm_multilabel_trainpreds[:, 1])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Test data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Logreg--Test data evaluation Metrics for H1N1 Vaccines\n",
    "h1n1_logreg_multilabel_test_acc = accuracy_score(y_both_vacc_test[:, 0], logreg_multilabel_testpreds[:, 0])\n",
    "h1n1_logreg_multilabel_test_recall = recall_score(y_both_vacc_test[:, 0], logreg_multilabel_testpreds[:, 0])\n",
    "h1n1_logreg_multilabel_test_precision = precision_score(y_both_vacc_test[:, 0], logreg_multilabel_testpreds[:, 0])\n",
    "h1n1_logreg_multilabel_test_f1 = f1_score(y_both_vacc_test[:, 0], logreg_multilabel_testpreds[:, 0])\n",
    "h1n1_logreg_multilabel_test_roc = roc_auc_score(y_both_vacc_test[:, 0], logreg_multilabel_testpreds[:, 0])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_test[:, 0], logreg_multilabel_testpreds[:, 0])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_test[:, 0], logreg_multilabel_testpreds[:, 0])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_test[:, 0], logreg_multilabel_testpreds[:, 0])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_test[:, 0], logreg_multilabel_testpreds[:, 0])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_test[:, 0], logreg_multilabel_testpreds[:, 0])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Logreg--Test data Evaluation Metrics for seasonal Vaccines\n",
    "seasonal_logreg_multilabel_test_acc = accuracy_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])\n",
    "seasonal_logreg_multilabel_test_recall = recall_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])\n",
    "seasonal_logreg_multilabel_test_precision = precision_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])\n",
    "seasonal_logreg_multilabel_test_f1 = f1_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])\n",
    "seasonal_logreg_multilabel_test_roc = roc_auc_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# KNN--Test data evaluation Metrics for H1N1 Vaccines\n",
    "h1n1_knn_multilabel_test_acc = accuracy_score(y_both_vacc_test[:, 0], knn_multilabel_testpreds[:, 0])\n",
    "h1n1_knn_multilabel_test_recall = recall_score(y_both_vacc_test[:, 0], knn_multilabel_testpreds[:, 0])\n",
    "h1n1_knn_multilabel_test_precision = precision_score(y_both_vacc_test[:, 0], knn_multilabel_testpreds[:, 0])\n",
    "h1n1_knn_multilabel_test_f1 = f1_score(y_both_vacc_test[:, 0], knn_multilabel_testpreds[:, 0])\n",
    "h1n1_knn_multilabel_test_roc = roc_auc_score(y_both_vacc_test[:, 0], knn_multilabel_testpreds[:, 0])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_test[:, 0], knn_multilabel_testpreds[:, 0])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_test[:, 0], knn_multilabel_testpreds[:, 0])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_test[:, 0], knn_multilabel_testpreds[:, 0])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_test[:, 0], knn_multilabel_testpreds[:, 0])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_test[:, 0], knn_multilabel_testpreds[:, 0])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# KNN--Test data Evaluation Metrics for seasonal Vaccines\n",
    "seasonal_knn_multilabel_test_acc = accuracy_score(y_both_vacc_test[:, 1], knn_multilabel_testpreds[:, 1])\n",
    "seasonal_knn_multilabel_test_recall = recall_score(y_both_vacc_test[:, 1], knn_multilabel_testpreds[:, 1])\n",
    "seasonal_knn_multilabel_test_precision = precision_score(y_both_vacc_test[:, 1], knn_multilabel_testpreds[:, 1])\n",
    "seasonal_knn_multilabel_test_f1 = f1_score(y_both_vacc_test[:, 1], knn_multilabel_testpreds[:, 1])\n",
    "seasonal_knn_multilabel_test_roc = roc_auc_score(y_both_vacc_test[:, 1], knn_multilabel_testpreds[:, 1])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_test[:, 1], knn_multilabel_testpreds[:, 1])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_test[:, 1], knn_multilabel_testpreds[:, 1])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_test[:, 1], knn_multilabel_testpreds[:, 1])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_test[:, 1], knn_multilabel_testpreds[:, 1])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_test[:, 1], knn_multilabel_testpreds[:, 1])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Random Forest--Test data evaluation Metrics for H1N1 Vaccines\n",
    "# THESE RESULTS ARE SLIGHTLY OFF FROM PREVIOUS NOTEBOOK (BY 0.01)--CHECK WHAT'S AT PLAY. VARIATION COMING FROM TEST-TRAIN SPLIT? EXPORT TEST-TRAIN DATA AS CSV AND TRY AGAIN\n",
    "#IS IT BECAUSE IT'S RANDOM FOREST? DIFFERENT STARTING STUMP EACH TIME?\n",
    "h1n1_rand_forst_multilabel_test_acc = accuracy_score(y_both_vacc_test[:, 0], rand_forst_multilabel_testpreds[:, 0])\n",
    "h1n1_rand_forst_multilabel_test_recall = recall_score(y_both_vacc_test[:, 0], rand_forst_multilabel_testpreds[:, 0])\n",
    "h1n1_rand_forst_multilabel_test_precision = precision_score(y_both_vacc_test[:, 0], rand_forst_multilabel_testpreds[:, 0])\n",
    "h1n1_rand_forst_multilabel_test_f1 = f1_score(y_both_vacc_test[:, 0], rand_forst_multilabel_testpreds[:, 0])\n",
    "h1n1_rand_forst_multilabel_test_roc = roc_auc_score(y_both_vacc_test[:, 0], rand_forst_multilabel_testpreds[:, 0])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_test[:, 0], rand_forst_multilabel_testpreds[:, 0])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_test[:, 0], rand_forst_multilabel_testpreds[:, 0])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_test[:, 0], rand_forst_multilabel_testpreds[:, 0])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_test[:, 0], rand_forst_multilabel_testpreds[:, 0])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_test[:, 0], rand_forst_multilabel_testpreds[:, 0])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Random Forest--Test data Evaluation Metrics for seasonal Vaccines\n",
    "# THESE RESULTS ARE SLIGHTLY OFF FROM PREVIOUS NOTEBOOK (BY 0.01)--CHECK WHAT'S AT PLAY. VARIATION COMING FROM TEST-TRAIN SPLIT? EXPORT TEST-TRAIN DATA AS CSV AND TRY AGAIN\n",
    "#IS IT BECAUSE IT'S RANDOM FOREST? DIFFERENT STARTING STUMP EACH TIME?\n",
    "seasonal_rand_forst_multilabel_test_acc = accuracy_score(y_both_vacc_test[:, 1], rand_forst_multilabel_testpreds[:, 1])\n",
    "seasonal_rand_forst_multilabel_test_recall = recall_score(y_both_vacc_test[:, 1], rand_forst_multilabel_testpreds[:, 1])\n",
    "seasonal_rand_forst_multilabel_test_precision = precision_score(y_both_vacc_test[:, 1], rand_forst_multilabel_testpreds[:, 1])\n",
    "seasonal_rand_forst_multilabel_test_f1 = f1_score(y_both_vacc_test[:, 1], rand_forst_multilabel_testpreds[:, 1])\n",
    "seasonal_rand_forst_multilabel_test_roc = roc_auc_score(y_both_vacc_test[:, 1], rand_forst_multilabel_testpreds[:, 1])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_test[:, 1], rand_forst_multilabel_testpreds[:, 1])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_test[:, 1], rand_forst_multilabel_testpreds[:, 1])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_test[:, 1], rand_forst_multilabel_testpreds[:, 1])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_test[:, 1], rand_forst_multilabel_testpreds[:, 1])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_test[:, 1], rand_forst_multilabel_testpreds[:, 1])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SVM--Test data evaluation Metrics for H1N1 Vaccines\n",
    "h1n1_svm_multilabel_test_acc = accuracy_score(y_both_vacc_test[:, 0], svm_multilabel_testpreds[:, 0])\n",
    "h1n1_svm_multilabel_test_recall = recall_score(y_both_vacc_test[:, 0], svm_multilabel_testpreds[:, 0])\n",
    "h1n1_svm_multilabel_test_precision = precision_score(y_both_vacc_test[:, 0], svm_multilabel_testpreds[:, 0])\n",
    "h1n1_svm_multilabel_test_f1 = f1_score(y_both_vacc_test[:, 0], svm_multilabel_testpreds[:, 0])\n",
    "h1n1_svm_multilabel_test_roc = roc_auc_score(y_both_vacc_test[:, 0], svm_multilabel_testpreds[:, 0])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_test[:, 0], svm_multilabel_testpreds[:, 0])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_test[:, 0], svm_multilabel_testpreds[:, 0])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_test[:, 0], svm_multilabel_testpreds[:, 0])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_test[:, 0], svm_multilabel_testpreds[:, 0])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_test[:, 0], svm_multilabel_testpreds[:, 0])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SVM--Test data Evaluation Metrics for seasonal Vaccines\n",
    "seasonal_svm_multilabel_test_acc = accuracy_score(y_both_vacc_test[:, 1], svm_multilabel_testpreds[:, 1])\n",
    "seasonal_svm_multilabel_test_recall = recall_score(y_both_vacc_test[:, 1], svm_multilabel_testpreds[:, 1])\n",
    "seasonal_svm_multilabel_test_precision = precision_score(y_both_vacc_test[:, 1], svm_multilabel_testpreds[:, 1])\n",
    "seasonal_svm_multilabel_test_f1 = f1_score(y_both_vacc_test[:, 1], svm_multilabel_testpreds[:, 1])\n",
    "seasonal_svm_multilabel_test_roc = roc_auc_score(y_both_vacc_test[:, 1], svm_multilabel_testpreds[:, 1])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tracking the model with MLFlow"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### H1N1 vaccine output"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Logistic regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_multilabel) #this needs to be adjusted for each experiment\n",
    "name = 'logreg_multilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_logreg_multilabel_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_logreg_multilabel_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_logreg_multilabel_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_logreg_multilabel_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_logreg_multilabel_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_logreg_multilabel_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_logreg_multilabel_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_logreg_multilabel_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_logreg_multilabel_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_logreg_multilabel_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### KNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_multilabel)\n",
    "name = 'knn_multilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_knn_multilabel_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_knn_multilabel_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_knn_multilabel_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_knn_multilabel_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_knn_multilabel_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_knn_multilabel_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_knn_multilabel_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_knn_multilabel_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_knn_multilabel_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_knn_multilabel_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_multilabel)\n",
    "name = 'rand_forst_multilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_rand_forst_multilabel_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_rand_forst_multilabel_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_rand_forst_multilabel_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_rand_forst_multilabel_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_rand_forst_multilabel_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_rand_forst_multilabel_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_rand_forst_multilabel_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_rand_forst_multilabel_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_rand_forst_multilabel_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_rand_forst_multilabel_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### SVM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_multilabel)\n",
    "name = 'svm_multilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_svm_multilabel_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_svm_multilabel_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_svm_multilabel_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_svm_multilabel_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_svm_multilabel_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_svm_multilabel_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_svm_multilabel_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_svm_multilabel_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_svm_multilabel_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_svm_multilabel_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Seasonal vaccine output"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Logistic regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_multilabel)\n",
    "name = 'logreg_multilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seasonal_logreg_multilabel_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seasonal_logreg_multilabel_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seasonal_logreg_multilabel_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seasonal_logreg_multilabel_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seasonal_logreg_multilabel_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seasonal_logreg_multilabel_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seasonal_logreg_multilabel_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seasonal_logreg_multilabel_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seasonal_logreg_multilabel_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seasonal_logreg_multilabel_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### KNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_multilabel)\n",
    "name = 'knn_multilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seasonal_knn_multilabel_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seasonal_knn_multilabel_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seasonal_knn_multilabel_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seasonal_knn_multilabel_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seasonal_knn_multilabel_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seasonal_knn_multilabel_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seasonal_knn_multilabel_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seasonal_knn_multilabel_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seasonal_knn_multilabel_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seasonal_knn_multilabel_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_multilabel)\n",
    "name = 'rand_forst_multilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seasonal_rand_forst_multilabel_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seasonal_rand_forst_multilabel_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seasonal_rand_forst_multilabel_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seasonal_rand_forst_multilabel_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seasonal_rand_forst_multilabel_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seasonal_rand_forst_multilabel_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seasonal_rand_forst_multilabel_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seasonal_rand_forst_multilabel_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seasonal_rand_forst_multilabel_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seasonal_rand_forst_multilabel_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### SVM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_multilabel)\n",
    "name = 'svm_multilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seasonal_svm_multilabel_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seasonal_svm_multilabel_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seasonal_svm_multilabel_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seasonal_svm_multilabel_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seasonal_svm_multilabel_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seasonal_svm_multilabel_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seasonal_svm_multilabel_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seasonal_svm_multilabel_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seasonal_svm_multilabel_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seasonal_svm_multilabel_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TheFluShot_H1N1: Single Label Modelling, output H1N1 vaccine"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Single Label Modelling, output H1N1 vaccine -> Seasonal Flu Vaccine not in features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The cat_features_no_vacc and X_no_vacc variables and the preprocessor remain the same from the multilabel modelling:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set up the target variable:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "y_h1n1_vacc = df.h1n1_vaccine"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "#y_h1n1_vacc = y_h1n1_vacc.to_numpy()\n",
    "#y_h1n1_vacc = y_h1n1_vacc.squeeze()\n",
    "y_h1n1_vacc"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "26702    0\n",
       "26703    0\n",
       "26704    0\n",
       "26705    0\n",
       "26706    0\n",
       "Name: h1n1_vaccine, Length: 26707, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Performing test-train split:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "X_no_vacc_train, X_no_vacc_test, y_h1n1_vacc_train, y_h1n1_vacc_test = train_test_split(X_no_vacc, y_h1n1_vacc, stratify = y_h1n1_vacc, test_size=0.2, random_state=RSEED)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "print('X_no_vacc_train shape:', X_no_vacc_train.shape)\n",
    "print('X_no_vacc_test shape:', X_no_vacc_test.shape)\n",
    "print('y_h1n1_vacc_train:', y_h1n1_vacc_train.shape)\n",
    "print('y_h1n1_vacc_test:', y_h1n1_vacc_test.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X_no_vacc_train shape: (21365, 35)\n",
      "X_no_vacc_test shape: (5342, 35)\n",
      "y_h1n1_vacc_train: (21365,)\n",
      "y_h1n1_vacc_test: (5342,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setting up the pipeline for each model:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "# for logreg\n",
    "logreg_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", logreg),\n",
    "])\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", knn),\n",
    "])\n",
    "\n",
    "# for Random Forest\n",
    "\n",
    "rand_forst_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", rand_forst),\n",
    "])\n",
    "\n",
    "#for SVM\n",
    "svm_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", svm),\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Balancing\n",
    "\n",
    "https://towardsdatascience.com/methods-for-dealing-with-imbalanced-data-5b761be45a18\n",
    "\n",
    "Since the H1N1 label is unbalanced, three approaches will be tried to balance it:\n",
    "\n",
    "1. Oversampling of the minority class (h1n1_vaccine == 1)\n",
    "2. Undersampling of the majority class (h1n1_vaccine == 0)\n",
    "3. Creation of synthetic samples using SMOTE"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       h1n1_vaccine  seasonal_vaccine  h1n1_concern  h1n1_knowledge  \\\n",
       "0                 0                 0           1.0             0.0   \n",
       "1                 0                 1           3.0             2.0   \n",
       "2                 0                 0           1.0             1.0   \n",
       "3                 0                 1           1.0             1.0   \n",
       "4                 0                 0           2.0             1.0   \n",
       "...             ...               ...           ...             ...   \n",
       "26702             0                 0           2.0             0.0   \n",
       "26703             0                 0           1.0             2.0   \n",
       "26704             0                 1           2.0             2.0   \n",
       "26705             0                 0           1.0             1.0   \n",
       "26706             0                 0           0.0             0.0   \n",
       "\n",
       "       behavioral_antiviral_meds  behavioral_avoidance  behavioral_face_mask  \\\n",
       "0                            0.0                   0.0                   0.0   \n",
       "1                            0.0                   1.0                   0.0   \n",
       "2                            0.0                   1.0                   0.0   \n",
       "3                            0.0                   1.0                   0.0   \n",
       "4                            0.0                   1.0                   0.0   \n",
       "...                          ...                   ...                   ...   \n",
       "26702                        0.0                   1.0                   0.0   \n",
       "26703                        0.0                   1.0                   0.0   \n",
       "26704                        0.0                   1.0                   1.0   \n",
       "26705                        0.0                   0.0                   0.0   \n",
       "26706                        0.0                   1.0                   0.0   \n",
       "\n",
       "       behavioral_wash_hands  behavioral_large_gatherings  \\\n",
       "0                        0.0                          0.0   \n",
       "1                        1.0                          0.0   \n",
       "2                        0.0                          0.0   \n",
       "3                        1.0                          1.0   \n",
       "4                        1.0                          1.0   \n",
       "...                      ...                          ...   \n",
       "26702                    0.0                          0.0   \n",
       "26703                    1.0                          0.0   \n",
       "26704                    1.0                          1.0   \n",
       "26705                    0.0                          0.0   \n",
       "26706                    0.0                          0.0   \n",
       "\n",
       "       behavioral_outside_home  ...             income_poverty  \\\n",
       "0                          1.0  ...              Below Poverty   \n",
       "1                          1.0  ...              Below Poverty   \n",
       "2                          0.0  ...  <= $75,000, Above Poverty   \n",
       "3                          0.0  ...              Below Poverty   \n",
       "4                          0.0  ...  <= $75,000, Above Poverty   \n",
       "...                        ...  ...                        ...   \n",
       "26702                      1.0  ...  <= $75,000, Above Poverty   \n",
       "26703                      0.0  ...  <= $75,000, Above Poverty   \n",
       "26704                      0.0  ...                        NaN   \n",
       "26705                      0.0  ...  <= $75,000, Above Poverty   \n",
       "26706                      0.0  ...  <= $75,000, Above Poverty   \n",
       "\n",
       "       marital_status  rent_or_own   employment_status  hhs_geo_region  \\\n",
       "0         Not Married          Own  Not in Labor Force        oxchjgsf   \n",
       "1         Not Married         Rent            Employed        bhuqouqj   \n",
       "2         Not Married          Own            Employed        qufhixun   \n",
       "3         Not Married         Rent  Not in Labor Force        lrircsnp   \n",
       "4             Married          Own            Employed        qufhixun   \n",
       "...               ...          ...                 ...             ...   \n",
       "26702     Not Married          Own  Not in Labor Force        qufhixun   \n",
       "26703     Not Married         Rent            Employed        lzgpxyit   \n",
       "26704     Not Married          Own                 NaN        lzgpxyit   \n",
       "26705         Married         Rent            Employed        lrircsnp   \n",
       "26706         Married          Own  Not in Labor Force        mlyzmhmf   \n",
       "\n",
       "                     census_msa  household_adults  household_children  \\\n",
       "0                       Non-MSA               0.0                 0.0   \n",
       "1      MSA, Not Principle  City               0.0                 0.0   \n",
       "2      MSA, Not Principle  City               2.0                 0.0   \n",
       "3           MSA, Principle City               0.0                 0.0   \n",
       "4      MSA, Not Principle  City               1.0                 0.0   \n",
       "...                         ...               ...                 ...   \n",
       "26702                   Non-MSA               0.0                 0.0   \n",
       "26703       MSA, Principle City               1.0                 0.0   \n",
       "26704  MSA, Not Principle  City               0.0                 0.0   \n",
       "26705                   Non-MSA               1.0                 0.0   \n",
       "26706       MSA, Principle City               1.0                 0.0   \n",
       "\n",
       "       employment_industry  employment_occupation  \n",
       "0                      NaN                    NaN  \n",
       "1                 pxcmvdjn               xgwztkwe  \n",
       "2                 rucpziij               xtkaffoo  \n",
       "3                      NaN                    NaN  \n",
       "4                 wxleyezf               emcorrxb  \n",
       "...                    ...                    ...  \n",
       "26702                  NaN                    NaN  \n",
       "26703             fcxhlnwr               cmhcxjea  \n",
       "26704                  NaN                    NaN  \n",
       "26705             fcxhlnwr               haliazsg  \n",
       "26706                  NaN                    NaN  \n",
       "\n",
       "[26707 rows x 37 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h1n1_vaccine</th>\n",
       "      <th>seasonal_vaccine</th>\n",
       "      <th>h1n1_concern</th>\n",
       "      <th>h1n1_knowledge</th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>behavioral_outside_home</th>\n",
       "      <th>...</th>\n",
       "      <th>income_poverty</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>rent_or_own</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>hhs_geo_region</th>\n",
       "      <th>census_msa</th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "      <th>employment_industry</th>\n",
       "      <th>employment_occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>oxchjgsf</td>\n",
       "      <td>Non-MSA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Employed</td>\n",
       "      <td>bhuqouqj</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pxcmvdjn</td>\n",
       "      <td>xgwztkwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;= $75,000, Above Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Employed</td>\n",
       "      <td>qufhixun</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rucpziij</td>\n",
       "      <td>xtkaffoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>lrircsnp</td>\n",
       "      <td>MSA, Principle City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;= $75,000, Above Poverty</td>\n",
       "      <td>Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Employed</td>\n",
       "      <td>qufhixun</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>wxleyezf</td>\n",
       "      <td>emcorrxb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26702</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;= $75,000, Above Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>qufhixun</td>\n",
       "      <td>Non-MSA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26703</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;= $75,000, Above Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Employed</td>\n",
       "      <td>lzgpxyit</td>\n",
       "      <td>MSA, Principle City</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fcxhlnwr</td>\n",
       "      <td>cmhcxjea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26704</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lzgpxyit</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26705</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;= $75,000, Above Poverty</td>\n",
       "      <td>Married</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Employed</td>\n",
       "      <td>lrircsnp</td>\n",
       "      <td>Non-MSA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fcxhlnwr</td>\n",
       "      <td>haliazsg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26706</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;= $75,000, Above Poverty</td>\n",
       "      <td>Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>mlyzmhmf</td>\n",
       "      <td>MSA, Principle City</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26707 rows × 37 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "y_h1n1_vacc_train"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "20417    0\n",
       "13969    0\n",
       "24930    1\n",
       "15420    0\n",
       "10998    1\n",
       "        ..\n",
       "17823    0\n",
       "10210    0\n",
       "7737     0\n",
       "12227    0\n",
       "26118    1\n",
       "Name: h1n1_vaccine, Length: 21365, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Creating concatenated training dataframe and separating into minority and majority class**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "# concatenating our train data back together\n",
    "\n",
    "concat_train_df = pd.concat([X_no_vacc_train, y_h1n1_vacc_train], axis = 1)\n",
    "\n",
    "# separating into minority and majority classes\n",
    "\n",
    "# majority class\n",
    "no_h1n1_vacc = concat_train_df[concat_train_df.h1n1_vaccine==0]\n",
    "\n",
    "# minority class\n",
    "yes_h1n1_vacc = concat_train_df[concat_train_df.h1n1_vaccine==1]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "no_h1n1_vacc"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\n",
       "20417           1.0             2.0                        0.0   \n",
       "13969           2.0             2.0                        0.0   \n",
       "15420           2.0             1.0                        0.0   \n",
       "2100            2.0             1.0                        0.0   \n",
       "5555            2.0             2.0                        0.0   \n",
       "...             ...             ...                        ...   \n",
       "5519            2.0             0.0                        0.0   \n",
       "17823           2.0             1.0                        0.0   \n",
       "10210           1.0             0.0                        0.0   \n",
       "7737            3.0             2.0                        0.0   \n",
       "12227           1.0             1.0                        0.0   \n",
       "\n",
       "       behavioral_avoidance  behavioral_face_mask  behavioral_wash_hands  \\\n",
       "20417                   1.0                   0.0                    0.0   \n",
       "13969                   1.0                   0.0                    1.0   \n",
       "15420                   0.0                   0.0                    1.0   \n",
       "2100                    1.0                   0.0                    1.0   \n",
       "5555                    1.0                   0.0                    1.0   \n",
       "...                     ...                   ...                    ...   \n",
       "5519                    0.0                   0.0                    0.0   \n",
       "17823                   1.0                   0.0                    1.0   \n",
       "10210                   1.0                   0.0                    1.0   \n",
       "7737                    1.0                   0.0                    1.0   \n",
       "12227                   1.0                   0.0                    1.0   \n",
       "\n",
       "       behavioral_large_gatherings  behavioral_outside_home  \\\n",
       "20417                          0.0                      0.0   \n",
       "13969                          0.0                      1.0   \n",
       "15420                          0.0                      0.0   \n",
       "2100                           0.0                      0.0   \n",
       "5555                           1.0                      1.0   \n",
       "...                            ...                      ...   \n",
       "5519                           0.0                      1.0   \n",
       "17823                          0.0                      1.0   \n",
       "10210                          0.0                      1.0   \n",
       "7737                           1.0                      1.0   \n",
       "12227                          0.0                      0.0   \n",
       "\n",
       "       behavioral_touch_face  doctor_recc_h1n1  ...  marital_status  \\\n",
       "20417                    0.0               0.0  ...         Married   \n",
       "13969                    1.0               1.0  ...     Not Married   \n",
       "15420                    0.0               NaN  ...         Married   \n",
       "2100                     1.0               0.0  ...     Not Married   \n",
       "5555                     1.0               1.0  ...     Not Married   \n",
       "...                      ...               ...  ...             ...   \n",
       "5519                     0.0               1.0  ...     Not Married   \n",
       "17823                    0.0               0.0  ...     Not Married   \n",
       "10210                    1.0               0.0  ...     Not Married   \n",
       "7737                     1.0               0.0  ...     Not Married   \n",
       "12227                    1.0               0.0  ...     Not Married   \n",
       "\n",
       "       rent_or_own   employment_status  hhs_geo_region  \\\n",
       "20417          Own            Employed        kbazzjca   \n",
       "13969          Own  Not in Labor Force        atmpeygn   \n",
       "15420          Own            Employed        qufhixun   \n",
       "2100          Rent            Employed        qufhixun   \n",
       "5555           Own            Employed        fpwskwrf   \n",
       "...            ...                 ...             ...   \n",
       "5519          Rent  Not in Labor Force        bhuqouqj   \n",
       "17823         Rent            Employed        fpwskwrf   \n",
       "10210          Own  Not in Labor Force        kbazzjca   \n",
       "7737           Own  Not in Labor Force        qufhixun   \n",
       "12227          Own            Employed        mlyzmhmf   \n",
       "\n",
       "                     census_msa  household_adults  household_children  \\\n",
       "20417  MSA, Not Principle  City               1.0                 1.0   \n",
       "13969  MSA, Not Principle  City               0.0                 0.0   \n",
       "15420  MSA, Not Principle  City               1.0                 2.0   \n",
       "2100        MSA, Principle City               0.0                 0.0   \n",
       "5555   MSA, Not Principle  City               1.0                 1.0   \n",
       "...                         ...               ...                 ...   \n",
       "5519   MSA, Not Principle  City               0.0                 0.0   \n",
       "17823                   Non-MSA               3.0                 0.0   \n",
       "10210                   Non-MSA               0.0                 0.0   \n",
       "7737                    Non-MSA               0.0                 0.0   \n",
       "12227       MSA, Principle City               0.0                 2.0   \n",
       "\n",
       "       employment_industry  employment_occupation  h1n1_vaccine  \n",
       "20417             haxffmxo               dcjcmpih             0  \n",
       "13969                  NaN                    NaN             0  \n",
       "15420             wxleyezf               emcorrxb             0  \n",
       "2100              atmlpfrs               xqwwgdyp             0  \n",
       "5555              qnlwzans               mxkfnird             0  \n",
       "...                    ...                    ...           ...  \n",
       "5519                   NaN                    NaN             0  \n",
       "17823             rucpziij               tfqavkke             0  \n",
       "10210                  NaN                    NaN             0  \n",
       "7737                   NaN                    NaN             0  \n",
       "12227             xicduogh               ccgxvspp             0  \n",
       "\n",
       "[16826 rows x 36 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h1n1_concern</th>\n",
       "      <th>h1n1_knowledge</th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>behavioral_outside_home</th>\n",
       "      <th>behavioral_touch_face</th>\n",
       "      <th>doctor_recc_h1n1</th>\n",
       "      <th>...</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>rent_or_own</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>hhs_geo_region</th>\n",
       "      <th>census_msa</th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "      <th>employment_industry</th>\n",
       "      <th>employment_occupation</th>\n",
       "      <th>h1n1_vaccine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20417</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Employed</td>\n",
       "      <td>kbazzjca</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>haxffmxo</td>\n",
       "      <td>dcjcmpih</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13969</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>atmpeygn</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15420</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Employed</td>\n",
       "      <td>qufhixun</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>wxleyezf</td>\n",
       "      <td>emcorrxb</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Employed</td>\n",
       "      <td>qufhixun</td>\n",
       "      <td>MSA, Principle City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>atmlpfrs</td>\n",
       "      <td>xqwwgdyp</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5555</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Employed</td>\n",
       "      <td>fpwskwrf</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>qnlwzans</td>\n",
       "      <td>mxkfnird</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5519</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>bhuqouqj</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17823</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Employed</td>\n",
       "      <td>fpwskwrf</td>\n",
       "      <td>Non-MSA</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rucpziij</td>\n",
       "      <td>tfqavkke</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10210</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>kbazzjca</td>\n",
       "      <td>Non-MSA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7737</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>qufhixun</td>\n",
       "      <td>Non-MSA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12227</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Employed</td>\n",
       "      <td>mlyzmhmf</td>\n",
       "      <td>MSA, Principle City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>xicduogh</td>\n",
       "      <td>ccgxvspp</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16826 rows × 36 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "yes_h1n1_vacc"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\n",
       "24930           2.0             2.0                        0.0   \n",
       "10998           2.0             1.0                        0.0   \n",
       "8967            2.0             2.0                        0.0   \n",
       "8720            0.0             2.0                        0.0   \n",
       "12152           2.0             1.0                        0.0   \n",
       "...             ...             ...                        ...   \n",
       "2240            3.0             2.0                        1.0   \n",
       "2132            1.0             2.0                        0.0   \n",
       "7138            2.0             2.0                        0.0   \n",
       "10195           2.0             2.0                        0.0   \n",
       "26118           1.0             1.0                        0.0   \n",
       "\n",
       "       behavioral_avoidance  behavioral_face_mask  behavioral_wash_hands  \\\n",
       "24930                   1.0                   1.0                    1.0   \n",
       "10998                   0.0                   0.0                    1.0   \n",
       "8967                    1.0                   0.0                    1.0   \n",
       "8720                    1.0                   0.0                    1.0   \n",
       "12152                   1.0                   0.0                    1.0   \n",
       "...                     ...                   ...                    ...   \n",
       "2240                    1.0                   1.0                    1.0   \n",
       "2132                    1.0                   0.0                    0.0   \n",
       "7138                    1.0                   0.0                    1.0   \n",
       "10195                   1.0                   1.0                    1.0   \n",
       "26118                   0.0                   1.0                    1.0   \n",
       "\n",
       "       behavioral_large_gatherings  behavioral_outside_home  \\\n",
       "24930                          0.0                      0.0   \n",
       "10998                          0.0                      0.0   \n",
       "8967                           1.0                      0.0   \n",
       "8720                           1.0                      0.0   \n",
       "12152                          1.0                      1.0   \n",
       "...                            ...                      ...   \n",
       "2240                           1.0                      1.0   \n",
       "2132                           1.0                      0.0   \n",
       "7138                           1.0                      1.0   \n",
       "10195                          1.0                      0.0   \n",
       "26118                          1.0                      0.0   \n",
       "\n",
       "       behavioral_touch_face  doctor_recc_h1n1  ...  marital_status  \\\n",
       "24930                    1.0               0.0  ...         Married   \n",
       "10998                    1.0               0.0  ...         Married   \n",
       "8967                     1.0               1.0  ...         Married   \n",
       "8720                     0.0               1.0  ...         Married   \n",
       "12152                    1.0               1.0  ...             NaN   \n",
       "...                      ...               ...  ...             ...   \n",
       "2240                     1.0               1.0  ...         Married   \n",
       "2132                     1.0               1.0  ...     Not Married   \n",
       "7138                     1.0               1.0  ...         Married   \n",
       "10195                    1.0               0.0  ...         Married   \n",
       "26118                    1.0               0.0  ...     Not Married   \n",
       "\n",
       "       rent_or_own   employment_status  hhs_geo_region  \\\n",
       "24930          Own            Employed        dqpwygqj   \n",
       "10998          Own  Not in Labor Force        atmpeygn   \n",
       "8967           Own  Not in Labor Force        bhuqouqj   \n",
       "8720           Own  Not in Labor Force        oxchjgsf   \n",
       "12152          NaN          Unemployed        bhuqouqj   \n",
       "...            ...                 ...             ...   \n",
       "2240           Own            Employed        dqpwygqj   \n",
       "2132           Own  Not in Labor Force        kbazzjca   \n",
       "7138           Own            Employed        qufhixun   \n",
       "10195          Own  Not in Labor Force        mlyzmhmf   \n",
       "26118          Own  Not in Labor Force        qufhixun   \n",
       "\n",
       "                     census_msa  household_adults  household_children  \\\n",
       "24930  MSA, Not Principle  City               2.0                 1.0   \n",
       "10998                   Non-MSA               1.0                 0.0   \n",
       "8967   MSA, Not Principle  City               1.0                 0.0   \n",
       "8720                    Non-MSA               1.0                 1.0   \n",
       "12152       MSA, Principle City               0.0                 0.0   \n",
       "...                         ...               ...                 ...   \n",
       "2240   MSA, Not Principle  City               3.0                 0.0   \n",
       "2132   MSA, Not Principle  City               0.0                 0.0   \n",
       "7138        MSA, Principle City               1.0                 1.0   \n",
       "10195       MSA, Principle City               1.0                 0.0   \n",
       "26118  MSA, Not Principle  City               0.0                 0.0   \n",
       "\n",
       "       employment_industry  employment_occupation  h1n1_vaccine  \n",
       "24930             fcxhlnwr               xtkaffoo             1  \n",
       "10998                  NaN                    NaN             1  \n",
       "8967                   NaN                    NaN             1  \n",
       "8720                   NaN                    NaN             1  \n",
       "12152                  NaN                    NaN             1  \n",
       "...                    ...                    ...           ...  \n",
       "2240              fcxhlnwr               cmhcxjea             1  \n",
       "2132                   NaN                    NaN             1  \n",
       "7138              arjwrbjb               kldqjyjy             1  \n",
       "10195                  NaN                    NaN             1  \n",
       "26118                  NaN                    NaN             1  \n",
       "\n",
       "[4539 rows x 36 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h1n1_concern</th>\n",
       "      <th>h1n1_knowledge</th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>behavioral_outside_home</th>\n",
       "      <th>behavioral_touch_face</th>\n",
       "      <th>doctor_recc_h1n1</th>\n",
       "      <th>...</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>rent_or_own</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>hhs_geo_region</th>\n",
       "      <th>census_msa</th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "      <th>employment_industry</th>\n",
       "      <th>employment_occupation</th>\n",
       "      <th>h1n1_vaccine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24930</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Employed</td>\n",
       "      <td>dqpwygqj</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fcxhlnwr</td>\n",
       "      <td>xtkaffoo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>atmpeygn</td>\n",
       "      <td>Non-MSA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8967</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>bhuqouqj</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8720</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>oxchjgsf</td>\n",
       "      <td>Non-MSA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12152</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>bhuqouqj</td>\n",
       "      <td>MSA, Principle City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2240</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Employed</td>\n",
       "      <td>dqpwygqj</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>fcxhlnwr</td>\n",
       "      <td>cmhcxjea</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>kbazzjca</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7138</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Employed</td>\n",
       "      <td>qufhixun</td>\n",
       "      <td>MSA, Principle City</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>arjwrbjb</td>\n",
       "      <td>kldqjyjy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10195</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>mlyzmhmf</td>\n",
       "      <td>MSA, Principle City</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26118</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>qufhixun</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4539 rows × 36 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**1. Oversampling of the minority class (upsampling)**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "#upsample minority class\n",
    "yes_h1n1_vacc_upsampled = resample(yes_h1n1_vacc,\n",
    "                                   replace = True,\n",
    "                                   n_samples = len(no_h1n1_vacc),\n",
    "                                   random_state = RSEED)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "# combine majority and upsampled minority\n",
    "\n",
    "upsampled = pd.concat([no_h1n1_vacc, yes_h1n1_vacc_upsampled])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "# checking new class counts\n",
    "upsampled.h1n1_vaccine.value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    16826\n",
       "1    16826\n",
       "Name: h1n1_vaccine, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "# relabelling the upsampled data as train dataset\n",
    "\n",
    "y_h1n1_vacc_upsamp_train = upsampled.h1n1_vaccine\n",
    "\n",
    "X_no_vacc_upsamp_train =upsampled.drop('h1n1_vaccine', axis = 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**2. Undersampling of majority class (downsampling)**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "source": [
    "# downsample minority class\n",
    "no_h1n1_vacc_downsampled = resample(no_h1n1_vacc,\n",
    "                                   replace = False,\n",
    "                                   n_samples = len(yes_h1n1_vacc),\n",
    "                                   random_state = RSEED)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "source": [
    "# combine minority and downsampled majority\n",
    "\n",
    "downsampled = pd.concat([no_h1n1_vacc_downsampled, yes_h1n1_vacc])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "source": [
    "# checking new class counts\n",
    "downsampled.h1n1_vaccine.value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    4539\n",
       "1    4539\n",
       "Name: h1n1_vaccine, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 141
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "source": [
    "# relabelling the downsampled data as train dataset\n",
    "\n",
    "y_h1n1_vacc_downsamp_train = downsampled.h1n1_vaccine\n",
    "\n",
    "X_no_vacc_downsamp_train =downsampled.drop('h1n1_vaccine', axis = 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**3. Generate synthetic samples (SMOTE)**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "source": [
    "sm = SMOTE(random_state=27, sampling_strategy=1.0)\n",
    "#X_no_vacc_train, X_no_vacc_test, y_h1n1_vacc_train, y_h1n1_vacc_test = train_test_split(X_no_vacc, y_h1n1_vacc, stratify = y_h1n1_vacc, test_size=0.2, random_state=RSEED)\n",
    "X_no_vacc_sm_train, y_h1n1_vacc_sm_train = sm.fit_resample(X_no_vacc_train, y_h1n1_vacc_train)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "could not convert string to float: '18 - 34 Years'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wg/qvgqr4_90653dyqmcf1s20lw0000gn/T/ipykernel_5142/2002681335.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m27\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#X_no_vacc_train, X_no_vacc_test, y_h1n1_vacc_train, y_h1n1_vacc_test = train_test_split(X_no_vacc, y_h1n1_vacc, stratify = y_h1n1_vacc, test_size=0.2, random_state=RSEED)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_no_vacc_sm_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_h1n1_vacc_sm_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_no_vacc_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_h1n1_vacc_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0marrays_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         self.sampling_strategy_ = check_sampling_strategy(\n",
      "\u001b[0;32m~/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[0;34m(self, X, y, accept_sparse)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0maccept_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicate_one_vs_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[1;32m    872\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    671\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order, like)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1898\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m     def __array_wrap__(\n",
      "\u001b[0;32m~/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order, like)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '18 - 34 Years'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "No resampling:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for logreg\n",
    "logreg_unilabel_no_vacc = logreg_unilabel_pipeline.fit(X_no_vacc_train, y_h1n1_vacc_train)\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_no_vacc = knn_unilabel_pipeline.fit(X_no_vacc_train, y_h1n1_vacc_train)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_unilabel_no_vacc = rand_forst_unilabel_pipeline.fit(X_no_vacc_train, y_h1n1_vacc_train)\n",
    "\n",
    "#for SVM\n",
    "svm_unilabel_no_vacc = svm_unilabel_pipeline.fit(X_no_vacc_train, y_h1n1_vacc_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For upsampled data: "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "# for logreg\n",
    "logreg_unilabel_no_vacc_upsamp = logreg_unilabel_pipeline.fit(X_no_vacc_upsamp_train, y_h1n1_vacc_upsamp_train)\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_no_vacc_upsamp = knn_unilabel_pipeline.fit(X_no_vacc_upsamp_train, y_h1n1_vacc_upsamp_train)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_unilabel_no_vacc_upsamp = rand_forst_unilabel_pipeline.fit(X_no_vacc_upsamp_train, y_h1n1_vacc_upsamp_train)\n",
    "\n",
    "#for SVM\n",
    "svm_unilabel_no_vacc_upsamp = svm_unilabel_pipeline.fit(X_no_vacc_upsamp_train, y_h1n1_vacc_upsamp_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For downsampled data:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "source": [
    "# for logreg\n",
    "logreg_unilabel_no_vacc_downsamp = logreg_unilabel_pipeline.fit(X_no_vacc_downsamp_train, y_h1n1_vacc_downsamp_train)\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_no_vacc_downsamp = knn_unilabel_pipeline.fit(X_no_vacc_downsamp_train, y_h1n1_vacc_downsamp_train)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_unilabel_no_vacc_downsamp = rand_forst_unilabel_pipeline.fit(X_no_vacc_downsamp_train, y_h1n1_vacc_downsamp_train)\n",
    "\n",
    "#for SVM\n",
    "svm_unilabel_no_vacc_downsamp = svm_unilabel_pipeline.fit(X_no_vacc_downsamp_train, y_h1n1_vacc_downsamp_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Figure out later what this does and if we want to use it\n",
    "\n",
    "\n",
    "#y_train_predicted = cross_val_predict(full_pipeline, X_train, y_train, cv=5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Making predictions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Making predictions based on train and test data:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "No resampling:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "# for logreg\n",
    "logreg_unilabel_no_vacc_trainpreds = logreg_unilabel_no_vacc.predict(X_no_vacc_train)\n",
    "logreg_unilabel_no_vacc_testpreds = logreg_unilabel_no_vacc.predict(X_no_vacc_test)\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_no_vacc_trainpreds = knn_unilabel_no_vacc.predict(X_no_vacc_train)\n",
    "knn_unilabel_no_vacc_testpreds = knn_unilabel_no_vacc.predict(X_no_vacc_test)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_unilabel_no_vacc_trainpreds = rand_forst_unilabel_no_vacc.predict(X_no_vacc_train)\n",
    "rand_forst_unilabel_no_vacc_testpreds = rand_forst_unilabel_no_vacc.predict(X_no_vacc_test)\n",
    "\n",
    "# for SVM\n",
    "svm_unilabel_no_vacc_trainpreds = svm_unilabel_no_vacc.predict(X_no_vacc_train)\n",
    "svm_unilabel_no_vacc_testpreds = svm_unilabel_no_vacc.predict(X_no_vacc_test)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'logreg_unilabel_no_vacc' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wg/qvgqr4_90653dyqmcf1s20lw0000gn/T/ipykernel_5142/410005391.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# for logreg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlogreg_unilabel_no_vacc_trainpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogreg_unilabel_no_vacc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_no_vacc_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlogreg_unilabel_no_vacc_testpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogreg_unilabel_no_vacc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_no_vacc_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# for KNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logreg_unilabel_no_vacc' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Upsampling:\n",
    "\n",
    "FOR MAKING PREDICTIONS FROM THE TRAIN DATASET...WE MAKE THEM ON THE TEST DATASET WITHOUT THE UPSAMPLING, RIGHT?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "# for logreg\n",
    "logreg_unilabel_no_vacc_upsamp_trainpreds = logreg_unilabel_no_vacc_upsamp.predict(X_no_vacc_train)\n",
    "logreg_unilabel_no_vacc_upsamp_testpreds = logreg_unilabel_no_vacc_upsamp.predict(X_no_vacc_test)\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_no_vacc_upsamp_trainpreds = knn_unilabel_no_vacc_upsamp.predict(X_no_vacc_train)\n",
    "knn_unilabel_no_vacc_upsamp_testpreds = knn_unilabel_no_vacc_upsamp.predict(X_no_vacc_test)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_unilabel_no_vacc_upsamp_trainpreds = rand_forst_unilabel_no_vacc_upsamp.predict(X_no_vacc_train)\n",
    "rand_forst_unilabel_no_vacc_upsamp_testpreds = rand_forst_unilabel_no_vacc_upsamp.predict(X_no_vacc_test)\n",
    "\n",
    "# for SVM\n",
    "svm_unilabel_no_vacc_upsamp_trainpreds = svm_unilabel_no_vacc_upsamp.predict(X_no_vacc_train)\n",
    "svm_unilabel_no_vacc_upsamp_testpreds = svm_unilabel_no_vacc_upsamp.predict(X_no_vacc_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For downsampling:\n",
    "\n",
    "FOR MAKING PREDICTIONS FROM THE TRAIN DATASET...WE MAKE THEM ON THE TEST DATASET WITHOUT THE DOWNSAMPLING, RIGHT?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "source": [
    "# for logreg\n",
    "logreg_unilabel_no_vacc_downsamp_trainpreds = logreg_unilabel_no_vacc_downsamp.predict(X_no_vacc_train)\n",
    "logreg_unilabel_no_vacc_downsamp_testpreds = logreg_unilabel_no_vacc_downsamp.predict(X_no_vacc_test)\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_no_vacc_downsamp_trainpreds = knn_unilabel_no_vacc_downsamp.predict(X_no_vacc_train)\n",
    "knn_unilabel_no_vacc_downsamp_testpreds = knn_unilabel_no_vacc_downsamp.predict(X_no_vacc_test)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_unilabel_no_vacc_downsamp_trainpreds = rand_forst_unilabel_no_vacc_downsamp.predict(X_no_vacc_train)\n",
    "rand_forst_unilabel_no_vacc_downsamp_testpreds = rand_forst_unilabel_no_vacc_downsamp.predict(X_no_vacc_test)\n",
    "\n",
    "# for SVM\n",
    "svm_unilabel_no_vacc_downsamp_trainpreds = svm_unilabel_no_vacc_downsamp.predict(X_no_vacc_train)\n",
    "svm_unilabel_no_vacc_downsamp_testpreds = svm_unilabel_no_vacc_downsamp.predict(X_no_vacc_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model evaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train data--no resampling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Logreg--Train data evaluation Metrics\n",
    "h1n1_logreg_unilabel_no_vacc_train_acc = accuracy_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_trainpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_train_recall = recall_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_trainpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_train_precision = precision_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_trainpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_train_f1 = f1_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_trainpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_train_roc = roc_auc_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_trainpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# KNN--Train data evaluation Metrics\n",
    "h1n1_knn_unilabel_no_vacc_train_acc = accuracy_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_trainpreds)\n",
    "h1n1_knn_unilabel_no_vacc_train_recall = recall_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_trainpreds)\n",
    "h1n1_knn_unilabel_no_vacc_train_precision = precision_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_trainpreds)\n",
    "h1n1_knn_unilabel_no_vacc_train_f1 = f1_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_trainpreds)\n",
    "h1n1_knn_unilabel_no_vacc_train_roc = roc_auc_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_trainpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Random Forest--Train data evaluation Metrics\n",
    "#check if these metrics are changing compared to previous results\n",
    "h1n1_rand_forst_unilabel_no_vacc_train_acc = accuracy_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_train_recall = recall_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_train_precision = precision_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_train_f1 = f1_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_train_roc = roc_auc_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SVM--Train data evaluation Metrics\n",
    "h1n1_svm_unilabel_no_vacc_train_acc = accuracy_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_trainpreds)\n",
    "h1n1_svm_unilabel_no_vacc_train_recall = recall_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_trainpreds)\n",
    "h1n1_svm_unilabel_no_vacc_train_precision = precision_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_trainpreds)\n",
    "h1n1_svm_unilabel_no_vacc_train_f1 = f1_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_trainpreds)\n",
    "h1n1_svm_unilabel_no_vacc_train_roc = roc_auc_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_trainpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Test data--no resampling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Logreg--Test data evaluation Metrics\n",
    "h1n1_logreg_unilabel_no_vacc_test_acc = accuracy_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_testpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_test_recall = recall_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_testpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_test_precision = precision_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_testpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_test_f1 = f1_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_testpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_test_roc = roc_auc_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_testpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# KNN--Test data evaluation Metrics\n",
    "h1n1_knn_unilabel_no_vacc_test_acc = accuracy_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_testpreds)\n",
    "h1n1_knn_unilabel_no_vacc_test_recall = recall_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_testpreds)\n",
    "h1n1_knn_unilabel_no_vacc_test_precision = precision_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_testpreds)\n",
    "h1n1_knn_unilabel_no_vacc_test_f1 = f1_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_testpreds)\n",
    "h1n1_knn_unilabel_no_vacc_test_roc = roc_auc_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_testpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Random Forest--Test data evaluation Metrics\n",
    "#check if these metrics are changing compared to previous results\n",
    "h1n1_rand_forst_unilabel_no_vacc_test_acc = accuracy_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_testpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_test_recall = recall_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_testpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_test_precision = precision_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_testpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_test_f1 = f1_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_testpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_test_roc = roc_auc_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_testpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SVM--Test data evaluation Metrics\n",
    "h1n1_svm_unilabel_no_vacc_test_acc = accuracy_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_testpreds)\n",
    "h1n1_svm_unilabel_no_vacc_test_recall = recall_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_testpreds)\n",
    "h1n1_svm_unilabel_no_vacc_test_precision = precision_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_testpreds)\n",
    "h1n1_svm_unilabel_no_vacc_test_f1 = f1_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_testpreds)\n",
    "h1n1_svm_unilabel_no_vacc_test_roc = roc_auc_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_testpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train data--upsampling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "# Logreg--Train data evaluation Metrics\n",
    "h1n1_logreg_unilabel_no_vacc_upsamp_train_acc = accuracy_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_upsamp_trainpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_upsamp_train_recall = recall_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_upsamp_trainpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_upsamp_train_precision = precision_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_upsamp_trainpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_upsamp_train_f1 = f1_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_upsamp_trainpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_upsamp_train_roc = roc_auc_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_upsamp_trainpreds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "# KNN--Train data evaluation Metrics\n",
    "h1n1_knn_unilabel_no_vacc_upsamp_train_acc = accuracy_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_upsamp_trainpreds)\n",
    "h1n1_knn_unilabel_no_vacc_upsamp_train_recall = recall_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_upsamp_trainpreds)\n",
    "h1n1_knn_unilabel_no_vacc_upsamp_train_precision = precision_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_upsamp_trainpreds)\n",
    "h1n1_knn_unilabel_no_vacc_upsamp_train_f1 = f1_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_upsamp_trainpreds)\n",
    "h1n1_knn_unilabel_no_vacc_upsamp_train_roc = roc_auc_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_upsamp_trainpreds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "# Random Forest--Train data evaluation Metrics\n",
    "#check if these metrics are changing compared to previous results\n",
    "h1n1_rand_forst_unilabel_no_vacc_upsamp_train_acc = accuracy_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_upsamp_trainpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_upsamp_train_recall = recall_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_upsamp_trainpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_upsamp_train_precision = precision_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_upsamp_trainpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_upsamp_train_f1 = f1_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_upsamp_trainpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_upsamp_train_roc = roc_auc_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_upsamp_trainpreds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "# SVM--Train data evaluation Metrics\n",
    "h1n1_svm_unilabel_no_vacc_upsamp_train_acc = accuracy_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_upsamp_trainpreds)\n",
    "h1n1_svm_unilabel_no_vacc_upsamp_train_recall = recall_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_upsamp_trainpreds)\n",
    "h1n1_svm_unilabel_no_vacc_upsamp_train_precision = precision_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_upsamp_trainpreds)\n",
    "h1n1_svm_unilabel_no_vacc_upsamp_train_f1 = f1_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_upsamp_trainpreds)\n",
    "h1n1_svm_unilabel_no_vacc_upsamp_train_roc = roc_auc_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_upsamp_trainpreds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Test data--upsampling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "# Logreg--Test data evaluation Metrics\n",
    "h1n1_logreg_unilabel_no_vacc_upsamp_test_acc = accuracy_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_upsamp_testpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_upsamp_test_recall = recall_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_upsamp_testpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_upsamp_test_precision = precision_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_upsamp_testpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_upsamp_test_f1 = f1_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_upsamp_testpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_upsamp_test_roc = roc_auc_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_upsamp_testpreds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "# KNN--Test data evaluation Metrics\n",
    "h1n1_knn_unilabel_no_vacc_upsamp_test_acc = accuracy_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_upsamp_testpreds)\n",
    "h1n1_knn_unilabel_no_vacc_upsamp_test_recall = recall_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_upsamp_testpreds)\n",
    "h1n1_knn_unilabel_no_vacc_upsamp_test_precision = precision_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_upsamp_testpreds)\n",
    "h1n1_knn_unilabel_no_vacc_upsamp_test_f1 = f1_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_upsamp_testpreds)\n",
    "h1n1_knn_unilabel_no_vacc_upsamp_test_roc = roc_auc_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_upsamp_testpreds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "source": [
    "# Random Forest--Test data evaluation Metrics\n",
    "#check if these metrics are changing compared to previous results\n",
    "h1n1_rand_forst_unilabel_no_vacc_upsamp_test_acc = accuracy_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_upsamp_testpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_upsamp_test_recall = recall_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_upsamp_testpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_upsamp_test_precision = precision_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_upsamp_testpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_upsamp_test_f1 = f1_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_upsamp_testpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_upsamp_test_roc = roc_auc_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_upsamp_testpreds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "source": [
    "# SVM--Train data evaluation Metrics\n",
    "h1n1_svm_unilabel_no_vacc_upsamp_test_acc = accuracy_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_upsamp_testpreds)\n",
    "h1n1_svm_unilabel_no_vacc_upsamp_test_recall = recall_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_upsamp_testpreds)\n",
    "h1n1_svm_unilabel_no_vacc_upsamp_test_precision = precision_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_upsamp_testpreds)\n",
    "h1n1_svm_unilabel_no_vacc_upsamp_test_f1 = f1_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_upsamp_testpreds)\n",
    "h1n1_svm_unilabel_no_vacc_upsamp_test_roc = roc_auc_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_upsamp_testpreds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Train data--downsampling**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "source": [
    "# Logreg--Train data evaluation Metrics\n",
    "h1n1_logreg_unilabel_no_vacc_downsamp_train_acc = accuracy_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_downsamp_trainpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_downsamp_train_recall = recall_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_downsamp_trainpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_downsamp_train_precision = precision_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_downsamp_trainpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_downsamp_train_f1 = f1_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_downsamp_trainpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_downsamp_train_roc = roc_auc_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_downsamp_trainpreds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "source": [
    "# KNN--Train data evaluation Metrics\n",
    "h1n1_knn_unilabel_no_vacc_downsamp_train_acc = accuracy_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_downsamp_trainpreds)\n",
    "h1n1_knn_unilabel_no_vacc_downsamp_train_recall = recall_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_downsamp_trainpreds)\n",
    "h1n1_knn_unilabel_no_vacc_downsamp_train_precision = precision_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_downsamp_trainpreds)\n",
    "h1n1_knn_unilabel_no_vacc_downsamp_train_f1 = f1_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_downsamp_trainpreds)\n",
    "h1n1_knn_unilabel_no_vacc_downsamp_train_roc = roc_auc_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_downsamp_trainpreds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "source": [
    "# Random Forest--Train data evaluation Metrics\n",
    "#check if these metrics are changing compared to previous results\n",
    "h1n1_rand_forst_unilabel_no_vacc_downsamp_train_acc = accuracy_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_downsamp_trainpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_downsamp_train_recall = recall_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_downsamp_trainpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_downsamp_train_precision = precision_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_downsamp_trainpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_downsamp_train_f1 = f1_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_downsamp_trainpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_downsamp_train_roc = roc_auc_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_downsamp_trainpreds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "source": [
    "# SVM--Train data evaluation Metrics\n",
    "h1n1_svm_unilabel_no_vacc_downsamp_train_acc = accuracy_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_downsamp_trainpreds)\n",
    "h1n1_svm_unilabel_no_vacc_downsamp_train_recall = recall_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_downsamp_trainpreds)\n",
    "h1n1_svm_unilabel_no_vacc_downsamp_train_precision = precision_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_downsamp_trainpreds)\n",
    "h1n1_svm_unilabel_no_vacc_downsamp_train_f1 = f1_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_downsamp_trainpreds)\n",
    "h1n1_svm_unilabel_no_vacc_downsamp_train_roc = roc_auc_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_downsamp_trainpreds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Test data--downsampling**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "source": [
    "# Logreg--Test data evaluation Metrics\n",
    "h1n1_logreg_unilabel_no_vacc_downsamp_test_acc = accuracy_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_downsamp_testpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_downsamp_test_recall = recall_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_downsamp_testpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_downsamp_test_precision = precision_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_downsamp_testpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_downsamp_test_f1 = f1_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_downsamp_testpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_downsamp_test_roc = roc_auc_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_downsamp_testpreds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "source": [
    "# KNN--Test data evaluation Metrics\n",
    "h1n1_knn_unilabel_no_vacc_downsamp_test_acc = accuracy_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_downsamp_testpreds)\n",
    "h1n1_knn_unilabel_no_vacc_downsamp_test_recall = recall_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_downsamp_testpreds)\n",
    "h1n1_knn_unilabel_no_vacc_downsamp_test_precision = precision_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_downsamp_testpreds)\n",
    "h1n1_knn_unilabel_no_vacc_downsamp_test_f1 = f1_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_downsamp_testpreds)\n",
    "h1n1_knn_unilabel_no_vacc_downsamp_test_roc = roc_auc_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_downsamp_testpreds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "source": [
    "# Random Forest--Test data evaluation Metrics\n",
    "#check if these metrics are changing compared to previous results\n",
    "h1n1_rand_forst_unilabel_no_vacc_downsamp_test_acc = accuracy_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_downsamp_testpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_downsamp_test_recall = recall_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_downsamp_testpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_downsamp_test_precision = precision_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_downsamp_testpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_downsamp_test_f1 = f1_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_downsamp_testpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_downsamp_test_roc = roc_auc_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_downsamp_testpreds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "source": [
    "# SVM--Train data evaluation Metrics\n",
    "h1n1_svm_unilabel_no_vacc_downsamp_test_acc = accuracy_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_downsamp_testpreds)\n",
    "h1n1_svm_unilabel_no_vacc_downsamp_test_recall = recall_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_downsamp_testpreds)\n",
    "h1n1_svm_unilabel_no_vacc_downsamp_test_precision = precision_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_downsamp_testpreds)\n",
    "h1n1_svm_unilabel_no_vacc_downsamp_test_f1 = f1_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_downsamp_testpreds)\n",
    "h1n1_svm_unilabel_no_vacc_downsamp_test_roc = roc_auc_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_downsamp_testpreds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tracking the model with MLFlow"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### H1N1 vaccine output"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Logistic regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "*No resampling*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_h1n1) #this needs to be adjusted for each experiment\n",
    "name = 'logreg_unilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_logreg_unilabel_no_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_logreg_unilabel_no_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_logreg_unilabel_no_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_logreg_unilabel_no_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_logreg_unilabel_no_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_logreg_unilabel_no_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_logreg_unilabel_no_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_logreg_unilabel_no_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_logreg_unilabel_no_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_logreg_unilabel_no_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Upsampling*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_h1n1) #this needs to be adjusted for each experiment\n",
    "name = 'logreg_unilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Active run_id: 194ca524566844758e23a807eeb6f9c7\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"Upsampling\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_logreg_unilabel_no_vacc_upsamp_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_logreg_unilabel_no_vacc_upsamp_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_logreg_unilabel_no_vacc_upsamp_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_logreg_unilabel_no_vacc_upsamp_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_logreg_unilabel_no_vacc_upsamp_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_logreg_unilabel_no_vacc_upsamp_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_logreg_unilabel_no_vacc_upsamp_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_logreg_unilabel_no_vacc_upsamp_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_logreg_unilabel_no_vacc_upsamp_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_logreg_unilabel_no_vacc_upsamp_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Downsampling*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_h1n1) #this needs to be adjusted for each experiment\n",
    "name = 'logreg_unilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()\n",
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Active run_id: 506787a9e0134fb9bbc6911aa9bbb96d\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"Downsampling\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_logreg_unilabel_no_vacc_downsamp_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_logreg_unilabel_no_vacc_downsamp_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_logreg_unilabel_no_vacc_downsamp_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_logreg_unilabel_no_vacc_downsamp_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_logreg_unilabel_no_vacc_downsamp_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_logreg_unilabel_no_vacc_downsamp_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_logreg_unilabel_no_vacc_downsamp_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_logreg_unilabel_no_vacc_downsamp_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_logreg_unilabel_no_vacc_downsamp_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_logreg_unilabel_no_vacc_downsamp_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### KNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "*No resampling*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_h1n1)\n",
    "name = 'knn_unilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_knn_unilabel_no_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_knn_unilabel_no_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_knn_unilabel_no_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_knn_unilabel_no_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_knn_unilabel_no_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_knn_unilabel_no_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_knn_unilabel_no_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_knn_unilabel_no_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_knn_unilabel_no_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_knn_unilabel_no_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Upsampling*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_h1n1)\n",
    "name = 'knn_unilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()\n",
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Active run_id: 3e7eb1f3f7e64b6b9e264bf70b859318\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"Upsampling\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_knn_unilabel_no_vacc_upsamp_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_knn_unilabel_no_vacc_upsamp_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_knn_unilabel_no_vacc_upsamp_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_knn_unilabel_no_vacc_upsamp_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_knn_unilabel_no_vacc_upsamp_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_knn_unilabel_no_vacc_upsamp_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_knn_unilabel_no_vacc_upsamp_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_knn_unilabel_no_vacc_upsamp_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_knn_unilabel_no_vacc_upsamp_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_knn_unilabel_no_vacc_upsamp_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Downsampling*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_h1n1)\n",
    "name = 'knn_unilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()\n",
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Active run_id: 9d9c8e3067f6409db02d21af944ee334\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"Downsampling\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_knn_unilabel_no_vacc_downsamp_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_knn_unilabel_no_vacc_downsamp_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_knn_unilabel_no_vacc_downsamp_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_knn_unilabel_no_vacc_downsamp_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_knn_unilabel_no_vacc_downsamp_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_knn_unilabel_no_vacc_downsamp_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_knn_unilabel_no_vacc_downsamp_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_knn_unilabel_no_vacc_downsamp_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_knn_unilabel_no_vacc_downsamp_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_knn_unilabel_no_vacc_downsamp_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "*No resampling*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_h1n1)\n",
    "name = 'rand_forst_unilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_rand_forst_unilabel_no_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_rand_forst_unilabel_no_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_rand_forst_unilabel_no_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_rand_forst_unilabel_no_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_rand_forst_unilabel_no_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_rand_forst_unilabel_no_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_rand_forst_unilabel_no_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_rand_forst_unilabel_no_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_rand_forst_unilabel_no_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_rand_forst_unilabel_no_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Upsampling*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_h1n1)\n",
    "name = 'rand_forst_unilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()\n",
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Active run_id: 538ec529bcc94de39ec7501dcc9a2047\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"Upsampling\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_rand_forst_unilabel_no_vacc_upsamp_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_rand_forst_unilabel_no_vacc_upsamp_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_rand_forst_unilabel_no_vacc_upsamp_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_rand_forst_unilabel_no_vacc_upsamp_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_rand_forst_unilabel_no_vacc_upsamp_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_rand_forst_unilabel_no_vacc_upsamp_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_rand_forst_unilabel_no_vacc_upsamp_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_rand_forst_unilabel_no_vacc_upsamp_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_rand_forst_unilabel_no_vacc_upsamp_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_rand_forst_unilabel_no_vacc_upsamp_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Downsampling*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_h1n1)\n",
    "name = 'rand_forst_unilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()\n",
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Active run_id: c82bd0d4012f4c948e4bd44e6d9a7e78\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"Downsampling\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_rand_forst_unilabel_no_vacc_downsamp_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_rand_forst_unilabel_no_vacc_downsamp_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_rand_forst_unilabel_no_vacc_downsamp_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_rand_forst_unilabel_no_vacc_downsamp_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_rand_forst_unilabel_no_vacc_downsamp_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_rand_forst_unilabel_no_vacc_downsamp_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_rand_forst_unilabel_no_vacc_downsamp_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_rand_forst_unilabel_no_vacc_downsamp_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_rand_forst_unilabel_no_vacc_downsamp_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_rand_forst_unilabel_no_vacc_downsamp_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### SVM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "*No resampling*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_h1n1)\n",
    "name = 'svm_unilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_svm_unilabel_no_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_svm_unilabel_no_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_svm_unilabel_no_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_svm_unilabel_no_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_svm_unilabel_no_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_svm_unilabel_no_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_svm_unilabel_no_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_svm_unilabel_no_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_svm_unilabel_no_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_svm_unilabel_no_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Upsampling*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_h1n1)\n",
    "name = 'svm_unilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()\n",
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Active run_id: 1846c3394bae4322a1b3251fa7a4f55d\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"Upsampling\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_svm_unilabel_no_vacc_upsamp_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_svm_unilabel_no_vacc_upsamp_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_svm_unilabel_no_vacc_upsamp_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_svm_unilabel_no_vacc_upsamp_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_svm_unilabel_no_vacc_upsamp_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_svm_unilabel_no_vacc_upsamp_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_svm_unilabel_no_vacc_upsamp_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_svm_unilabel_no_vacc_upsamp_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_svm_unilabel_no_vacc_upsamp_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_svm_unilabel_no_vacc_upsamp_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Downsampling*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_h1n1)\n",
    "name = 'svm_unilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()\n",
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Active run_id: 95b79642703a4e289b1b8635a0073505\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"Downsampling\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_svm_unilabel_no_vacc_downsamp_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_svm_unilabel_no_vacc_downsamp_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_svm_unilabel_no_vacc_downsamp_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_svm_unilabel_no_vacc_downsamp_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_svm_unilabel_no_vacc_downsamp_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_svm_unilabel_no_vacc_downsamp_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_svm_unilabel_no_vacc_downsamp_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_svm_unilabel_no_vacc_downsamp_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_svm_unilabel_no_vacc_downsamp_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_svm_unilabel_no_vacc_downsamp_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Single Label Modelling, output H1N1 vaccine -> Seasonal Flu Vaccine is in features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The y_h1n1_vacc remains the same from the previous model; the X feature and cat_features (for the preprocessor) need to be adjusted:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cat_features_seas_vacc = cat_features.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cat_features_seas_vacc.remove('h1n1_vaccine')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#NB: dropping the 'h1n1_vaccine' and 'seasonal_vaccine' columns\n",
    "X_seas_vacc = df.drop(columns=['h1n1_vaccine'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_seas_vacc.columns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Performing test-train split (the same data can be used for each model in multilabelling):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_seas_vacc_train, X_seas_vacc_test, y_h1n1_vacc_train, y_h1n1_vacc_test = train_test_split(X_seas_vacc, y_h1n1_vacc, stratify = y_h1n1_vacc, test_size=0.2, random_state=RSEED)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('X_seas_vacc_train shape:', X_seas_vacc_train.shape)\n",
    "print('X_seas_vacc_test shape:', X_seas_vacc_test.shape)\n",
    "print('y_h1n1_vacc_train:', y_h1n1_vacc_train.shape)\n",
    "print('y_h1n1_vacc_test:', y_h1n1_vacc_test.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preprocessor is adjusted:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "preprocessor_seas_vacc = ColumnTransformer([\n",
    "    ('cat', cat_pipeline, cat_features_seas_vacc)\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pipeline is adjusted:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for logreg\n",
    "logreg_seas_vacc_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_seas_vacc),\n",
    "    (\"estimators\", logreg),\n",
    "])\n",
    "\n",
    "# for KNN\n",
    "knn_seas_vacc_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_seas_vacc),\n",
    "    (\"estimators\", knn),\n",
    "])\n",
    "\n",
    "# for Random Forest\n",
    "\n",
    "rand_forst_seas_vacc_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_seas_vacc),\n",
    "    (\"estimators\", rand_forst),\n",
    "])\n",
    "\n",
    "#for SVM\n",
    "svm_seas_vacc_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_seas_vacc),\n",
    "    (\"estimators\", svm),\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training the models:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for logreg\n",
    "logreg_unilabel_seas_vacc = logreg_seas_vacc_unilabel_pipeline.fit(X_seas_vacc_train, y_h1n1_vacc_train)\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_seas_vacc = knn_seas_vacc_unilabel_pipeline.fit(X_seas_vacc_train, y_h1n1_vacc_train)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_unilabel_seas_vacc = rand_forst_seas_vacc_unilabel_pipeline.fit(X_seas_vacc_train, y_h1n1_vacc_train)\n",
    "\n",
    "#for SVM\n",
    "svm_unilabel_seas_vacc = svm_seas_vacc_unilabel_pipeline.fit(X_seas_vacc_train, y_h1n1_vacc_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Figure out later what this does and if we want to use it\n",
    "\n",
    "\n",
    "#y_train_predicted = cross_val_predict(full_pipeline, X_train, y_train, cv=5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Making predictions based on train and test data:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for logreg\n",
    "logreg_unilabel_seas_vacc_trainpreds = logreg_unilabel_seas_vacc.predict(X_seas_vacc_train)\n",
    "logreg_unilabel_seas_vacc_testpreds = logreg_unilabel_seas_vacc.predict(X_seas_vacc_test)\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_seas_vacc_trainpreds = knn_unilabel_seas_vacc.predict(X_seas_vacc_train)\n",
    "knn_unilabel_seas_vacc_testpreds = knn_unilabel_seas_vacc.predict(X_seas_vacc_test)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_unilabel_seas_vacc_trainpreds = rand_forst_unilabel_seas_vacc.predict(X_seas_vacc_train)\n",
    "rand_forst_unilabel_seas_vacc_testpreds = rand_forst_unilabel_seas_vacc.predict(X_seas_vacc_test)\n",
    "\n",
    "# for SVM\n",
    "svm_unilabel_seas_vacc_trainpreds = svm_unilabel_seas_vacc.predict(X_seas_vacc_train)\n",
    "svm_unilabel_seas_vacc_testpreds = svm_unilabel_seas_vacc.predict(X_seas_vacc_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model evaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Logreg--Train data evaluation Metrics\n",
    "h1n1_logreg_unilabel_seas_vacc_train_acc = accuracy_score(y_h1n1_vacc_train, logreg_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_logreg_unilabel_seas_vacc_train_recall = recall_score(y_h1n1_vacc_train, logreg_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_logreg_unilabel_seas_vacc_train_precision = precision_score(y_h1n1_vacc_train, logreg_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_logreg_unilabel_seas_vacc_train_f1 = f1_score(y_h1n1_vacc_train, logreg_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_logreg_unilabel_seas_vacc_train_roc = roc_auc_score(y_h1n1_vacc_train, logreg_unilabel_seas_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_train, logreg_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_train, logreg_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_train, logreg_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_train, logreg_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_train, logreg_unilabel_seas_vacc_trainpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# KNN--Train data evaluation Metrics\n",
    "h1n1_knn_unilabel_seas_vacc_train_acc = accuracy_score(y_h1n1_vacc_train, knn_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_knn_unilabel_seas_vacc_train_recall = recall_score(y_h1n1_vacc_train, knn_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_knn_unilabel_seas_vacc_train_precision = precision_score(y_h1n1_vacc_train, knn_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_knn_unilabel_seas_vacc_train_f1 = f1_score(y_h1n1_vacc_train, knn_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_knn_unilabel_seas_vacc_train_roc = roc_auc_score(y_h1n1_vacc_train, knn_unilabel_seas_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_train, knn_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_train, knn_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_train, knn_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_train, knn_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_train, knn_unilabel_seas_vacc_trainpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Random Forest--Train data evaluation Metrics\n",
    "#check if these metrics are changing compared to previous results\n",
    "h1n1_rand_forst_unilabel_seas_vacc_train_acc = accuracy_score(y_h1n1_vacc_train, rand_forst_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_rand_forst_unilabel_seas_vacc_train_recall = recall_score(y_h1n1_vacc_train, rand_forst_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_rand_forst_unilabel_seas_vacc_train_precision = precision_score(y_h1n1_vacc_train, rand_forst_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_rand_forst_unilabel_seas_vacc_train_f1 = f1_score(y_h1n1_vacc_train, rand_forst_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_rand_forst_unilabel_seas_vacc_train_roc = roc_auc_score(y_h1n1_vacc_train, rand_forst_unilabel_seas_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_train, rand_forst_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_train, rand_forst_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_train, rand_forst_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_train, rand_forst_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_train, rand_forst_unilabel_seas_vacc_trainpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SVM--Train data evaluation Metrics\n",
    "h1n1_svm_unilabel_seas_vacc_train_acc = accuracy_score(y_h1n1_vacc_train, svm_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_svm_unilabel_seas_vacc_train_recall = recall_score(y_h1n1_vacc_train, svm_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_svm_unilabel_seas_vacc_train_precision = precision_score(y_h1n1_vacc_train, svm_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_svm_unilabel_seas_vacc_train_f1 = f1_score(y_h1n1_vacc_train, svm_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_svm_unilabel_seas_vacc_train_roc = roc_auc_score(y_h1n1_vacc_train, svm_unilabel_seas_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_train, svm_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_train, svm_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_train, svm_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_train, svm_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_train, svm_unilabel_seas_vacc_trainpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Test data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Logreg--Test data evaluation Metrics\n",
    "h1n1_logreg_unilabel_seas_vacc_test_acc = accuracy_score(y_h1n1_vacc_test, logreg_unilabel_seas_vacc_testpreds)\n",
    "h1n1_logreg_unilabel_seas_vacc_test_recall = recall_score(y_h1n1_vacc_test, logreg_unilabel_seas_vacc_testpreds)\n",
    "h1n1_logreg_unilabel_seas_vacc_test_precision = precision_score(y_h1n1_vacc_test, logreg_unilabel_seas_vacc_testpreds)\n",
    "h1n1_logreg_unilabel_seas_vacc_test_f1 = f1_score(y_h1n1_vacc_test, logreg_unilabel_seas_vacc_testpreds)\n",
    "h1n1_logreg_unilabel_seas_vacc_test_roc = roc_auc_score(y_h1n1_vacc_test, logreg_unilabel_seas_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_test, logreg_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_test, logreg_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_test, logreg_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_test, logreg_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_test, logreg_unilabel_seas_vacc_testpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# KNN--Test data evaluation Metrics\n",
    "h1n1_knn_unilabel_seas_vacc_test_acc = accuracy_score(y_h1n1_vacc_test, knn_unilabel_seas_vacc_testpreds)\n",
    "h1n1_knn_unilabel_seas_vacc_test_recall = recall_score(y_h1n1_vacc_test, knn_unilabel_seas_vacc_testpreds)\n",
    "h1n1_knn_unilabel_seas_vacc_test_precision = precision_score(y_h1n1_vacc_test, knn_unilabel_seas_vacc_testpreds)\n",
    "h1n1_knn_unilabel_seas_vacc_test_f1 = f1_score(y_h1n1_vacc_test, knn_unilabel_seas_vacc_testpreds)\n",
    "h1n1_knn_unilabel_seas_vacc_test_roc = roc_auc_score(y_h1n1_vacc_test, knn_unilabel_seas_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_test, knn_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_test, knn_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_test, knn_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_test, knn_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_test, knn_unilabel_seas_vacc_testpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Random Forest--Test data evaluation Metrics\n",
    "#check if these metrics are changing compared to previous results\n",
    "h1n1_rand_forst_unilabel_seas_vacc_test_acc = accuracy_score(y_h1n1_vacc_test, rand_forst_unilabel_seas_vacc_testpreds)\n",
    "h1n1_rand_forst_unilabel_seas_vacc_test_recall = recall_score(y_h1n1_vacc_test, rand_forst_unilabel_seas_vacc_testpreds)\n",
    "h1n1_rand_forst_unilabel_seas_vacc_test_precision = precision_score(y_h1n1_vacc_test, rand_forst_unilabel_seas_vacc_testpreds)\n",
    "h1n1_rand_forst_unilabel_seas_vacc_test_f1 = f1_score(y_h1n1_vacc_test, rand_forst_unilabel_seas_vacc_testpreds)\n",
    "h1n1_rand_forst_unilabel_seas_vacc_test_roc = roc_auc_score(y_h1n1_vacc_test, rand_forst_unilabel_seas_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_test, rand_forst_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_test, rand_forst_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_test, rand_forst_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_test, rand_forst_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_test, rand_forst_unilabel_seas_vacc_testpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SVM--Test data evaluation Metrics\n",
    "h1n1_svm_unilabel_seas_vacc_test_acc = accuracy_score(y_h1n1_vacc_test, svm_unilabel_seas_vacc_testpreds)\n",
    "h1n1_svm_unilabel_seas_vacc_test_recall = recall_score(y_h1n1_vacc_test, svm_unilabel_seas_vacc_testpreds)\n",
    "h1n1_svm_unilabel_seas_vacc_test_precision = precision_score(y_h1n1_vacc_test, svm_unilabel_seas_vacc_testpreds)\n",
    "h1n1_svm_unilabel_seas_vacc_test_f1 = f1_score(y_h1n1_vacc_test, svm_unilabel_seas_vacc_testpreds)\n",
    "h1n1_svm_unilabel_seas_vacc_test_roc = roc_auc_score(y_h1n1_vacc_test, svm_unilabel_seas_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_test, svm_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_test, svm_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_test, svm_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_test, svm_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_test, svm_unilabel_seas_vacc_testpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tracking the model with MLFlow"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### H1N1 vaccine output"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Logistic regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_h1n1) #this needs to be adjusted for each experiment\n",
    "name = 'logreg_unilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"Seasonal\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_logreg_unilabel_seas_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_logreg_unilabel_seas_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_logreg_unilabel_seas_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_logreg_unilabel_seas_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_logreg_unilabel_seas_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_logreg_unilabel_seas_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_logreg_unilabel_seas_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_logreg_unilabel_seas_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_logreg_unilabel_seas_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_logreg_unilabel_seas_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### KNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_h1n1)\n",
    "name = 'knn_unilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"Seasonal\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_knn_unilabel_seas_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_knn_unilabel_seas_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_knn_unilabel_seas_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_knn_unilabel_seas_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_knn_unilabel_seas_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_knn_unilabel_seas_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_knn_unilabel_seas_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_knn_unilabel_seas_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_knn_unilabel_seas_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_knn_unilabel_seas_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_h1n1)\n",
    "name = 'rand_forst_unilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"Seasonal\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_rand_forst_unilabel_seas_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_rand_forst_unilabel_seas_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_rand_forst_unilabel_seas_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_rand_forst_unilabel_seas_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_rand_forst_unilabel_seas_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_rand_forst_unilabel_seas_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_rand_forst_unilabel_seas_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_rand_forst_unilabel_seas_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_rand_forst_unilabel_seas_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_rand_forst_unilabel_seas_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### SVM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_h1n1)\n",
    "name = 'svm_unilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"Seasonal\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_svm_unilabel_seas_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_svm_unilabel_seas_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_svm_unilabel_seas_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_svm_unilabel_seas_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_svm_unilabel_seas_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_svm_unilabel_seas_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_svm_unilabel_seas_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_svm_unilabel_seas_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_svm_unilabel_seas_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_svm_unilabel_seas_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TheFluShot_seasonal: Single Label Modelling, output seasonal vaccine"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Single Label Modelling, output seasonal vaccine -> H1N1 Flu Vaccine not in features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The cat_features_no_vacc and X_no_vacc variables and the preprocessor remain the same from the multilabel modelling:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set up the target variable:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_seas_vacc = df['seasonal_vaccine'].copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_seas_vacc = y_seas_vacc.to_numpy()\n",
    "y_seas_vacc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(y_seas_vacc)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Performing test-train split:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_no_vacc_train, X_no_vacc_test, y_seas_vacc_train, y_seas_vacc_test = train_test_split(X_no_vacc, y_seas_vacc, stratify = y_seas_vacc, test_size=0.2, random_state=RSEED)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('X_no_vacc_train shape:', X_no_vacc_train.shape)\n",
    "print('X_no_vacc_test shape:', X_no_vacc_test.shape)\n",
    "print('y_seas_vacc_train:', y_seas_vacc_train.shape)\n",
    "print('y_seas_vacc_test:', y_seas_vacc_test.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setting up the pipeline for each model:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for logreg\n",
    "logreg_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", logreg),\n",
    "])\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", knn),\n",
    "])\n",
    "\n",
    "# for Random Forest\n",
    "\n",
    "rand_forst_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", rand_forst),\n",
    "])\n",
    "\n",
    "#for SVM\n",
    "svm_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", svm),\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training the models:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for logreg\n",
    "logreg_unilabel_no_vacc = logreg_unilabel_pipeline.fit(X_no_vacc_train, y_seas_vacc_train)\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_no_vacc = knn_unilabel_pipeline.fit(X_no_vacc_train, y_seas_vacc_train)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_unilabel_no_vacc = rand_forst_unilabel_pipeline.fit(X_no_vacc_train, y_seas_vacc_train)\n",
    "\n",
    "#for SVM\n",
    "svm_unilabel_no_vacc = svm_unilabel_pipeline.fit(X_no_vacc_train, y_seas_vacc_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Figure out later what this does and if we want to use it\n",
    "\n",
    "\n",
    "#y_train_predicted = cross_val_predict(full_pipeline, X_train, y_train, cv=5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Making predictions based on train and test data:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for logreg\n",
    "logreg_unilabel_no_vacc_trainpreds = logreg_unilabel_no_vacc.predict(X_no_vacc_train)\n",
    "logreg_unilabel_no_vacc_testpreds = logreg_unilabel_no_vacc.predict(X_no_vacc_test)\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_no_vacc_trainpreds = knn_unilabel_no_vacc.predict(X_no_vacc_train)\n",
    "knn_unilabel_no_vacc_testpreds = knn_unilabel_no_vacc.predict(X_no_vacc_test)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_unilabel_no_vacc_trainpreds = rand_forst_unilabel_no_vacc.predict(X_no_vacc_train)\n",
    "rand_forst_unilabel_no_vacc_testpreds = rand_forst_unilabel_no_vacc.predict(X_no_vacc_test)\n",
    "\n",
    "# for SVM\n",
    "svm_unilabel_no_vacc_trainpreds = svm_unilabel_no_vacc.predict(X_no_vacc_train)\n",
    "svm_unilabel_no_vacc_testpreds = svm_unilabel_no_vacc.predict(X_no_vacc_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model evaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Logreg--Train data evaluation Metrics\n",
    "seas_logreg_unilabel_no_vacc_train_acc = accuracy_score(y_seas_vacc_train, logreg_unilabel_no_vacc_trainpreds)\n",
    "seas_logreg_unilabel_no_vacc_train_recall = recall_score(y_seas_vacc_train, logreg_unilabel_no_vacc_trainpreds)\n",
    "seas_logreg_unilabel_no_vacc_train_precision = precision_score(y_seas_vacc_train, logreg_unilabel_no_vacc_trainpreds)\n",
    "seas_logreg_unilabel_no_vacc_train_f1 = f1_score(y_seas_vacc_train, logreg_unilabel_no_vacc_trainpreds)\n",
    "seas_logreg_unilabel_no_vacc_train_roc = roc_auc_score(y_seas_vacc_train, logreg_unilabel_no_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_train, logreg_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_train, logreg_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_train, logreg_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_train, logreg_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_train, logreg_unilabel_no_vacc_trainpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# KNN--Train data evaluation Metrics\n",
    "seas_knn_unilabel_no_vacc_train_acc = accuracy_score(y_seas_vacc_train, knn_unilabel_no_vacc_trainpreds)\n",
    "seas_knn_unilabel_no_vacc_train_recall = recall_score(y_seas_vacc_train, knn_unilabel_no_vacc_trainpreds)\n",
    "seas_knn_unilabel_no_vacc_train_precision = precision_score(y_seas_vacc_train, knn_unilabel_no_vacc_trainpreds)\n",
    "seas_knn_unilabel_no_vacc_train_f1 = f1_score(y_seas_vacc_train, knn_unilabel_no_vacc_trainpreds)\n",
    "seas_knn_unilabel_no_vacc_train_roc = roc_auc_score(y_seas_vacc_train, knn_unilabel_no_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_train, knn_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_train, knn_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_train, knn_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_train, knn_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_train, knn_unilabel_no_vacc_trainpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Random Forest--Train data evaluation Metrics\n",
    "#check if these metrics are changing compared to previous results\n",
    "seas_rand_forst_unilabel_no_vacc_train_acc = accuracy_score(y_seas_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)\n",
    "seas_rand_forst_unilabel_no_vacc_train_recall = recall_score(y_seas_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)\n",
    "seas_rand_forst_unilabel_no_vacc_train_precision = precision_score(y_seas_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)\n",
    "seas_rand_forst_unilabel_no_vacc_train_f1 = f1_score(y_seas_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)\n",
    "seas_rand_forst_unilabel_no_vacc_train_roc = roc_auc_score(y_seas_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SVM--Train data evaluation Metrics\n",
    "seas_svm_unilabel_no_vacc_train_acc = accuracy_score(y_seas_vacc_train, svm_unilabel_no_vacc_trainpreds)\n",
    "seas_svm_unilabel_no_vacc_train_recall = recall_score(y_seas_vacc_train, svm_unilabel_no_vacc_trainpreds)\n",
    "seas_svm_unilabel_no_vacc_train_precision = precision_score(y_seas_vacc_train, svm_unilabel_no_vacc_trainpreds)\n",
    "seas_svm_unilabel_no_vacc_train_f1 = f1_score(y_seas_vacc_train, svm_unilabel_no_vacc_trainpreds)\n",
    "seas_svm_unilabel_no_vacc_train_roc = roc_auc_score(y_seas_vacc_train, svm_unilabel_no_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_train, svm_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_train, svm_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_train, svm_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_train, svm_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_train, svm_unilabel_no_vacc_trainpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Test data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Logreg--Test data evaluation Metrics\n",
    "seas_logreg_unilabel_no_vacc_test_acc = accuracy_score(y_seas_vacc_test, logreg_unilabel_no_vacc_testpreds)\n",
    "seas_logreg_unilabel_no_vacc_test_recall = recall_score(y_seas_vacc_test, logreg_unilabel_no_vacc_testpreds)\n",
    "seas_logreg_unilabel_no_vacc_test_precision = precision_score(y_seas_vacc_test, logreg_unilabel_no_vacc_testpreds)\n",
    "seas_logreg_unilabel_no_vacc_test_f1 = f1_score(y_seas_vacc_test, logreg_unilabel_no_vacc_testpreds)\n",
    "seas_logreg_unilabel_no_vacc_test_roc = roc_auc_score(y_seas_vacc_test, logreg_unilabel_no_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_test, logreg_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_test, logreg_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_test, logreg_unilabel_no_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_test, logreg_unilabel_no_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_test, logreg_unilabel_no_vacc_testpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# KNN--Test data evaluation Metrics\n",
    "seas_knn_unilabel_no_vacc_test_acc = accuracy_score(y_seas_vacc_test, knn_unilabel_no_vacc_testpreds)\n",
    "seas_knn_unilabel_no_vacc_test_recall = recall_score(y_seas_vacc_test, knn_unilabel_no_vacc_testpreds)\n",
    "seas_knn_unilabel_no_vacc_test_precision = precision_score(y_seas_vacc_test, knn_unilabel_no_vacc_testpreds)\n",
    "seas_knn_unilabel_no_vacc_test_f1 = f1_score(y_seas_vacc_test, knn_unilabel_no_vacc_testpreds)\n",
    "seas_knn_unilabel_no_vacc_test_roc = roc_auc_score(y_seas_vacc_test, knn_unilabel_no_vacc_testpreds)\n",
    "\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_test, knn_unilabel_no_vacc_testpreds)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_test, knn_unilabel_no_vacc_testpreds)))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_test, knn_unilabel_no_vacc_testpreds)))\n",
    "print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_test, knn_unilabel_no_vacc_testpreds)))\n",
    "print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_test, knn_unilabel_no_vacc_testpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(seas_knn_unilabel_no_vacc_test_acc)\n",
    "print(seas_knn_unilabel_no_vacc_test_recall)\n",
    "print(seas_knn_unilabel_no_vacc_test_precision)\n",
    "print(seas_knn_unilabel_no_vacc_test_f1)\n",
    "print(seas_knn_unilabel_no_vacc_test_roc)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Random Forest--Test data evaluation Metrics\n",
    "#check if these metrics are changing compared to previous results\n",
    "seas_rand_forst_unilabel_no_vacc_test_acc = accuracy_score(y_seas_vacc_test, rand_forst_unilabel_no_vacc_testpreds)\n",
    "seas_rand_forst_unilabel_no_vacc_test_recall = recall_score(y_seas_vacc_test, rand_forst_unilabel_no_vacc_testpreds)\n",
    "seas_rand_forst_unilabel_no_vacc_test_precision = precision_score(y_seas_vacc_test, rand_forst_unilabel_no_vacc_testpreds)\n",
    "seas_rand_forst_unilabel_no_vacc_test_f1 = f1_score(y_seas_vacc_test, rand_forst_unilabel_no_vacc_testpreds)\n",
    "seas_rand_forst_unilabel_no_vacc_test_roc = roc_auc_score(y_seas_vacc_test, rand_forst_unilabel_no_vacc_testpreds)\n",
    "\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_test, rand_forst_unilabel_no_vacc_testpreds)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_test, rand_forst_unilabel_no_vacc_testpreds)))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_test, rand_forst_unilabel_no_vacc_testpreds)))\n",
    "print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_test, rand_forst_unilabel_no_vacc_testpreds)))\n",
    "print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_test, rand_forst_unilabel_no_vacc_testpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(seas_rand_forst_unilabel_no_vacc_test_acc)\n",
    "print(seas_rand_forst_unilabel_no_vacc_test_recall)\n",
    "print(seas_rand_forst_unilabel_no_vacc_test_precision)\n",
    "print(seas_rand_forst_unilabel_no_vacc_test_f1)\n",
    "print(seas_rand_forst_unilabel_no_vacc_test_roc)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SVM--Test data evaluation Metrics\n",
    "seas_svm_unilabel_no_vacc_test_acc = accuracy_score(y_seas_vacc_test, svm_unilabel_no_vacc_testpreds)\n",
    "seas_svm_unilabel_no_vacc_test_recall = recall_score(y_seas_vacc_test, svm_unilabel_no_vacc_testpreds)\n",
    "seas_svm_unilabel_no_vacc_test_precision = precision_score(y_seas_vacc_test, svm_unilabel_no_vacc_testpreds)\n",
    "seas_svm_unilabel_no_vacc_test_f1 = f1_score(y_seas_vacc_test, svm_unilabel_no_vacc_testpreds)\n",
    "seas_svm_unilabel_no_vacc_test_roc = roc_auc_score(y_seas_vacc_test, svm_unilabel_no_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_test, svm_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_test, svm_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_test, svm_unilabel_no_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_test, svm_unilabel_no_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_test, svm_unilabel_no_vacc_testpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tracking the model with MLFlow"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Seasonal vaccine output"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Logistic regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_seasonal) #this needs to be adjusted for each experiment\n",
    "name = 'logreg_unilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seas_logreg_unilabel_no_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seas_logreg_unilabel_no_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seas_logreg_unilabel_no_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seas_logreg_unilabel_no_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seas_logreg_unilabel_no_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seas_logreg_unilabel_no_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seas_logreg_unilabel_no_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seas_logreg_unilabel_no_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seas_logreg_unilabel_no_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seas_logreg_unilabel_no_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### KNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_seasonal)\n",
    "name = 'knn_unilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seas_knn_unilabel_no_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seas_knn_unilabel_no_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seas_knn_unilabel_no_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seas_knn_unilabel_no_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seas_knn_unilabel_no_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seas_knn_unilabel_no_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seas_knn_unilabel_no_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seas_knn_unilabel_no_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seas_knn_unilabel_no_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seas_knn_unilabel_no_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_seasonal)\n",
    "name = 'rand_forst_unilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seas_rand_forst_unilabel_no_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seas_rand_forst_unilabel_no_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seas_rand_forst_unilabel_no_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seas_rand_forst_unilabel_no_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seas_rand_forst_unilabel_no_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seas_rand_forst_unilabel_no_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seas_rand_forst_unilabel_no_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seas_rand_forst_unilabel_no_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seas_rand_forst_unilabel_no_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seas_rand_forst_unilabel_no_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### SVM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_seasonal)\n",
    "name = 'svm_unilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seas_svm_unilabel_no_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seas_svm_unilabel_no_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seas_svm_unilabel_no_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seas_svm_unilabel_no_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seas_svm_unilabel_no_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seas_svm_unilabel_no_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seas_svm_unilabel_no_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seas_svm_unilabel_no_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seas_svm_unilabel_no_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seas_svm_unilabel_no_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Single Label Modelling, output seasonal vaccine -> H1N1 Flu Vaccine is in features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The y_seas_vacc remains the same from the previous model; the X feature and cat_features (for the preprocessor) need to be adjusted:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cat_features_h1n1_vacc = cat_features.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cat_features_h1n1_vacc.remove('seasonal_vaccine')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#NB: dropping the 'h1n1_vaccine' and 'seasonal_vaccine' columns\n",
    "X_h1n1_vacc = df.drop(columns=['seasonal_vaccine'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Performing test-train split (the same data can be used for each model in multilabelling):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_h1n1_vacc_train, X_h1n1_vacc_test, y_seas_vacc_train, y_seas_vacc_test = train_test_split(X_h1n1_vacc, y_seas_vacc, stratify = y_seas_vacc, test_size=0.2, random_state=RSEED)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('X_h1n1_vacc_train shape:', X_h1n1_vacc_train.shape)\n",
    "print('X_h1n1_vacc_test shape:', X_h1n1_vacc_test.shape)\n",
    "print('y_seas_vacc_train:', y_seas_vacc_train.shape)\n",
    "print('y_seas_vacc_test:', y_seas_vacc_test.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The preprocessor is adjusted:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "preprocessor_h1n1_vacc = ColumnTransformer([\n",
    "    ('cat', cat_pipeline, cat_features_h1n1_vacc)\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The pipeline is adjusted:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for logreg\n",
    "logreg_h1n1_vacc_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_h1n1_vacc),\n",
    "    (\"estimators\", logreg),\n",
    "])\n",
    "\n",
    "# for KNN\n",
    "knn_h1n1_vacc_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_h1n1_vacc),\n",
    "    (\"estimators\", knn),\n",
    "])\n",
    "\n",
    "# for Random Forest\n",
    "\n",
    "rand_forst_h1n1_vacc_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_h1n1_vacc),\n",
    "    (\"estimators\", rand_forst),\n",
    "])\n",
    "\n",
    "#for SVM\n",
    "svm_h1n1_vacc_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_h1n1_vacc),\n",
    "    (\"estimators\", svm),\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training the models:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for logreg\n",
    "logreg_unilabel_h1n1_vacc = logreg_h1n1_vacc_unilabel_pipeline.fit(X_h1n1_vacc_train, y_seas_vacc_train)\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_h1n1_vacc = knn_h1n1_vacc_unilabel_pipeline.fit(X_h1n1_vacc_train, y_seas_vacc_train)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_unilabel_h1n1_vacc = rand_forst_h1n1_vacc_unilabel_pipeline.fit(X_h1n1_vacc_train, y_seas_vacc_train)\n",
    "\n",
    "#for SVM\n",
    "svm_unilabel_h1n1_vacc = svm_h1n1_vacc_unilabel_pipeline.fit(X_h1n1_vacc_train, y_seas_vacc_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Figure out later what this does and if we want to use it\n",
    "\n",
    "\n",
    "#y_train_predicted = cross_val_predict(full_pipeline, X_train, y_train, cv=5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Making predictions based on train and test data:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for logreg\n",
    "logreg_unilabel_h1n1_vacc_trainpreds = logreg_unilabel_h1n1_vacc.predict(X_h1n1_vacc_train)\n",
    "logreg_unilabel_h1n1_vacc_testpreds = logreg_unilabel_h1n1_vacc.predict(X_h1n1_vacc_test)\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_h1n1_vacc_trainpreds = knn_unilabel_h1n1_vacc.predict(X_h1n1_vacc_train)\n",
    "knn_unilabel_h1n1_vacc_testpreds = knn_unilabel_h1n1_vacc.predict(X_h1n1_vacc_test)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_unilabel_h1n1_vacc_trainpreds = rand_forst_unilabel_h1n1_vacc.predict(X_h1n1_vacc_train)\n",
    "rand_forst_unilabel_h1n1_vacc_testpreds = rand_forst_unilabel_h1n1_vacc.predict(X_h1n1_vacc_test)\n",
    "\n",
    "# for SVM\n",
    "svm_unilabel_h1n1_vacc_trainpreds = svm_unilabel_h1n1_vacc.predict(X_h1n1_vacc_train)\n",
    "svm_unilabel_h1n1_vacc_testpreds = svm_unilabel_h1n1_vacc.predict(X_h1n1_vacc_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model evaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Logreg--Train data evaluation Metrics\n",
    "seas_logreg_unilabel_h1n1_vacc_train_acc = accuracy_score(y_seas_vacc_train, logreg_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_logreg_unilabel_h1n1_vacc_train_recall = recall_score(y_seas_vacc_train, logreg_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_logreg_unilabel_h1n1_vacc_train_precision = precision_score(y_seas_vacc_train, logreg_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_logreg_unilabel_h1n1_vacc_train_f1 = f1_score(y_seas_vacc_train, logreg_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_logreg_unilabel_h1n1_vacc_train_roc = roc_auc_score(y_seas_vacc_train, logreg_unilabel_h1n1_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_train, logreg_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_train, logreg_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_train, logreg_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_train, logreg_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_train, logreg_unilabel_h1n1_vacc_trainpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# KNN--Train data evaluation Metrics\n",
    "seas_knn_unilabel_h1n1_vacc_train_acc = accuracy_score(y_seas_vacc_train, knn_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_knn_unilabel_h1n1_vacc_train_recall = recall_score(y_seas_vacc_train, knn_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_knn_unilabel_h1n1_vacc_train_precision = precision_score(y_seas_vacc_train, knn_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_knn_unilabel_h1n1_vacc_train_f1 = f1_score(y_seas_vacc_train, knn_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_knn_unilabel_h1n1_vacc_train_roc = roc_auc_score(y_seas_vacc_train, knn_unilabel_h1n1_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_train, knn_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_train, knn_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_train, knn_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_train, knn_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_train, knn_unilabel_h1n1_vacc_trainpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Random Forest--Train data evaluation Metrics\n",
    "#check if these metrics are changing compared to previous results\n",
    "seas_rand_forst_unilabel_h1n1_vacc_train_acc = accuracy_score(y_seas_vacc_train, rand_forst_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_rand_forst_unilabel_h1n1_vacc_train_recall = recall_score(y_seas_vacc_train, rand_forst_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_rand_forst_unilabel_h1n1_vacc_train_precision = precision_score(y_seas_vacc_train, rand_forst_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_rand_forst_unilabel_h1n1_vacc_train_f1 = f1_score(y_seas_vacc_train, rand_forst_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_rand_forst_unilabel_h1n1_vacc_train_roc = roc_auc_score(y_seas_vacc_train, rand_forst_unilabel_h1n1_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_train, rand_forst_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_train, rand_forst_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_train, rand_forst_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_train, rand_forst_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_train, rand_forst_unilabel_h1n1_vacc_trainpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SVM--Train data evaluation Metrics\n",
    "seas_svm_unilabel_h1n1_vacc_train_acc = accuracy_score(y_seas_vacc_train, svm_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_svm_unilabel_h1n1_vacc_train_recall = recall_score(y_seas_vacc_train, svm_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_svm_unilabel_h1n1_vacc_train_precision = precision_score(y_seas_vacc_train, svm_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_svm_unilabel_h1n1_vacc_train_f1 = f1_score(y_seas_vacc_train, svm_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_svm_unilabel_h1n1_vacc_train_roc = roc_auc_score(y_seas_vacc_train, svm_unilabel_h1n1_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_train, svm_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_train, svm_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_train, svm_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_train, svm_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_train, svm_unilabel_h1n1_vacc_trainpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Test data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Logreg--Test data evaluation Metrics\n",
    "seas_logreg_unilabel_h1n1_vacc_test_acc = accuracy_score(y_seas_vacc_test, logreg_unilabel_h1n1_vacc_testpreds)\n",
    "seas_logreg_unilabel_h1n1_vacc_test_recall = recall_score(y_seas_vacc_test, logreg_unilabel_h1n1_vacc_testpreds)\n",
    "seas_logreg_unilabel_h1n1_vacc_test_precision = precision_score(y_seas_vacc_test, logreg_unilabel_h1n1_vacc_testpreds)\n",
    "seas_logreg_unilabel_h1n1_vacc_test_f1 = f1_score(y_seas_vacc_test, logreg_unilabel_h1n1_vacc_testpreds)\n",
    "seas_logreg_unilabel_h1n1_vacc_test_roc = roc_auc_score(y_seas_vacc_test, logreg_unilabel_h1n1_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_test, logreg_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_test, logreg_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_test, logreg_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_test, logreg_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_test, logreg_unilabel_h1n1_vacc_testpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# KNN--Test data evaluation Metrics\n",
    "seas_knn_unilabel_h1n1_vacc_test_acc = accuracy_score(y_seas_vacc_test, knn_unilabel_h1n1_vacc_testpreds)\n",
    "seas_knn_unilabel_h1n1_vacc_test_recall = recall_score(y_seas_vacc_test, knn_unilabel_h1n1_vacc_testpreds)\n",
    "seas_knn_unilabel_h1n1_vacc_test_precision = precision_score(y_seas_vacc_test, knn_unilabel_h1n1_vacc_testpreds)\n",
    "seas_knn_unilabel_h1n1_vacc_test_f1 = f1_score(y_seas_vacc_test, knn_unilabel_h1n1_vacc_testpreds)\n",
    "seas_knn_unilabel_h1n1_vacc_test_roc = roc_auc_score(y_seas_vacc_test, knn_unilabel_h1n1_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_test, knn_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_test, knn_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_test, knn_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_test, knn_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_test, knn_unilabel_h1n1_vacc_testpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Random Forest--Test data evaluation Metrics\n",
    "#check if these metrics are changing compared to previous results\n",
    "seas_rand_forst_unilabel_h1n1_vacc_test_acc = accuracy_score(y_seas_vacc_test, rand_forst_unilabel_h1n1_vacc_testpreds)\n",
    "seas_rand_forst_unilabel_h1n1_vacc_test_recall = recall_score(y_seas_vacc_test, rand_forst_unilabel_h1n1_vacc_testpreds)\n",
    "seas_rand_forst_unilabel_h1n1_vacc_test_precision = precision_score(y_seas_vacc_test, rand_forst_unilabel_h1n1_vacc_testpreds)\n",
    "seas_rand_forst_unilabel_h1n1_vacc_test_f1 = f1_score(y_seas_vacc_test, rand_forst_unilabel_h1n1_vacc_testpreds)\n",
    "seas_rand_forst_unilabel_h1n1_vacc_test_roc = roc_auc_score(y_seas_vacc_test, rand_forst_unilabel_h1n1_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_test, rand_forst_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_test, rand_forst_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_test, rand_forst_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_test, rand_forst_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_test, rand_forst_unilabel_h1n1_vacc_testpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SVM--Test data evaluation Metrics\n",
    "seas_svm_unilabel_h1n1_vacc_test_acc = accuracy_score(y_seas_vacc_test, svm_unilabel_h1n1_vacc_testpreds)\n",
    "seas_svm_unilabel_h1n1_vacc_test_recall = recall_score(y_seas_vacc_test, svm_unilabel_h1n1_vacc_testpreds)\n",
    "seas_svm_unilabel_h1n1_vacc_test_precision = precision_score(y_seas_vacc_test, svm_unilabel_h1n1_vacc_testpreds)\n",
    "seas_svm_unilabel_h1n1_vacc_test_f1 = f1_score(y_seas_vacc_test, svm_unilabel_h1n1_vacc_testpreds)\n",
    "seas_svm_unilabel_h1n1_vacc_test_roc = roc_auc_score(y_seas_vacc_test, svm_unilabel_h1n1_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_test, svm_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_test, svm_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_test, svm_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_test, svm_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_test, svm_unilabel_h1n1_vacc_testpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tracking the model with MLFlow"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### H1N1 vaccine output"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Logistic regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_seasonal) #this needs to be adjusted for each experiment\n",
    "name = 'logreg_unilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"H1N1\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seas_logreg_unilabel_h1n1_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seas_logreg_unilabel_h1n1_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seas_logreg_unilabel_h1n1_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seas_logreg_unilabel_h1n1_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seas_logreg_unilabel_h1n1_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seas_logreg_unilabel_h1n1_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seas_logreg_unilabel_h1n1_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seas_logreg_unilabel_h1n1_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seas_logreg_unilabel_h1n1_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seas_logreg_unilabel_h1n1_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### KNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_seasonal)\n",
    "name = 'knn_unilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"H1N1\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seas_knn_unilabel_h1n1_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seas_knn_unilabel_h1n1_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seas_knn_unilabel_h1n1_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seas_knn_unilabel_h1n1_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seas_knn_unilabel_h1n1_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seas_knn_unilabel_h1n1_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seas_knn_unilabel_h1n1_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seas_knn_unilabel_h1n1_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seas_knn_unilabel_h1n1_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seas_knn_unilabel_h1n1_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_seasonal)\n",
    "name = 'rand_forst_unilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"H1N1\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seas_rand_forst_unilabel_h1n1_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seas_rand_forst_unilabel_h1n1_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seas_rand_forst_unilabel_h1n1_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seas_rand_forst_unilabel_h1n1_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seas_rand_forst_unilabel_h1n1_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seas_rand_forst_unilabel_h1n1_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seas_rand_forst_unilabel_h1n1_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seas_rand_forst_unilabel_h1n1_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seas_rand_forst_unilabel_h1n1_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seas_rand_forst_unilabel_h1n1_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### SVM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_seasonal)\n",
    "name = 'svm_unilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"H1N1\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seas_svm_unilabel_h1n1_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seas_svm_unilabel_h1n1_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seas_svm_unilabel_h1n1_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seas_svm_unilabel_h1n1_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seas_svm_unilabel_h1n1_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seas_svm_unilabel_h1n1_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seas_svm_unilabel_h1n1_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seas_svm_unilabel_h1n1_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seas_svm_unilabel_h1n1_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seas_svm_unilabel_h1n1_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bdc0c931d2d4c1e254c9b407be81fb640f6c2f032b4d6ab78d09bb2272bcd9af"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('.venv')"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}