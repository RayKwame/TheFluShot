{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering to eliminate multicollinearity and to choose features based on target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/Flu_Shot_Data_cleaned_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the highly correlated features\n",
    "s = df.corr(method='spearman').unstack().sort_values(kind=\"quicksort\", ascending=False).drop_duplicates()\n",
    "print(s[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This notebook deals with highly correlated features \n",
    "- We will apply two strategies:\n",
    "    - binary features will be combined into categories (4 combinations)\n",
    "    - non-binary features will be dropped according to the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe apply chi squared test on binary variables? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new column based on recommendation (2 binary features)\n",
    "- applying a function that tells if both, none or either of the vaccines have been recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reco(row):\n",
    "    # none of the vaccines has been recommended\n",
    "    if row['doctor_recc_seasonal'] == 0 and row['doctor_recc_h1n1'] == 0:\n",
    "        val = 0\n",
    "    # both vaccines have been recommended\n",
    "    elif row['doctor_recc_seasonal'] == 1 and row['doctor_recc_h1n1'] == 1:\n",
    "        val = 1\n",
    "    # only seasonal vaccine has been recommended \n",
    "    elif row['doctor_recc_seasonal'] == 1 and row['doctor_recc_h1n1'] == 0:\n",
    "        val = 2\n",
    "    # only H1N1 vaccine has been recommended\n",
    "    elif row['doctor_recc_seasonal'] == 0 and row['doctor_recc_h1n1'] == 1:\n",
    "        val = 3\n",
    "    else:\n",
    "        val = None\n",
    "    return val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the function\n",
    "# values will be converted to categorical \n",
    "df['reco_vaccines'] = df.apply(get_reco, axis=1).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reco_vaccines'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.behavioral_large_gatherings.value_counts())\n",
    "print(df.behavioral_outside_home.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a new column based on 2 behavioural features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- next, we will create a function that combines behaviour at large gatherings and outside of home\n",
    "- NOTE: we need to make an assumption that '0' refers to not having done it and '1' refers to having done it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_behaviour(row):\n",
    "    # none of the behaviours applies \n",
    "    if row['behavioral_large_gatherings'] == 0 and row['behavioral_outside_home'] == 0:\n",
    "        val = 0\n",
    "    # both behaviours apply \n",
    "    elif row['behavioral_large_gatherings'] == 1 and row['behavioral_outside_home'] == 1:\n",
    "        val = 1\n",
    "    # only reducing time at large gatherings applies \n",
    "    elif row['behavioral_large_gatherings'] == 1 and row['behavioral_outside_home'] == 0:\n",
    "        val = 2\n",
    "    # only reduced contact with people outside of household applies \n",
    "    elif row['behavioral_large_gatherings'] == 0 and row['behavioral_outside_home'] == 1:\n",
    "        val = 3\n",
    "    else:\n",
    "        val = None\n",
    "    return val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the function\n",
    "# values will be converted to categorical \n",
    "df['behaviour_gather_home'] = df.apply(get_behaviour, axis=1).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.behaviour_gather_home.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we will now drop the columns that are no longer necessary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removal = ['doctor_recc_seasonal', 'doctor_recc_h1n1', 'behavioral_large_gatherings', 'behavioral_outside_home']\n",
    "\n",
    "df.drop(removal, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removal of feature depending on target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- apply the following code if H1N1 is the single target variable \n",
    "- we take out the feature that is related to seasonal flu/vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_seas = ['opinion_seas_risk', 'opinion_seas_sick_from_vacc']\n",
    "\n",
    "df.drop(list_seas, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- apply the following code if seasonal vaccine is the single target variable \n",
    "- we take out the feature that is related to H1N1 flu/vaccine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_h1n1 = ['opinion_h1n1_risk', 'opinion_h1n1_sick_from_vacc']\n",
    "\n",
    "df.drop(list_h1n1, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying principal component analysis in order to reduce features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('h1n1_vaccine', axis=1)\n",
    "X = df.drop('seasonal_vaccine', axis=1)\n",
    "y = df['h1n1_vaccine']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded = pd.get_dummies(X_train, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to perform PCA, we need to drop missing values\n",
    "# we will impute missing values with the mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace({'nan': np.nan}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying simple imputer to deal with missing values \n",
    "imp_mode = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "X_train_encoded_filled = imp_mode.fit_transform(X_train_encoded)\n",
    "X_train_encoded_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.DataFrame(data=X_train_encoded_filled)\n",
    "df_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=5)\n",
    "df_encoded_pca = pca.fit(df_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_trans = pca.transform(df_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled_trans = pd.DataFrame(data=X_train_scaled_trans)\n",
    "X_train_scaled_trans.head(5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c0c25dab8ee693e846481bd08863e7cb648266bb2d9a40c015c16febc8ddeeb0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}