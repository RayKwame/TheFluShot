{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on MLFlow:\n",
    "- 'Run name' field: model name, type of output (multilabel vs unilabel), which vaccine (for multiclass only)\n",
    "- 'Parameters' field: methods applied for data (data cleaning, data balancing, hyperparameters)--insert feature engineering info here, if relevant?\n",
    "- 'Tags' field: details about the features used for the run (is one of the vaccines in the features?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /Users/julianeberek/neuefische/TheFluShot/.venv/lib/python3.8/site-packages (5.1.0)\n",
      "Requirement already satisfied: six in /Users/julianeberek/neuefische/TheFluShot/.venv/lib/python3.8/site-packages (from plotly) (1.16.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/julianeberek/neuefische/TheFluShot/.venv/lib/python3.8/site-packages (from plotly) (8.0.1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# adding to the path variables the one folder higher (locally, not changing system variables)\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "#mlflow import\n",
    "import mlflow\n",
    "from modeling.config import EXPERIMENT_NAME_multilabel, EXPERIMENT_NAME_h1n1, EXPERIMENT_NAME_seasonal, EXPERIMENT_NAME_multiclass\n",
    "TRACKING_URI = open(\"../.mlflow_uri\").read().strip()\n",
    "\n",
    "RSEED = 42\n",
    "\n",
    "# Modeling Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "!pip install plotly\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, cross_validate\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data from a previously prepared dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/Flu_Shot_Data_cleaned_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>h1n1_vaccine</th>\n",
       "      <th>seasonal_vaccine</th>\n",
       "      <th>h1n1_concern</th>\n",
       "      <th>h1n1_knowledge</th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>...</th>\n",
       "      <th>income_poverty</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>rent_or_own</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>hhs_geo_region</th>\n",
       "      <th>census_msa</th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "      <th>employment_industry</th>\n",
       "      <th>employment_occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>oxchjgsf</td>\n",
       "      <td>Non-MSA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Employed</td>\n",
       "      <td>bhuqouqj</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pxcmvdjn</td>\n",
       "      <td>xgwztkwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;= $75,000, Above Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Employed</td>\n",
       "      <td>qufhixun</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rucpziij</td>\n",
       "      <td>xtkaffoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>lrircsnp</td>\n",
       "      <td>MSA, Principle City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;= $75,000, Above Poverty</td>\n",
       "      <td>Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Employed</td>\n",
       "      <td>qufhixun</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>wxleyezf</td>\n",
       "      <td>emcorrxb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  h1n1_vaccine  seasonal_vaccine  h1n1_concern  h1n1_knowledge  \\\n",
       "0           0             0                 0           1.0             0.0   \n",
       "1           1             0                 1           3.0             2.0   \n",
       "2           2             0                 0           1.0             1.0   \n",
       "3           3             0                 1           1.0             1.0   \n",
       "4           4             0                 0           2.0             1.0   \n",
       "\n",
       "   behavioral_antiviral_meds  behavioral_avoidance  behavioral_face_mask  \\\n",
       "0                        0.0                   0.0                   0.0   \n",
       "1                        0.0                   1.0                   0.0   \n",
       "2                        0.0                   1.0                   0.0   \n",
       "3                        0.0                   1.0                   0.0   \n",
       "4                        0.0                   1.0                   0.0   \n",
       "\n",
       "   behavioral_wash_hands  behavioral_large_gatherings  ...  \\\n",
       "0                    0.0                          0.0  ...   \n",
       "1                    1.0                          0.0  ...   \n",
       "2                    0.0                          0.0  ...   \n",
       "3                    1.0                          1.0  ...   \n",
       "4                    1.0                          1.0  ...   \n",
       "\n",
       "              income_poverty  marital_status  rent_or_own   employment_status  \\\n",
       "0              Below Poverty     Not Married          Own  Not in Labor Force   \n",
       "1              Below Poverty     Not Married         Rent            Employed   \n",
       "2  <= $75,000, Above Poverty     Not Married          Own            Employed   \n",
       "3              Below Poverty     Not Married         Rent  Not in Labor Force   \n",
       "4  <= $75,000, Above Poverty         Married          Own            Employed   \n",
       "\n",
       "   hhs_geo_region                census_msa  household_adults  \\\n",
       "0        oxchjgsf                   Non-MSA               0.0   \n",
       "1        bhuqouqj  MSA, Not Principle  City               0.0   \n",
       "2        qufhixun  MSA, Not Principle  City               2.0   \n",
       "3        lrircsnp       MSA, Principle City               0.0   \n",
       "4        qufhixun  MSA, Not Principle  City               1.0   \n",
       "\n",
       "   household_children  employment_industry  employment_occupation  \n",
       "0                 0.0                  NaN                    NaN  \n",
       "1                 0.0             pxcmvdjn               xgwztkwe  \n",
       "2                 0.0             rucpziij               xtkaffoo  \n",
       "3                 0.0                  NaN                    NaN  \n",
       "4                 0.0             wxleyezf               emcorrxb  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the strange 'Unnamed: 0' column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26707, 37)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up for modelling (stays the same for all experiemnts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up of pipeline preprocessor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for categorical features\n",
    "# This stays the same for everything\n",
    "cat_pipeline = Pipeline([\n",
    "    ('1hot', OneHotEncoder(handle_unknown='error', drop='first'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiating the Random Forest Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Random Forest\n",
    "rand_forst= RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TheFluShot_multilabel: Multilabel prediction (both vaccinations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removal of target variables from cat_features list (this needs to be adjusted for each dataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features_no_vacc = cat_features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features_no_vacc.remove('h1n1_vaccine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features_no_vacc.remove('seasonal_vaccine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h1n1_concern',\n",
       " 'h1n1_knowledge',\n",
       " 'behavioral_antiviral_meds',\n",
       " 'behavioral_avoidance',\n",
       " 'behavioral_face_mask',\n",
       " 'behavioral_wash_hands',\n",
       " 'behavioral_large_gatherings',\n",
       " 'behavioral_outside_home',\n",
       " 'behavioral_touch_face',\n",
       " 'doctor_recc_h1n1',\n",
       " 'doctor_recc_seasonal',\n",
       " 'chronic_med_condition',\n",
       " 'child_under_6_months',\n",
       " 'health_worker',\n",
       " 'health_insurance',\n",
       " 'opinion_h1n1_vacc_effective',\n",
       " 'opinion_h1n1_risk',\n",
       " 'opinion_h1n1_sick_from_vacc',\n",
       " 'opinion_seas_vacc_effective',\n",
       " 'opinion_seas_risk',\n",
       " 'opinion_seas_sick_from_vacc',\n",
       " 'age_group',\n",
       " 'education',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'income_poverty',\n",
       " 'marital_status',\n",
       " 'rent_or_own',\n",
       " 'employment_status',\n",
       " 'hhs_geo_region',\n",
       " 'census_msa',\n",
       " 'household_adults',\n",
       " 'household_children',\n",
       " 'employment_industry',\n",
       " 'employment_occupation']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features_no_vacc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the features and target to 'X' and 'y', to make the test-train split easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_both_vacc = df[['h1n1_vaccine', 'seasonal_vaccine']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       ...,\n",
       "       [0, 1],\n",
       "       [0, 0],\n",
       "       [0, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_both_vacc = y_both_vacc.to_numpy()\n",
    "y_both_vacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NB: dropping the 'h1n1_vaccine' and 'seasonal_vaccine' columns\n",
    "X_no_vacc = df.drop(columns=['h1n1_vaccine', 'seasonal_vaccine'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing test-train split (the same data can be used for each model in multilabelling):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_no_vacc_train, X_no_vacc_test, y_both_vacc_train, y_both_vacc_test = train_test_split(X_no_vacc, y_both_vacc, stratify = y_both_vacc, test_size=0.2, random_state=RSEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_no_vacc_train shape: (21365, 35)\n",
      "X_no_vacc_test shape: (5342, 35)\n",
      "y_both_vacc_train: (21365, 2)\n",
      "y_both_vacc_test: (5342, 2)\n"
     ]
    }
   ],
   "source": [
    "print('X_no_vacc_train shape:', X_no_vacc_train.shape)\n",
    "print('X_no_vacc_test shape:', X_no_vacc_test.shape)\n",
    "print('y_both_vacc_train:', y_both_vacc_train.shape)\n",
    "print('y_both_vacc_test:', y_both_vacc_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the preprocessor (the same one can be used for each modelling in multilabelling):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', cat_pipeline, cat_features_no_vacc)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the multilabel estimators for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Random Forest\n",
    "multilabel_est_rand_forst= MultiOutputClassifier(\n",
    "    estimator=rand_forst\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the pipeline for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Random Forest\n",
    "\n",
    "rand_forst_multilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", multilabel_est_rand_forst),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for the Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid from a previous notebook \n",
    "# will need to be adjusted in further runs \n",
    "# the pipeline step is accessed with estimators__\n",
    "\n",
    "param_grid_multilabel = {\n",
    "    'estimator__n_estimators': np.linspace(10, 200).astype(int),\n",
    "    'estimator__max_depth': [None] + list(np.linspace(3, 20).astype(int)),\n",
    "    'estimator__max_features': ['auto', 'sqrt', None] + list(np.arange(0.5, 1, 0.1)),\n",
    "    'estimator__max_leaf_nodes': [None] + list(np.linspace(10, 50, 500).astype(int)),\n",
    "    'estimator__min_samples_split': [2, 5, 10]\n",
    "    #'estimators__bootstrap': [True, False] - bootstrap cannot be used as a parameter (multioutput)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bootstrap', 'ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'max_samples', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'n_estimators', 'n_jobs', 'oob_score', 'random_state', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the random search model is created \n",
    "# we define roc_auc as our evaluation metric \n",
    "\n",
    "grid_logreg_multilabel = GridSearchCV(rand_forst_multilabel_pipeline, param_grid=param_grid_multilabel, cv=5, scoring='roc_auc', \n",
    "                           verbose=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Random Forest grid search model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30661200 candidates, totalling 153306000 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter estimator for estimator Pipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('cat',\n                                                  Pipeline(steps=[('1hot',\n                                                                   OneHotEncoder(drop='first'))]),\n                                                  ['h1n1_concern',\n                                                   'h1n1_knowledge',\n                                                   'behavioral_antiviral_meds',\n                                                   'behavioral_avoidance',\n                                                   'behavioral_face_mask',\n                                                   'behavioral_wash_hands',\n                                                   'behavioral_large_gatherings',\n                                                   'behavioral_outside_home',\n                                                   'behavioral_touch_face',\n                                                   'doctor_recc_...\n                                                   'opinion_h1n1_vacc_effective',\n                                                   'opinion_h1n1_risk',\n                                                   'opinion_h1n1_sick_from_vacc',\n                                                   'opinion_seas_vacc_effective',\n                                                   'opinion_seas_risk',\n                                                   'opinion_seas_sick_from_vacc',\n                                                   'age_group', 'education',\n                                                   'race', 'sex',\n                                                   'income_poverty',\n                                                   'marital_status',\n                                                   'rent_or_own',\n                                                   'employment_status',\n                                                   'hhs_geo_region', ...])])),\n                ('estimators',\n                 MultiOutputClassifier(estimator=RandomForestClassifier()))]). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/julianeberek/neuefische/TheFluShot/.venv/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"/Users/julianeberek/neuefische/TheFluShot/.venv/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/Users/julianeberek/neuefische/TheFluShot/.venv/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/julianeberek/neuefische/TheFluShot/.venv/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"/Users/julianeberek/neuefische/TheFluShot/.venv/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/Users/julianeberek/neuefische/TheFluShot/.venv/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 222, in __call__\n    return self.function(*args, **kwargs)\n  File \"/Users/julianeberek/neuefische/TheFluShot/.venv/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 586, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n  File \"/Users/julianeberek/neuefische/TheFluShot/.venv/lib/python3.8/site-packages/sklearn/pipeline.py\", line 150, in set_params\n    self._set_params('steps', **kwargs)\n  File \"/Users/julianeberek/neuefische/TheFluShot/.venv/lib/python3.8/site-packages/sklearn/utils/metaestimators.py\", line 54, in _set_params\n    super().set_params(**params)\n  File \"/Users/julianeberek/neuefische/TheFluShot/.venv/lib/python3.8/site-packages/sklearn/base.py\", line 230, in set_params\n    raise ValueError('Invalid parameter %s for estimator %s. '\nValueError: Invalid parameter estimator for estimator Pipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('cat',\n                                                  Pipeline(steps=[('1hot',\n                                                                   OneHotEncoder(drop='first'))]),\n                                                  ['h1n1_concern',\n                                                   'h1n1_knowledge',\n                                                   'behavioral_antiviral_meds',\n                                                   'behavioral_avoidance',\n                                                   'behavioral_face_mask',\n                                                   'behavioral_wash_hands',\n                                                   'behavioral_large_gatherings',\n                                                   'behavioral_outside_home',\n                                                   'behavioral_touch_face',\n                                                   'doctor_recc_...\n                                                   'opinion_h1n1_vacc_effective',\n                                                   'opinion_h1n1_risk',\n                                                   'opinion_h1n1_sick_from_vacc',\n                                                   'opinion_seas_vacc_effective',\n                                                   'opinion_seas_risk',\n                                                   'opinion_seas_sick_from_vacc',\n                                                   'age_group', 'education',\n                                                   'race', 'sex',\n                                                   'income_poverty',\n                                                   'marital_status',\n                                                   'rent_or_own',\n                                                   'employment_status',\n                                                   'hhs_geo_region', ...])])),\n                ('estimators',\n                 MultiOutputClassifier(estimator=RandomForestClassifier()))]). Check the list of available parameters with `estimator.get_params().keys()`.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hq/qn47frx13tx83lx6lj1c_2yh0000gn/T/ipykernel_65860/3687022830.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# for Random Forest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrand_forst_multilabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_logreg_multilabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_no_vacc_train\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0my_both_vacc_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/neuefische/TheFluShot/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neuefische/TheFluShot/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neuefische/TheFluShot/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neuefische/TheFluShot/.venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neuefische/TheFluShot/.venv/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neuefische/TheFluShot/.venv/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neuefische/TheFluShot/.venv/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.5/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.5/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter estimator for estimator Pipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('cat',\n                                                  Pipeline(steps=[('1hot',\n                                                                   OneHotEncoder(drop='first'))]),\n                                                  ['h1n1_concern',\n                                                   'h1n1_knowledge',\n                                                   'behavioral_antiviral_meds',\n                                                   'behavioral_avoidance',\n                                                   'behavioral_face_mask',\n                                                   'behavioral_wash_hands',\n                                                   'behavioral_large_gatherings',\n                                                   'behavioral_outside_home',\n                                                   'behavioral_touch_face',\n                                                   'doctor_recc_...\n                                                   'opinion_h1n1_vacc_effective',\n                                                   'opinion_h1n1_risk',\n                                                   'opinion_h1n1_sick_from_vacc',\n                                                   'opinion_seas_vacc_effective',\n                                                   'opinion_seas_risk',\n                                                   'opinion_seas_sick_from_vacc',\n                                                   'age_group', 'education',\n                                                   'race', 'sex',\n                                                   'income_poverty',\n                                                   'marital_status',\n                                                   'rent_or_own',\n                                                   'employment_status',\n                                                   'hhs_geo_region', ...])])),\n                ('estimators',\n                 MultiOutputClassifier(estimator=RandomForestClassifier()))]). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "# for Random Forest\n",
    "rand_forst_multilabel = grid_logreg_multilabel.fit(X_no_vacc_train,  y_both_vacc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show best parameters\n",
    "print('Best score:\\n{:.2f}'.format(rand_forst_multilabel.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(rand_forst_multilabel.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out later what this does and if we want to use it\n",
    "\n",
    "\n",
    "#y_train_predicted = cross_val_predict(full_pipeline, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making predictions based on train and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for logreg\n",
    "logreg_multilabel_trainpreds = logreg_multilabel.predict(X_no_vacc_train)\n",
    "logreg_multilabel_testpreds = logreg_multilabel.predict(X_no_vacc_test)\n",
    "\n",
    "# for KNN\n",
    "knn_multilabel_trainpreds = knn_multilabel.predict(X_no_vacc_train)\n",
    "knn_multilabel_testpreds = knn_multilabel.predict(X_no_vacc_test)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_multilabel_trainpreds = rand_forst_multilabel.predict(X_no_vacc_train)\n",
    "rand_forst_multilabel_testpreds = rand_forst_multilabel.predict(X_no_vacc_test)\n",
    "\n",
    "# for SVM\n",
    "svm_multilabel_trainpreds = svm_multilabel.predict(X_no_vacc_train)\n",
    "svm_multilabel_testpreds = svm_multilabel.predict(X_no_vacc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logreg--Train data evaluation Metrics for H1N1 Vaccines\n",
    "h1n1_logreg_multilabel_train_acc = accuracy_score(y_both_vacc_train[:, 0], logreg_multilabel_trainpreds[:, 0])\n",
    "h1n1_logreg_multilabel_train_recall = recall_score(y_both_vacc_train[:, 0], logreg_multilabel_trainpreds[:, 0])\n",
    "h1n1_logreg_multilabel_train_precision = precision_score(y_both_vacc_train[:, 0], logreg_multilabel_trainpreds[:, 0])\n",
    "h1n1_logreg_multilabel_train_f1 = f1_score(y_both_vacc_train[:, 0], logreg_multilabel_trainpreds[:, 0])\n",
    "h1n1_logreg_multilabel_train_roc = roc_auc_score(y_both_vacc_train[:, 0], logreg_multilabel_trainpreds[:, 0])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_train[:, 0], logreg_multilabel_trainpreds[:, 0])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_train[:, 0], logreg_multilabel_trainpreds[:, 0])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_train[:, 0], logreg_multilabel_trainpreds[:, 0])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_train[:, 0], logreg_multilabel_trainpreds[:, 0])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_train[:, 0], logreg_multilabel_trainpreds[:, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logreg--Train data Evaluation Metrics for seasonal Vaccines\n",
    "seasonal_logreg_multilabel_train_acc = accuracy_score(y_both_vacc_train[:, 1], logreg_multilabel_trainpreds[:, 1])\n",
    "seasonal_logreg_multilabel_train_recall = recall_score(y_both_vacc_train[:, 1], logreg_multilabel_trainpreds[:, 1])\n",
    "seasonal_logreg_multilabel_train_precision = precision_score(y_both_vacc_train[:, 1], logreg_multilabel_trainpreds[:, 1])\n",
    "seasonal_logreg_multilabel_train_f1 = f1_score(y_both_vacc_train[:, 1], logreg_multilabel_trainpreds[:, 1])\n",
    "seasonal_logreg_multilabel_train_roc = roc_auc_score(y_both_vacc_train[:, 1], logreg_multilabel_trainpreds[:, 1])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_train[:, 1], logreg_multilabel_trainpreds[:, 1])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_train[:, 1], logreg_multilabel_trainpreds[:, 1])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_train[:, 1], logreg_multilabel_trainpreds[:, 1])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_train[:, 1], logreg_multilabel_trainpreds[:, 1])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_train[:, 1], logreg_multilabel_trainpreds[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN--Train data evaluation Metrics for H1N1 Vaccines\n",
    "h1n1_knn_multilabel_train_acc = accuracy_score(y_both_vacc_train[:, 0], knn_multilabel_trainpreds[:, 0])\n",
    "h1n1_knn_multilabel_train_recall = recall_score(y_both_vacc_train[:, 0], knn_multilabel_trainpreds[:, 0])\n",
    "h1n1_knn_multilabel_train_precision = precision_score(y_both_vacc_train[:, 0], knn_multilabel_trainpreds[:, 0])\n",
    "h1n1_knn_multilabel_train_f1 = f1_score(y_both_vacc_train[:, 0], knn_multilabel_trainpreds[:, 0])\n",
    "h1n1_knn_multilabel_train_roc = roc_auc_score(y_both_vacc_train[:, 0], knn_multilabel_trainpreds[:, 0])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_train[:, 0], knn_multilabel_trainpreds[:, 0])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_train[:, 0], knn_multilabel_trainpreds[:, 0])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_train[:, 0], knn_multilabel_trainpreds[:, 0])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_train[:, 0], knn_multilabel_trainpreds[:, 0])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_train[:, 0], knn_multilabel_trainpreds[:, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN--Train data Evaluation Metrics for seasonal Vaccines\n",
    "seasonal_knn_multilabel_train_acc = accuracy_score(y_both_vacc_train[:, 1], knn_multilabel_trainpreds[:, 1])\n",
    "seasonal_knn_multilabel_train_recall = recall_score(y_both_vacc_train[:, 1], knn_multilabel_trainpreds[:, 1])\n",
    "seasonal_knn_multilabel_train_precision = precision_score(y_both_vacc_train[:, 1], knn_multilabel_trainpreds[:, 1])\n",
    "seasonal_knn_multilabel_train_f1 = f1_score(y_both_vacc_train[:, 1], knn_multilabel_trainpreds[:, 1])\n",
    "seasonal_knn_multilabel_train_roc = roc_auc_score(y_both_vacc_train[:, 1], knn_multilabel_trainpreds[:, 1])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_train[:, 1], knn_multilabel_trainpreds[:, 1])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_train[:, 1], knn_multilabel_trainpreds[:, 1])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_train[:, 1], knn_multilabel_trainpreds[:, 1])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_train[:, 1], knn_multilabel_trainpreds[:, 1])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_train[:, 1], knn_multilabel_trainpreds[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest--Train data evaluation Metrics for H1N1 Vaccines\n",
    "# THESE RESULTS ARE SLIGHTLY OFF FROM PREVIOUS NOTEBOOK (BY 0.01)--CHECK WHAT'S AT PLAY. VARIATION COMING FROM TEST-TRAIN SPLIT? EXPORT TEST-TRAIN DATA AS CSV AND TRY AGAIN\n",
    "#IS IT BECAUSE IT'S RANDOM FOREST? DIFFERENT STARTING STUMP EACH TIME?\n",
    "h1n1_rand_forst_multilabel_train_acc = accuracy_score(y_both_vacc_train[:, 0], rand_forst_multilabel_trainpreds[:, 0])\n",
    "h1n1_rand_forst_multilabel_train_recall = recall_score(y_both_vacc_train[:, 0], rand_forst_multilabel_trainpreds[:, 0])\n",
    "h1n1_rand_forst_multilabel_train_precision = precision_score(y_both_vacc_train[:, 0], rand_forst_multilabel_trainpreds[:, 0])\n",
    "h1n1_rand_forst_multilabel_train_f1 = f1_score(y_both_vacc_train[:, 0], rand_forst_multilabel_trainpreds[:, 0])\n",
    "h1n1_rand_forst_multilabel_train_roc = roc_auc_score(y_both_vacc_train[:, 0], rand_forst_multilabel_trainpreds[:, 0])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_train[:, 0], rand_forst_multilabel_trainpreds[:, 0])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_train[:, 0], rand_forst_multilabel_trainpreds[:, 0])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_train[:, 0], rand_forst_multilabel_trainpreds[:, 0])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_train[:, 0], rand_forst_multilabel_trainpreds[:, 0])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_train[:, 0], rand_forst_multilabel_trainpreds[:, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest--Train data Evaluation Metrics for seasonal Vaccines\n",
    "# THESE RESULTS ARE SLIGHTLY OFF FROM PREVIOUS NOTEBOOK (BY 0.01)--CHECK WHAT'S AT PLAY. VARIATION COMING FROM TEST-TRAIN SPLIT? EXPORT TEST-TRAIN DATA AS CSV AND TRY AGAIN\n",
    "#IS IT BECAUSE IT'S RANDOM FOREST? DIFFERENT STARTING STUMP EACH TIME?\n",
    "seasonal_rand_forst_multilabel_train_acc = accuracy_score(y_both_vacc_train[:, 1], rand_forst_multilabel_trainpreds[:, 1])\n",
    "seasonal_rand_forst_multilabel_train_recall = recall_score(y_both_vacc_train[:, 1], rand_forst_multilabel_trainpreds[:, 1])\n",
    "seasonal_rand_forst_multilabel_train_precision = precision_score(y_both_vacc_train[:, 1], rand_forst_multilabel_trainpreds[:, 1])\n",
    "seasonal_rand_forst_multilabel_train_f1 = f1_score(y_both_vacc_train[:, 1], rand_forst_multilabel_trainpreds[:, 1])\n",
    "seasonal_rand_forst_multilabel_train_roc = roc_auc_score(y_both_vacc_train[:, 1], rand_forst_multilabel_trainpreds[:, 1])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_train[:, 1], rand_forst_multilabel_trainpreds[:, 1])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_train[:, 1], rand_forst_multilabel_trainpreds[:, 1])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_train[:, 1], rand_forst_multilabel_trainpreds[:, 1])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_train[:, 1], rand_forst_multilabel_trainpreds[:, 1])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_train[:, 1], rand_forst_multilabel_trainpreds[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM--Train data evaluation Metrics for H1N1 Vaccines\n",
    "h1n1_svm_multilabel_train_acc = accuracy_score(y_both_vacc_train[:, 0], svm_multilabel_trainpreds[:, 0])\n",
    "h1n1_svm_multilabel_train_recall = recall_score(y_both_vacc_train[:, 0], svm_multilabel_trainpreds[:, 0])\n",
    "h1n1_svm_multilabel_train_precision = precision_score(y_both_vacc_train[:, 0], svm_multilabel_trainpreds[:, 0])\n",
    "h1n1_svm_multilabel_train_f1 = f1_score(y_both_vacc_train[:, 0], svm_multilabel_trainpreds[:, 0])\n",
    "h1n1_svm_multilabel_train_roc = roc_auc_score(y_both_vacc_train[:, 0], svm_multilabel_trainpreds[:, 0])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_train[:, 0], svm_multilabel_trainpreds[:, 0])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_train[:, 0], svm_multilabel_trainpreds[:, 0])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_train[:, 0], svm_multilabel_trainpreds[:, 0])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_train[:, 0], svm_multilabel_trainpreds[:, 0])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_train[:, 0], svm_multilabel_trainpreds[:, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM--Train data Evaluation Metrics for seasonal Vaccines\n",
    "seasonal_svm_multilabel_train_acc = accuracy_score(y_both_vacc_train[:, 1], svm_multilabel_trainpreds[:, 1])\n",
    "seasonal_svm_multilabel_train_recall = recall_score(y_both_vacc_train[:, 1], svm_multilabel_trainpreds[:, 1])\n",
    "seasonal_svm_multilabel_train_precision = precision_score(y_both_vacc_train[:, 1], svm_multilabel_trainpreds[:, 1])\n",
    "seasonal_svm_multilabel_train_f1 = f1_score(y_both_vacc_train[:, 1], svm_multilabel_trainpreds[:, 1])\n",
    "seasonal_svm_multilabel_train_roc = roc_auc_score(y_both_vacc_train[:, 1], svm_multilabel_trainpreds[:, 1])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_train[:, 1], svm_multilabel_trainpreds[:, 1])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_train[:, 1], svm_multilabel_trainpreds[:, 1])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_train[:, 1], svm_multilabel_trainpreds[:, 1])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_train[:, 1], svm_multilabel_trainpreds[:, 1])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_train[:, 1], svm_multilabel_trainpreds[:, 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logreg--Test data evaluation Metrics for H1N1 Vaccines\n",
    "h1n1_logreg_multilabel_test_acc = accuracy_score(y_both_vacc_test[:, 0], logreg_multilabel_testpreds[:, 0])\n",
    "h1n1_logreg_multilabel_test_recall = recall_score(y_both_vacc_test[:, 0], logreg_multilabel_testpreds[:, 0])\n",
    "h1n1_logreg_multilabel_test_precision = precision_score(y_both_vacc_test[:, 0], logreg_multilabel_testpreds[:, 0])\n",
    "h1n1_logreg_multilabel_test_f1 = f1_score(y_both_vacc_test[:, 0], logreg_multilabel_testpreds[:, 0])\n",
    "h1n1_logreg_multilabel_test_roc = roc_auc_score(y_both_vacc_test[:, 0], logreg_multilabel_testpreds[:, 0])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_test[:, 0], logreg_multilabel_testpreds[:, 0])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_test[:, 0], logreg_multilabel_testpreds[:, 0])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_test[:, 0], logreg_multilabel_testpreds[:, 0])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_test[:, 0], logreg_multilabel_testpreds[:, 0])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_test[:, 0], logreg_multilabel_testpreds[:, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logreg--Test data Evaluation Metrics for seasonal Vaccines\n",
    "seasonal_logreg_multilabel_test_acc = accuracy_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])\n",
    "seasonal_logreg_multilabel_test_recall = recall_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])\n",
    "seasonal_logreg_multilabel_test_precision = precision_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])\n",
    "seasonal_logreg_multilabel_test_f1 = f1_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])\n",
    "seasonal_logreg_multilabel_test_roc = roc_auc_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN--Test data evaluation Metrics for H1N1 Vaccines\n",
    "h1n1_knn_multilabel_test_acc = accuracy_score(y_both_vacc_test[:, 0], knn_multilabel_testpreds[:, 0])\n",
    "h1n1_knn_multilabel_test_recall = recall_score(y_both_vacc_test[:, 0], knn_multilabel_testpreds[:, 0])\n",
    "h1n1_knn_multilabel_test_precision = precision_score(y_both_vacc_test[:, 0], knn_multilabel_testpreds[:, 0])\n",
    "h1n1_knn_multilabel_test_f1 = f1_score(y_both_vacc_test[:, 0], knn_multilabel_testpreds[:, 0])\n",
    "h1n1_knn_multilabel_test_roc = roc_auc_score(y_both_vacc_test[:, 0], knn_multilabel_testpreds[:, 0])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_test[:, 0], knn_multilabel_testpreds[:, 0])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_test[:, 0], knn_multilabel_testpreds[:, 0])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_test[:, 0], knn_multilabel_testpreds[:, 0])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_test[:, 0], knn_multilabel_testpreds[:, 0])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_test[:, 0], knn_multilabel_testpreds[:, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN--Test data Evaluation Metrics for seasonal Vaccines\n",
    "seasonal_knn_multilabel_test_acc = accuracy_score(y_both_vacc_test[:, 1], knn_multilabel_testpreds[:, 1])\n",
    "seasonal_knn_multilabel_test_recall = recall_score(y_both_vacc_test[:, 1], knn_multilabel_testpreds[:, 1])\n",
    "seasonal_knn_multilabel_test_precision = precision_score(y_both_vacc_test[:, 1], knn_multilabel_testpreds[:, 1])\n",
    "seasonal_knn_multilabel_test_f1 = f1_score(y_both_vacc_test[:, 1], knn_multilabel_testpreds[:, 1])\n",
    "seasonal_knn_multilabel_test_roc = roc_auc_score(y_both_vacc_test[:, 1], knn_multilabel_testpreds[:, 1])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_test[:, 1], knn_multilabel_testpreds[:, 1])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_test[:, 1], knn_multilabel_testpreds[:, 1])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_test[:, 1], knn_multilabel_testpreds[:, 1])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_test[:, 1], knn_multilabel_testpreds[:, 1])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_test[:, 1], knn_multilabel_testpreds[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest--Test data evaluation Metrics for H1N1 Vaccines\n",
    "# THESE RESULTS ARE SLIGHTLY OFF FROM PREVIOUS NOTEBOOK (BY 0.01)--CHECK WHAT'S AT PLAY. VARIATION COMING FROM TEST-TRAIN SPLIT? EXPORT TEST-TRAIN DATA AS CSV AND TRY AGAIN\n",
    "#IS IT BECAUSE IT'S RANDOM FOREST? DIFFERENT STARTING STUMP EACH TIME?\n",
    "h1n1_rand_forst_multilabel_test_acc = accuracy_score(y_both_vacc_test[:, 0], rand_forst_multilabel_testpreds[:, 0])\n",
    "h1n1_rand_forst_multilabel_test_recall = recall_score(y_both_vacc_test[:, 0], rand_forst_multilabel_testpreds[:, 0])\n",
    "h1n1_rand_forst_multilabel_test_precision = precision_score(y_both_vacc_test[:, 0], rand_forst_multilabel_testpreds[:, 0])\n",
    "h1n1_rand_forst_multilabel_test_f1 = f1_score(y_both_vacc_test[:, 0], rand_forst_multilabel_testpreds[:, 0])\n",
    "h1n1_rand_forst_multilabel_test_roc = roc_auc_score(y_both_vacc_test[:, 0], rand_forst_multilabel_testpreds[:, 0])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_test[:, 0], rand_forst_multilabel_testpreds[:, 0])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_test[:, 0], rand_forst_multilabel_testpreds[:, 0])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_test[:, 0], rand_forst_multilabel_testpreds[:, 0])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_test[:, 0], rand_forst_multilabel_testpreds[:, 0])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_test[:, 0], rand_forst_multilabel_testpreds[:, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest--Test data Evaluation Metrics for seasonal Vaccines\n",
    "# THESE RESULTS ARE SLIGHTLY OFF FROM PREVIOUS NOTEBOOK (BY 0.01)--CHECK WHAT'S AT PLAY. VARIATION COMING FROM TEST-TRAIN SPLIT? EXPORT TEST-TRAIN DATA AS CSV AND TRY AGAIN\n",
    "#IS IT BECAUSE IT'S RANDOM FOREST? DIFFERENT STARTING STUMP EACH TIME?\n",
    "seasonal_rand_forst_multilabel_test_acc = accuracy_score(y_both_vacc_test[:, 1], rand_forst_multilabel_testpreds[:, 1])\n",
    "seasonal_rand_forst_multilabel_test_recall = recall_score(y_both_vacc_test[:, 1], rand_forst_multilabel_testpreds[:, 1])\n",
    "seasonal_rand_forst_multilabel_test_precision = precision_score(y_both_vacc_test[:, 1], rand_forst_multilabel_testpreds[:, 1])\n",
    "seasonal_rand_forst_multilabel_test_f1 = f1_score(y_both_vacc_test[:, 1], rand_forst_multilabel_testpreds[:, 1])\n",
    "seasonal_rand_forst_multilabel_test_roc = roc_auc_score(y_both_vacc_test[:, 1], rand_forst_multilabel_testpreds[:, 1])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_test[:, 1], rand_forst_multilabel_testpreds[:, 1])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_test[:, 1], rand_forst_multilabel_testpreds[:, 1])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_test[:, 1], rand_forst_multilabel_testpreds[:, 1])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_test[:, 1], rand_forst_multilabel_testpreds[:, 1])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_test[:, 1], rand_forst_multilabel_testpreds[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM--Test data evaluation Metrics for H1N1 Vaccines\n",
    "h1n1_svm_multilabel_test_acc = accuracy_score(y_both_vacc_test[:, 0], svm_multilabel_testpreds[:, 0])\n",
    "h1n1_svm_multilabel_test_recall = recall_score(y_both_vacc_test[:, 0], svm_multilabel_testpreds[:, 0])\n",
    "h1n1_svm_multilabel_test_precision = precision_score(y_both_vacc_test[:, 0], svm_multilabel_testpreds[:, 0])\n",
    "h1n1_svm_multilabel_test_f1 = f1_score(y_both_vacc_test[:, 0], svm_multilabel_testpreds[:, 0])\n",
    "h1n1_svm_multilabel_test_roc = roc_auc_score(y_both_vacc_test[:, 0], svm_multilabel_testpreds[:, 0])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_test[:, 0], svm_multilabel_testpreds[:, 0])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_test[:, 0], svm_multilabel_testpreds[:, 0])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_test[:, 0], svm_multilabel_testpreds[:, 0])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_test[:, 0], svm_multilabel_testpreds[:, 0])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_test[:, 0], svm_multilabel_testpreds[:, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM--Test data Evaluation Metrics for seasonal Vaccines\n",
    "seasonal_svm_multilabel_test_acc = accuracy_score(y_both_vacc_test[:, 1], svm_multilabel_testpreds[:, 1])\n",
    "seasonal_svm_multilabel_test_recall = recall_score(y_both_vacc_test[:, 1], svm_multilabel_testpreds[:, 1])\n",
    "seasonal_svm_multilabel_test_precision = precision_score(y_both_vacc_test[:, 1], svm_multilabel_testpreds[:, 1])\n",
    "seasonal_svm_multilabel_test_f1 = f1_score(y_both_vacc_test[:, 1], svm_multilabel_testpreds[:, 1])\n",
    "seasonal_svm_multilabel_test_roc = roc_auc_score(y_both_vacc_test[:, 1], svm_multilabel_testpreds[:, 1])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking the model with MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H1N1 vaccine output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_multilabel) #this needs to be adjusted for each experiment\n",
    "name = 'logreg_multilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_logreg_multilabel_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_logreg_multilabel_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_logreg_multilabel_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_logreg_multilabel_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_logreg_multilabel_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_logreg_multilabel_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_logreg_multilabel_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_logreg_multilabel_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_logreg_multilabel_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_logreg_multilabel_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_multilabel)\n",
    "name = 'knn_multilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_knn_multilabel_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_knn_multilabel_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_knn_multilabel_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_knn_multilabel_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_knn_multilabel_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_knn_multilabel_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_knn_multilabel_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_knn_multilabel_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_knn_multilabel_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_knn_multilabel_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_multilabel)\n",
    "name = 'rand_forst_multilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_rand_forst_multilabel_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_rand_forst_multilabel_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_rand_forst_multilabel_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_rand_forst_multilabel_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_rand_forst_multilabel_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_rand_forst_multilabel_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_rand_forst_multilabel_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_rand_forst_multilabel_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_rand_forst_multilabel_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_rand_forst_multilabel_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_multilabel)\n",
    "name = 'svm_multilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_svm_multilabel_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_svm_multilabel_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_svm_multilabel_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_svm_multilabel_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_svm_multilabel_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_svm_multilabel_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_svm_multilabel_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_svm_multilabel_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_svm_multilabel_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_svm_multilabel_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal vaccine output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_multilabel)\n",
    "name = 'logreg_multilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seasonal_logreg_multilabel_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seasonal_logreg_multilabel_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seasonal_logreg_multilabel_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seasonal_logreg_multilabel_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seasonal_logreg_multilabel_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seasonal_logreg_multilabel_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seasonal_logreg_multilabel_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seasonal_logreg_multilabel_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seasonal_logreg_multilabel_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seasonal_logreg_multilabel_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_multilabel)\n",
    "name = 'knn_multilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seasonal_knn_multilabel_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seasonal_knn_multilabel_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seasonal_knn_multilabel_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seasonal_knn_multilabel_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seasonal_knn_multilabel_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seasonal_knn_multilabel_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seasonal_knn_multilabel_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seasonal_knn_multilabel_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seasonal_knn_multilabel_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seasonal_knn_multilabel_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_multilabel)\n",
    "name = 'rand_forst_multilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seasonal_rand_forst_multilabel_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seasonal_rand_forst_multilabel_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seasonal_rand_forst_multilabel_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seasonal_rand_forst_multilabel_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seasonal_rand_forst_multilabel_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seasonal_rand_forst_multilabel_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seasonal_rand_forst_multilabel_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seasonal_rand_forst_multilabel_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seasonal_rand_forst_multilabel_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seasonal_rand_forst_multilabel_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_multilabel)\n",
    "name = 'svm_multilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seasonal_svm_multilabel_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seasonal_svm_multilabel_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seasonal_svm_multilabel_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seasonal_svm_multilabel_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seasonal_svm_multilabel_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seasonal_svm_multilabel_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seasonal_svm_multilabel_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seasonal_svm_multilabel_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seasonal_svm_multilabel_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seasonal_svm_multilabel_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TheFluShot_H1N1: Single Label Modelling, output H1N1 vaccine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Label Modelling, output H1N1 vaccine -> Seasonal Flu Vaccine not in features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cat_features_no_vacc and X_no_vacc variables and the preprocessor remain the same from the multilabel modelling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the target variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_h1n1_vacc = df[['h1n1_vaccine']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_h1n1_vacc = y_h1n1_vacc.to_numpy()\n",
    "y_h1n1_vacc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing test-train split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_no_vacc_train, X_no_vacc_test, y_h1n1_vacc_train, y_h1n1_vacc_test = train_test_split(X_no_vacc, y_h1n1_vacc, stratify = y_h1n1_vacc, test_size=0.2, random_state=RSEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_no_vacc_train shape:', X_no_vacc_train.shape)\n",
    "print('X_no_vacc_test shape:', X_no_vacc_test.shape)\n",
    "print('y_h1n1_vacc_train:', y_h1n1_vacc_train.shape)\n",
    "print('y_h1n1_vacc_test:', y_h1n1_vacc_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the pipeline for each model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for logreg\n",
    "logreg_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", logreg),\n",
    "])\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", knn),\n",
    "])\n",
    "\n",
    "# for Random Forest\n",
    "\n",
    "rand_forst_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", rand_forst),\n",
    "])\n",
    "\n",
    "#for SVM\n",
    "svm_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", svm),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for logreg\n",
    "logreg_unilabel_no_vacc = logreg_unilabel_pipeline.fit(X_no_vacc_train, y_h1n1_vacc_train)\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_no_vacc = knn_unilabel_pipeline.fit(X_no_vacc_train, y_h1n1_vacc_train)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_unilabel_no_vacc = rand_forst_unilabel_pipeline.fit(X_no_vacc_train, y_h1n1_vacc_train)\n",
    "\n",
    "#for SVM\n",
    "svm_unilabel_no_vacc = svm_unilabel_pipeline.fit(X_no_vacc_train, y_h1n1_vacc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out later what this does and if we want to use it\n",
    "\n",
    "\n",
    "#y_train_predicted = cross_val_predict(full_pipeline, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making predictions based on train and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for logreg\n",
    "logreg_unilabel_no_vacc_trainpreds = logreg_unilabel_no_vacc.predict(X_no_vacc_train)\n",
    "logreg_unilabel_no_vacc_testpreds = logreg_unilabel_no_vacc.predict(X_no_vacc_test)\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_no_vacc_trainpreds = knn_unilabel_no_vacc.predict(X_no_vacc_train)\n",
    "knn_unilabel_no_vacc_testpreds = knn_unilabel_no_vacc.predict(X_no_vacc_test)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_unilabel_no_vacc_trainpreds = rand_forst_unilabel_no_vacc.predict(X_no_vacc_train)\n",
    "rand_forst_unilabel_no_vacc_testpreds = rand_forst_unilabel_no_vacc.predict(X_no_vacc_test)\n",
    "\n",
    "# for SVM\n",
    "svm_unilabel_no_vacc_trainpreds = svm_unilabel_no_vacc.predict(X_no_vacc_train)\n",
    "svm_unilabel_no_vacc_testpreds = svm_unilabel_no_vacc.predict(X_no_vacc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logreg--Train data evaluation Metrics\n",
    "h1n1_logreg_unilabel_no_vacc_train_acc = accuracy_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_trainpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_train_recall = recall_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_trainpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_train_precision = precision_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_trainpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_train_f1 = f1_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_trainpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_train_roc = roc_auc_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_trainpreds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN--Train data evaluation Metrics\n",
    "h1n1_knn_unilabel_no_vacc_train_acc = accuracy_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_trainpreds)\n",
    "h1n1_knn_unilabel_no_vacc_train_recall = recall_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_trainpreds)\n",
    "h1n1_knn_unilabel_no_vacc_train_precision = precision_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_trainpreds)\n",
    "h1n1_knn_unilabel_no_vacc_train_f1 = f1_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_trainpreds)\n",
    "h1n1_knn_unilabel_no_vacc_train_roc = roc_auc_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_trainpreds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest--Train data evaluation Metrics\n",
    "#check if these metrics are changing compared to previous results\n",
    "h1n1_rand_forst_unilabel_no_vacc_train_acc = accuracy_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_train_recall = recall_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_train_precision = precision_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_train_f1 = f1_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_train_roc = roc_auc_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM--Train data evaluation Metrics\n",
    "h1n1_svm_unilabel_no_vacc_train_acc = accuracy_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_trainpreds)\n",
    "h1n1_svm_unilabel_no_vacc_train_recall = recall_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_trainpreds)\n",
    "h1n1_svm_unilabel_no_vacc_train_precision = precision_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_trainpreds)\n",
    "h1n1_svm_unilabel_no_vacc_train_f1 = f1_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_trainpreds)\n",
    "h1n1_svm_unilabel_no_vacc_train_roc = roc_auc_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_trainpreds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logreg--Test data evaluation Metrics\n",
    "h1n1_logreg_unilabel_no_vacc_test_acc = accuracy_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_testpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_test_recall = recall_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_testpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_test_precision = precision_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_testpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_test_f1 = f1_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_testpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_test_roc = roc_auc_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_testpreds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN--Test data evaluation Metrics\n",
    "h1n1_knn_unilabel_no_vacc_test_acc = accuracy_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_testpreds)\n",
    "h1n1_knn_unilabel_no_vacc_test_recall = recall_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_testpreds)\n",
    "h1n1_knn_unilabel_no_vacc_test_precision = precision_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_testpreds)\n",
    "h1n1_knn_unilabel_no_vacc_test_f1 = f1_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_testpreds)\n",
    "h1n1_knn_unilabel_no_vacc_test_roc = roc_auc_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_testpreds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest--Test data evaluation Metrics\n",
    "#check if these metrics are changing compared to previous results\n",
    "h1n1_rand_forst_unilabel_no_vacc_test_acc = accuracy_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_testpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_test_recall = recall_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_testpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_test_precision = precision_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_testpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_test_f1 = f1_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_testpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_test_roc = roc_auc_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_testpreds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM--Test data evaluation Metrics\n",
    "h1n1_svm_unilabel_no_vacc_test_acc = accuracy_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_testpreds)\n",
    "h1n1_svm_unilabel_no_vacc_test_recall = recall_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_testpreds)\n",
    "h1n1_svm_unilabel_no_vacc_test_precision = precision_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_testpreds)\n",
    "h1n1_svm_unilabel_no_vacc_test_f1 = f1_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_testpreds)\n",
    "h1n1_svm_unilabel_no_vacc_test_roc = roc_auc_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_testpreds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking the model with MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H1N1 vaccine output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_h1n1) #this needs to be adjusted for each experiment\n",
    "name = 'logreg_unilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_logreg_unilabel_no_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_logreg_unilabel_no_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_logreg_unilabel_no_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_logreg_unilabel_no_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_logreg_unilabel_no_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_logreg_unilabel_no_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_logreg_unilabel_no_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_logreg_unilabel_no_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_logreg_unilabel_no_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_logreg_unilabel_no_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_h1n1)\n",
    "name = 'knn_unilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_knn_unilabel_no_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_knn_unilabel_no_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_knn_unilabel_no_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_knn_unilabel_no_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_knn_unilabel_no_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_knn_unilabel_no_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_knn_unilabel_no_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_knn_unilabel_no_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_knn_unilabel_no_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_knn_unilabel_no_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_h1n1)\n",
    "name = 'rand_forst_unilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_rand_forst_unilabel_no_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_rand_forst_unilabel_no_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_rand_forst_unilabel_no_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_rand_forst_unilabel_no_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_rand_forst_unilabel_no_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_rand_forst_unilabel_no_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_rand_forst_unilabel_no_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_rand_forst_unilabel_no_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_rand_forst_unilabel_no_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_rand_forst_unilabel_no_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_h1n1)\n",
    "name = 'svm_unilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_svm_unilabel_no_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_svm_unilabel_no_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_svm_unilabel_no_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_svm_unilabel_no_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_svm_unilabel_no_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_svm_unilabel_no_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_svm_unilabel_no_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_svm_unilabel_no_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_svm_unilabel_no_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_svm_unilabel_no_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Label Modelling, output H1N1 vaccine -> Seasonal Flu Vaccine is in features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The y_h1n1_vacc remains the same from the previous model; the X feature and cat_features (for the preprocessor) need to be adjusted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features_seas_vacc = cat_features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features_seas_vacc.remove('h1n1_vaccine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NB: dropping the 'h1n1_vaccine' and 'seasonal_vaccine' columns\n",
    "X_seas_vacc = df.drop(columns=['h1n1_vaccine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seas_vacc.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing test-train split (the same data can be used for each model in multilabelling):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seas_vacc_train, X_seas_vacc_test, y_h1n1_vacc_train, y_h1n1_vacc_test = train_test_split(X_seas_vacc, y_h1n1_vacc, stratify = y_h1n1_vacc, test_size=0.2, random_state=RSEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_seas_vacc_train shape:', X_seas_vacc_train.shape)\n",
    "print('X_seas_vacc_test shape:', X_seas_vacc_test.shape)\n",
    "print('y_h1n1_vacc_train:', y_h1n1_vacc_train.shape)\n",
    "print('y_h1n1_vacc_test:', y_h1n1_vacc_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessor is adjusted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_seas_vacc = ColumnTransformer([\n",
    "    ('cat', cat_pipeline, cat_features_seas_vacc)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline is adjusted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for logreg\n",
    "logreg_seas_vacc_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_seas_vacc),\n",
    "    (\"estimators\", logreg),\n",
    "])\n",
    "\n",
    "# for KNN\n",
    "knn_seas_vacc_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_seas_vacc),\n",
    "    (\"estimators\", knn),\n",
    "])\n",
    "\n",
    "# for Random Forest\n",
    "\n",
    "rand_forst_seas_vacc_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_seas_vacc),\n",
    "    (\"estimators\", rand_forst),\n",
    "])\n",
    "\n",
    "#for SVM\n",
    "svm_seas_vacc_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_seas_vacc),\n",
    "    (\"estimators\", svm),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for logreg\n",
    "logreg_unilabel_seas_vacc = logreg_seas_vacc_unilabel_pipeline.fit(X_seas_vacc_train, y_h1n1_vacc_train)\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_seas_vacc = knn_seas_vacc_unilabel_pipeline.fit(X_seas_vacc_train, y_h1n1_vacc_train)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_unilabel_seas_vacc = rand_forst_seas_vacc_unilabel_pipeline.fit(X_seas_vacc_train, y_h1n1_vacc_train)\n",
    "\n",
    "#for SVM\n",
    "svm_unilabel_seas_vacc = svm_seas_vacc_unilabel_pipeline.fit(X_seas_vacc_train, y_h1n1_vacc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out later what this does and if we want to use it\n",
    "\n",
    "\n",
    "#y_train_predicted = cross_val_predict(full_pipeline, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making predictions based on train and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for logreg\n",
    "logreg_unilabel_seas_vacc_trainpreds = logreg_unilabel_seas_vacc.predict(X_seas_vacc_train)\n",
    "logreg_unilabel_seas_vacc_testpreds = logreg_unilabel_seas_vacc.predict(X_seas_vacc_test)\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_seas_vacc_trainpreds = knn_unilabel_seas_vacc.predict(X_seas_vacc_train)\n",
    "knn_unilabel_seas_vacc_testpreds = knn_unilabel_seas_vacc.predict(X_seas_vacc_test)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_unilabel_seas_vacc_trainpreds = rand_forst_unilabel_seas_vacc.predict(X_seas_vacc_train)\n",
    "rand_forst_unilabel_seas_vacc_testpreds = rand_forst_unilabel_seas_vacc.predict(X_seas_vacc_test)\n",
    "\n",
    "# for SVM\n",
    "svm_unilabel_seas_vacc_trainpreds = svm_unilabel_seas_vacc.predict(X_seas_vacc_train)\n",
    "svm_unilabel_seas_vacc_testpreds = svm_unilabel_seas_vacc.predict(X_seas_vacc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logreg--Train data evaluation Metrics\n",
    "h1n1_logreg_unilabel_seas_vacc_train_acc = accuracy_score(y_h1n1_vacc_train, logreg_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_logreg_unilabel_seas_vacc_train_recall = recall_score(y_h1n1_vacc_train, logreg_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_logreg_unilabel_seas_vacc_train_precision = precision_score(y_h1n1_vacc_train, logreg_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_logreg_unilabel_seas_vacc_train_f1 = f1_score(y_h1n1_vacc_train, logreg_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_logreg_unilabel_seas_vacc_train_roc = roc_auc_score(y_h1n1_vacc_train, logreg_unilabel_seas_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_train, logreg_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_train, logreg_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_train, logreg_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_train, logreg_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_train, logreg_unilabel_seas_vacc_trainpreds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN--Train data evaluation Metrics\n",
    "h1n1_knn_unilabel_seas_vacc_train_acc = accuracy_score(y_h1n1_vacc_train, knn_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_knn_unilabel_seas_vacc_train_recall = recall_score(y_h1n1_vacc_train, knn_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_knn_unilabel_seas_vacc_train_precision = precision_score(y_h1n1_vacc_train, knn_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_knn_unilabel_seas_vacc_train_f1 = f1_score(y_h1n1_vacc_train, knn_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_knn_unilabel_seas_vacc_train_roc = roc_auc_score(y_h1n1_vacc_train, knn_unilabel_seas_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_train, knn_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_train, knn_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_train, knn_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_train, knn_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_train, knn_unilabel_seas_vacc_trainpreds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest--Train data evaluation Metrics\n",
    "#check if these metrics are changing compared to previous results\n",
    "h1n1_rand_forst_unilabel_seas_vacc_train_acc = accuracy_score(y_h1n1_vacc_train, rand_forst_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_rand_forst_unilabel_seas_vacc_train_recall = recall_score(y_h1n1_vacc_train, rand_forst_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_rand_forst_unilabel_seas_vacc_train_precision = precision_score(y_h1n1_vacc_train, rand_forst_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_rand_forst_unilabel_seas_vacc_train_f1 = f1_score(y_h1n1_vacc_train, rand_forst_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_rand_forst_unilabel_seas_vacc_train_roc = roc_auc_score(y_h1n1_vacc_train, rand_forst_unilabel_seas_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_train, rand_forst_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_train, rand_forst_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_train, rand_forst_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_train, rand_forst_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_train, rand_forst_unilabel_seas_vacc_trainpreds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM--Train data evaluation Metrics\n",
    "h1n1_svm_unilabel_seas_vacc_train_acc = accuracy_score(y_h1n1_vacc_train, svm_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_svm_unilabel_seas_vacc_train_recall = recall_score(y_h1n1_vacc_train, svm_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_svm_unilabel_seas_vacc_train_precision = precision_score(y_h1n1_vacc_train, svm_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_svm_unilabel_seas_vacc_train_f1 = f1_score(y_h1n1_vacc_train, svm_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_svm_unilabel_seas_vacc_train_roc = roc_auc_score(y_h1n1_vacc_train, svm_unilabel_seas_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_train, svm_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_train, svm_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_train, svm_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_train, svm_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_train, svm_unilabel_seas_vacc_trainpreds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logreg--Test data evaluation Metrics\n",
    "h1n1_logreg_unilabel_seas_vacc_test_acc = accuracy_score(y_h1n1_vacc_test, logreg_unilabel_seas_vacc_testpreds)\n",
    "h1n1_logreg_unilabel_seas_vacc_test_recall = recall_score(y_h1n1_vacc_test, logreg_unilabel_seas_vacc_testpreds)\n",
    "h1n1_logreg_unilabel_seas_vacc_test_precision = precision_score(y_h1n1_vacc_test, logreg_unilabel_seas_vacc_testpreds)\n",
    "h1n1_logreg_unilabel_seas_vacc_test_f1 = f1_score(y_h1n1_vacc_test, logreg_unilabel_seas_vacc_testpreds)\n",
    "h1n1_logreg_unilabel_seas_vacc_test_roc = roc_auc_score(y_h1n1_vacc_test, logreg_unilabel_seas_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_test, logreg_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_test, logreg_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_test, logreg_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_test, logreg_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_test, logreg_unilabel_seas_vacc_testpreds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN--Test data evaluation Metrics\n",
    "h1n1_knn_unilabel_seas_vacc_test_acc = accuracy_score(y_h1n1_vacc_test, knn_unilabel_seas_vacc_testpreds)\n",
    "h1n1_knn_unilabel_seas_vacc_test_recall = recall_score(y_h1n1_vacc_test, knn_unilabel_seas_vacc_testpreds)\n",
    "h1n1_knn_unilabel_seas_vacc_test_precision = precision_score(y_h1n1_vacc_test, knn_unilabel_seas_vacc_testpreds)\n",
    "h1n1_knn_unilabel_seas_vacc_test_f1 = f1_score(y_h1n1_vacc_test, knn_unilabel_seas_vacc_testpreds)\n",
    "h1n1_knn_unilabel_seas_vacc_test_roc = roc_auc_score(y_h1n1_vacc_test, knn_unilabel_seas_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_test, knn_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_test, knn_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_test, knn_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_test, knn_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_test, knn_unilabel_seas_vacc_testpreds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest--Test data evaluation Metrics\n",
    "#check if these metrics are changing compared to previous results\n",
    "h1n1_rand_forst_unilabel_seas_vacc_test_acc = accuracy_score(y_h1n1_vacc_test, rand_forst_unilabel_seas_vacc_testpreds)\n",
    "h1n1_rand_forst_unilabel_seas_vacc_test_recall = recall_score(y_h1n1_vacc_test, rand_forst_unilabel_seas_vacc_testpreds)\n",
    "h1n1_rand_forst_unilabel_seas_vacc_test_precision = precision_score(y_h1n1_vacc_test, rand_forst_unilabel_seas_vacc_testpreds)\n",
    "h1n1_rand_forst_unilabel_seas_vacc_test_f1 = f1_score(y_h1n1_vacc_test, rand_forst_unilabel_seas_vacc_testpreds)\n",
    "h1n1_rand_forst_unilabel_seas_vacc_test_roc = roc_auc_score(y_h1n1_vacc_test, rand_forst_unilabel_seas_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_test, rand_forst_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_test, rand_forst_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_test, rand_forst_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_test, rand_forst_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_test, rand_forst_unilabel_seas_vacc_testpreds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM--Test data evaluation Metrics\n",
    "h1n1_svm_unilabel_seas_vacc_test_acc = accuracy_score(y_h1n1_vacc_test, svm_unilabel_seas_vacc_testpreds)\n",
    "h1n1_svm_unilabel_seas_vacc_test_recall = recall_score(y_h1n1_vacc_test, svm_unilabel_seas_vacc_testpreds)\n",
    "h1n1_svm_unilabel_seas_vacc_test_precision = precision_score(y_h1n1_vacc_test, svm_unilabel_seas_vacc_testpreds)\n",
    "h1n1_svm_unilabel_seas_vacc_test_f1 = f1_score(y_h1n1_vacc_test, svm_unilabel_seas_vacc_testpreds)\n",
    "h1n1_svm_unilabel_seas_vacc_test_roc = roc_auc_score(y_h1n1_vacc_test, svm_unilabel_seas_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_test, svm_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_test, svm_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_test, svm_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_test, svm_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_test, svm_unilabel_seas_vacc_testpreds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking the model with MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H1N1 vaccine output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_h1n1) #this needs to be adjusted for each experiment\n",
    "name = 'logreg_unilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"Seasonal\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_logreg_unilabel_seas_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_logreg_unilabel_seas_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_logreg_unilabel_seas_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_logreg_unilabel_seas_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_logreg_unilabel_seas_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_logreg_unilabel_seas_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_logreg_unilabel_seas_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_logreg_unilabel_seas_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_logreg_unilabel_seas_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_logreg_unilabel_seas_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_h1n1)\n",
    "name = 'knn_unilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"Seasonal\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_knn_unilabel_seas_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_knn_unilabel_seas_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_knn_unilabel_seas_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_knn_unilabel_seas_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_knn_unilabel_seas_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_knn_unilabel_seas_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_knn_unilabel_seas_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_knn_unilabel_seas_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_knn_unilabel_seas_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_knn_unilabel_seas_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_h1n1)\n",
    "name = 'rand_forst_unilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"Seasonal\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_rand_forst_unilabel_seas_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_rand_forst_unilabel_seas_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_rand_forst_unilabel_seas_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_rand_forst_unilabel_seas_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_rand_forst_unilabel_seas_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_rand_forst_unilabel_seas_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_rand_forst_unilabel_seas_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_rand_forst_unilabel_seas_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_rand_forst_unilabel_seas_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_rand_forst_unilabel_seas_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_h1n1)\n",
    "name = 'svm_unilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"Seasonal\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_svm_unilabel_seas_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_svm_unilabel_seas_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_svm_unilabel_seas_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_svm_unilabel_seas_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_svm_unilabel_seas_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_svm_unilabel_seas_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_svm_unilabel_seas_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_svm_unilabel_seas_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_svm_unilabel_seas_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_svm_unilabel_seas_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TheFluShot_seasonal: Single Label Modelling, output seasonal vaccine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Label Modelling, output seasonal vaccine -> H1N1 Flu Vaccine not in features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cat_features_no_vacc and X_no_vacc variables and the preprocessor remain the same from the multilabel modelling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the target variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_seas_vacc = df['seasonal_vaccine'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_seas_vacc = y_seas_vacc.to_numpy()\n",
    "y_seas_vacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_seas_vacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing test-train split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_no_vacc_train, X_no_vacc_test, y_seas_vacc_train, y_seas_vacc_test = train_test_split(X_no_vacc, y_seas_vacc, stratify = y_seas_vacc, test_size=0.2, random_state=RSEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_no_vacc_train shape:', X_no_vacc_train.shape)\n",
    "print('X_no_vacc_test shape:', X_no_vacc_test.shape)\n",
    "print('y_seas_vacc_train:', y_seas_vacc_train.shape)\n",
    "print('y_seas_vacc_test:', y_seas_vacc_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the pipeline for each model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for logreg\n",
    "logreg_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", logreg),\n",
    "])\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", knn),\n",
    "])\n",
    "\n",
    "# for Random Forest\n",
    "\n",
    "rand_forst_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", rand_forst),\n",
    "])\n",
    "\n",
    "#for SVM\n",
    "svm_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", svm),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for logreg\n",
    "logreg_unilabel_no_vacc = logreg_unilabel_pipeline.fit(X_no_vacc_train, y_seas_vacc_train)\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_no_vacc = knn_unilabel_pipeline.fit(X_no_vacc_train, y_seas_vacc_train)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_unilabel_no_vacc = rand_forst_unilabel_pipeline.fit(X_no_vacc_train, y_seas_vacc_train)\n",
    "\n",
    "#for SVM\n",
    "svm_unilabel_no_vacc = svm_unilabel_pipeline.fit(X_no_vacc_train, y_seas_vacc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out later what this does and if we want to use it\n",
    "\n",
    "\n",
    "#y_train_predicted = cross_val_predict(full_pipeline, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making predictions based on train and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for logreg\n",
    "logreg_unilabel_no_vacc_trainpreds = logreg_unilabel_no_vacc.predict(X_no_vacc_train)\n",
    "logreg_unilabel_no_vacc_testpreds = logreg_unilabel_no_vacc.predict(X_no_vacc_test)\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_no_vacc_trainpreds = knn_unilabel_no_vacc.predict(X_no_vacc_train)\n",
    "knn_unilabel_no_vacc_testpreds = knn_unilabel_no_vacc.predict(X_no_vacc_test)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_unilabel_no_vacc_trainpreds = rand_forst_unilabel_no_vacc.predict(X_no_vacc_train)\n",
    "rand_forst_unilabel_no_vacc_testpreds = rand_forst_unilabel_no_vacc.predict(X_no_vacc_test)\n",
    "\n",
    "# for SVM\n",
    "svm_unilabel_no_vacc_trainpreds = svm_unilabel_no_vacc.predict(X_no_vacc_train)\n",
    "svm_unilabel_no_vacc_testpreds = svm_unilabel_no_vacc.predict(X_no_vacc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logreg--Train data evaluation Metrics\n",
    "seas_logreg_unilabel_no_vacc_train_acc = accuracy_score(y_seas_vacc_train, logreg_unilabel_no_vacc_trainpreds)\n",
    "seas_logreg_unilabel_no_vacc_train_recall = recall_score(y_seas_vacc_train, logreg_unilabel_no_vacc_trainpreds)\n",
    "seas_logreg_unilabel_no_vacc_train_precision = precision_score(y_seas_vacc_train, logreg_unilabel_no_vacc_trainpreds)\n",
    "seas_logreg_unilabel_no_vacc_train_f1 = f1_score(y_seas_vacc_train, logreg_unilabel_no_vacc_trainpreds)\n",
    "seas_logreg_unilabel_no_vacc_train_roc = roc_auc_score(y_seas_vacc_train, logreg_unilabel_no_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_train, logreg_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_train, logreg_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_train, logreg_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_train, logreg_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_train, logreg_unilabel_no_vacc_trainpreds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN--Train data evaluation Metrics\n",
    "seas_knn_unilabel_no_vacc_train_acc = accuracy_score(y_seas_vacc_train, knn_unilabel_no_vacc_trainpreds)\n",
    "seas_knn_unilabel_no_vacc_train_recall = recall_score(y_seas_vacc_train, knn_unilabel_no_vacc_trainpreds)\n",
    "seas_knn_unilabel_no_vacc_train_precision = precision_score(y_seas_vacc_train, knn_unilabel_no_vacc_trainpreds)\n",
    "seas_knn_unilabel_no_vacc_train_f1 = f1_score(y_seas_vacc_train, knn_unilabel_no_vacc_trainpreds)\n",
    "seas_knn_unilabel_no_vacc_train_roc = roc_auc_score(y_seas_vacc_train, knn_unilabel_no_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_train, knn_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_train, knn_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_train, knn_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_train, knn_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_train, knn_unilabel_no_vacc_trainpreds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest--Train data evaluation Metrics\n",
    "#check if these metrics are changing compared to previous results\n",
    "seas_rand_forst_unilabel_no_vacc_train_acc = accuracy_score(y_seas_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)\n",
    "seas_rand_forst_unilabel_no_vacc_train_recall = recall_score(y_seas_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)\n",
    "seas_rand_forst_unilabel_no_vacc_train_precision = precision_score(y_seas_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)\n",
    "seas_rand_forst_unilabel_no_vacc_train_f1 = f1_score(y_seas_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)\n",
    "seas_rand_forst_unilabel_no_vacc_train_roc = roc_auc_score(y_seas_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM--Train data evaluation Metrics\n",
    "seas_svm_unilabel_no_vacc_train_acc = accuracy_score(y_seas_vacc_train, svm_unilabel_no_vacc_trainpreds)\n",
    "seas_svm_unilabel_no_vacc_train_recall = recall_score(y_seas_vacc_train, svm_unilabel_no_vacc_trainpreds)\n",
    "seas_svm_unilabel_no_vacc_train_precision = precision_score(y_seas_vacc_train, svm_unilabel_no_vacc_trainpreds)\n",
    "seas_svm_unilabel_no_vacc_train_f1 = f1_score(y_seas_vacc_train, svm_unilabel_no_vacc_trainpreds)\n",
    "seas_svm_unilabel_no_vacc_train_roc = roc_auc_score(y_seas_vacc_train, svm_unilabel_no_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_train, svm_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_train, svm_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_train, svm_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_train, svm_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_train, svm_unilabel_no_vacc_trainpreds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logreg--Test data evaluation Metrics\n",
    "seas_logreg_unilabel_no_vacc_test_acc = accuracy_score(y_seas_vacc_test, logreg_unilabel_no_vacc_testpreds)\n",
    "seas_logreg_unilabel_no_vacc_test_recall = recall_score(y_seas_vacc_test, logreg_unilabel_no_vacc_testpreds)\n",
    "seas_logreg_unilabel_no_vacc_test_precision = precision_score(y_seas_vacc_test, logreg_unilabel_no_vacc_testpreds)\n",
    "seas_logreg_unilabel_no_vacc_test_f1 = f1_score(y_seas_vacc_test, logreg_unilabel_no_vacc_testpreds)\n",
    "seas_logreg_unilabel_no_vacc_test_roc = roc_auc_score(y_seas_vacc_test, logreg_unilabel_no_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_test, logreg_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_test, logreg_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_test, logreg_unilabel_no_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_test, logreg_unilabel_no_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_test, logreg_unilabel_no_vacc_testpreds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN--Test data evaluation Metrics\n",
    "seas_knn_unilabel_no_vacc_test_acc = accuracy_score(y_seas_vacc_test, knn_unilabel_no_vacc_testpreds)\n",
    "seas_knn_unilabel_no_vacc_test_recall = recall_score(y_seas_vacc_test, knn_unilabel_no_vacc_testpreds)\n",
    "seas_knn_unilabel_no_vacc_test_precision = precision_score(y_seas_vacc_test, knn_unilabel_no_vacc_testpreds)\n",
    "seas_knn_unilabel_no_vacc_test_f1 = f1_score(y_seas_vacc_test, knn_unilabel_no_vacc_testpreds)\n",
    "seas_knn_unilabel_no_vacc_test_roc = roc_auc_score(y_seas_vacc_test, knn_unilabel_no_vacc_testpreds)\n",
    "\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_test, knn_unilabel_no_vacc_testpreds)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_test, knn_unilabel_no_vacc_testpreds)))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_test, knn_unilabel_no_vacc_testpreds)))\n",
    "print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_test, knn_unilabel_no_vacc_testpreds)))\n",
    "print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_test, knn_unilabel_no_vacc_testpreds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(seas_knn_unilabel_no_vacc_test_acc)\n",
    "print(seas_knn_unilabel_no_vacc_test_recall)\n",
    "print(seas_knn_unilabel_no_vacc_test_precision)\n",
    "print(seas_knn_unilabel_no_vacc_test_f1)\n",
    "print(seas_knn_unilabel_no_vacc_test_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest--Test data evaluation Metrics\n",
    "#check if these metrics are changing compared to previous results\n",
    "seas_rand_forst_unilabel_no_vacc_test_acc = accuracy_score(y_seas_vacc_test, rand_forst_unilabel_no_vacc_testpreds)\n",
    "seas_rand_forst_unilabel_no_vacc_test_recall = recall_score(y_seas_vacc_test, rand_forst_unilabel_no_vacc_testpreds)\n",
    "seas_rand_forst_unilabel_no_vacc_test_precision = precision_score(y_seas_vacc_test, rand_forst_unilabel_no_vacc_testpreds)\n",
    "seas_rand_forst_unilabel_no_vacc_test_f1 = f1_score(y_seas_vacc_test, rand_forst_unilabel_no_vacc_testpreds)\n",
    "seas_rand_forst_unilabel_no_vacc_test_roc = roc_auc_score(y_seas_vacc_test, rand_forst_unilabel_no_vacc_testpreds)\n",
    "\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_test, rand_forst_unilabel_no_vacc_testpreds)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_test, rand_forst_unilabel_no_vacc_testpreds)))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_test, rand_forst_unilabel_no_vacc_testpreds)))\n",
    "print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_test, rand_forst_unilabel_no_vacc_testpreds)))\n",
    "print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_test, rand_forst_unilabel_no_vacc_testpreds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(seas_rand_forst_unilabel_no_vacc_test_acc)\n",
    "print(seas_rand_forst_unilabel_no_vacc_test_recall)\n",
    "print(seas_rand_forst_unilabel_no_vacc_test_precision)\n",
    "print(seas_rand_forst_unilabel_no_vacc_test_f1)\n",
    "print(seas_rand_forst_unilabel_no_vacc_test_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM--Test data evaluation Metrics\n",
    "seas_svm_unilabel_no_vacc_test_acc = accuracy_score(y_seas_vacc_test, svm_unilabel_no_vacc_testpreds)\n",
    "seas_svm_unilabel_no_vacc_test_recall = recall_score(y_seas_vacc_test, svm_unilabel_no_vacc_testpreds)\n",
    "seas_svm_unilabel_no_vacc_test_precision = precision_score(y_seas_vacc_test, svm_unilabel_no_vacc_testpreds)\n",
    "seas_svm_unilabel_no_vacc_test_f1 = f1_score(y_seas_vacc_test, svm_unilabel_no_vacc_testpreds)\n",
    "seas_svm_unilabel_no_vacc_test_roc = roc_auc_score(y_seas_vacc_test, svm_unilabel_no_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_test, svm_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_test, svm_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_test, svm_unilabel_no_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_test, svm_unilabel_no_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_test, svm_unilabel_no_vacc_testpreds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking the model with MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal vaccine output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_seasonal) #this needs to be adjusted for each experiment\n",
    "name = 'logreg_unilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seas_logreg_unilabel_no_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seas_logreg_unilabel_no_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seas_logreg_unilabel_no_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seas_logreg_unilabel_no_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seas_logreg_unilabel_no_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seas_logreg_unilabel_no_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seas_logreg_unilabel_no_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seas_logreg_unilabel_no_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seas_logreg_unilabel_no_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seas_logreg_unilabel_no_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_seasonal)\n",
    "name = 'knn_unilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seas_knn_unilabel_no_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seas_knn_unilabel_no_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seas_knn_unilabel_no_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seas_knn_unilabel_no_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seas_knn_unilabel_no_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seas_knn_unilabel_no_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seas_knn_unilabel_no_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seas_knn_unilabel_no_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seas_knn_unilabel_no_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seas_knn_unilabel_no_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_seasonal)\n",
    "name = 'rand_forst_unilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seas_rand_forst_unilabel_no_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seas_rand_forst_unilabel_no_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seas_rand_forst_unilabel_no_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seas_rand_forst_unilabel_no_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seas_rand_forst_unilabel_no_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seas_rand_forst_unilabel_no_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seas_rand_forst_unilabel_no_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seas_rand_forst_unilabel_no_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seas_rand_forst_unilabel_no_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seas_rand_forst_unilabel_no_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_seasonal)\n",
    "name = 'svm_unilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seas_svm_unilabel_no_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seas_svm_unilabel_no_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seas_svm_unilabel_no_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seas_svm_unilabel_no_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seas_svm_unilabel_no_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seas_svm_unilabel_no_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seas_svm_unilabel_no_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seas_svm_unilabel_no_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seas_svm_unilabel_no_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seas_svm_unilabel_no_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Label Modelling, output seasonal vaccine -> H1N1 Flu Vaccine is in features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The y_seas_vacc remains the same from the previous model; the X feature and cat_features (for the preprocessor) need to be adjusted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features_h1n1_vacc = cat_features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features_h1n1_vacc.remove('seasonal_vaccine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NB: dropping the 'h1n1_vaccine' and 'seasonal_vaccine' columns\n",
    "X_h1n1_vacc = df.drop(columns=['seasonal_vaccine'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing test-train split (the same data can be used for each model in multilabelling):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_h1n1_vacc_train, X_h1n1_vacc_test, y_seas_vacc_train, y_seas_vacc_test = train_test_split(X_h1n1_vacc, y_seas_vacc, stratify = y_seas_vacc, test_size=0.2, random_state=RSEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_h1n1_vacc_train shape:', X_h1n1_vacc_train.shape)\n",
    "print('X_h1n1_vacc_test shape:', X_h1n1_vacc_test.shape)\n",
    "print('y_seas_vacc_train:', y_seas_vacc_train.shape)\n",
    "print('y_seas_vacc_test:', y_seas_vacc_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preprocessor is adjusted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_h1n1_vacc = ColumnTransformer([\n",
    "    ('cat', cat_pipeline, cat_features_h1n1_vacc)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline is adjusted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for logreg\n",
    "logreg_h1n1_vacc_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_h1n1_vacc),\n",
    "    (\"estimators\", logreg),\n",
    "])\n",
    "\n",
    "# for KNN\n",
    "knn_h1n1_vacc_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_h1n1_vacc),\n",
    "    (\"estimators\", knn),\n",
    "])\n",
    "\n",
    "# for Random Forest\n",
    "\n",
    "rand_forst_h1n1_vacc_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_h1n1_vacc),\n",
    "    (\"estimators\", rand_forst),\n",
    "])\n",
    "\n",
    "#for SVM\n",
    "svm_h1n1_vacc_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_h1n1_vacc),\n",
    "    (\"estimators\", svm),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for logreg\n",
    "logreg_unilabel_h1n1_vacc = logreg_h1n1_vacc_unilabel_pipeline.fit(X_h1n1_vacc_train, y_seas_vacc_train)\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_h1n1_vacc = knn_h1n1_vacc_unilabel_pipeline.fit(X_h1n1_vacc_train, y_seas_vacc_train)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_unilabel_h1n1_vacc = rand_forst_h1n1_vacc_unilabel_pipeline.fit(X_h1n1_vacc_train, y_seas_vacc_train)\n",
    "\n",
    "#for SVM\n",
    "svm_unilabel_h1n1_vacc = svm_h1n1_vacc_unilabel_pipeline.fit(X_h1n1_vacc_train, y_seas_vacc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out later what this does and if we want to use it\n",
    "\n",
    "\n",
    "#y_train_predicted = cross_val_predict(full_pipeline, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making predictions based on train and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for logreg\n",
    "logreg_unilabel_h1n1_vacc_trainpreds = logreg_unilabel_h1n1_vacc.predict(X_h1n1_vacc_train)\n",
    "logreg_unilabel_h1n1_vacc_testpreds = logreg_unilabel_h1n1_vacc.predict(X_h1n1_vacc_test)\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_h1n1_vacc_trainpreds = knn_unilabel_h1n1_vacc.predict(X_h1n1_vacc_train)\n",
    "knn_unilabel_h1n1_vacc_testpreds = knn_unilabel_h1n1_vacc.predict(X_h1n1_vacc_test)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_unilabel_h1n1_vacc_trainpreds = rand_forst_unilabel_h1n1_vacc.predict(X_h1n1_vacc_train)\n",
    "rand_forst_unilabel_h1n1_vacc_testpreds = rand_forst_unilabel_h1n1_vacc.predict(X_h1n1_vacc_test)\n",
    "\n",
    "# for SVM\n",
    "svm_unilabel_h1n1_vacc_trainpreds = svm_unilabel_h1n1_vacc.predict(X_h1n1_vacc_train)\n",
    "svm_unilabel_h1n1_vacc_testpreds = svm_unilabel_h1n1_vacc.predict(X_h1n1_vacc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logreg--Train data evaluation Metrics\n",
    "seas_logreg_unilabel_h1n1_vacc_train_acc = accuracy_score(y_seas_vacc_train, logreg_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_logreg_unilabel_h1n1_vacc_train_recall = recall_score(y_seas_vacc_train, logreg_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_logreg_unilabel_h1n1_vacc_train_precision = precision_score(y_seas_vacc_train, logreg_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_logreg_unilabel_h1n1_vacc_train_f1 = f1_score(y_seas_vacc_train, logreg_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_logreg_unilabel_h1n1_vacc_train_roc = roc_auc_score(y_seas_vacc_train, logreg_unilabel_h1n1_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_train, logreg_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_train, logreg_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_train, logreg_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_train, logreg_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_train, logreg_unilabel_h1n1_vacc_trainpreds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN--Train data evaluation Metrics\n",
    "seas_knn_unilabel_h1n1_vacc_train_acc = accuracy_score(y_seas_vacc_train, knn_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_knn_unilabel_h1n1_vacc_train_recall = recall_score(y_seas_vacc_train, knn_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_knn_unilabel_h1n1_vacc_train_precision = precision_score(y_seas_vacc_train, knn_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_knn_unilabel_h1n1_vacc_train_f1 = f1_score(y_seas_vacc_train, knn_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_knn_unilabel_h1n1_vacc_train_roc = roc_auc_score(y_seas_vacc_train, knn_unilabel_h1n1_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_train, knn_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_train, knn_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_train, knn_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_train, knn_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_train, knn_unilabel_h1n1_vacc_trainpreds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest--Train data evaluation Metrics\n",
    "#check if these metrics are changing compared to previous results\n",
    "seas_rand_forst_unilabel_h1n1_vacc_train_acc = accuracy_score(y_seas_vacc_train, rand_forst_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_rand_forst_unilabel_h1n1_vacc_train_recall = recall_score(y_seas_vacc_train, rand_forst_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_rand_forst_unilabel_h1n1_vacc_train_precision = precision_score(y_seas_vacc_train, rand_forst_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_rand_forst_unilabel_h1n1_vacc_train_f1 = f1_score(y_seas_vacc_train, rand_forst_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_rand_forst_unilabel_h1n1_vacc_train_roc = roc_auc_score(y_seas_vacc_train, rand_forst_unilabel_h1n1_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_train, rand_forst_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_train, rand_forst_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_train, rand_forst_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_train, rand_forst_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_train, rand_forst_unilabel_h1n1_vacc_trainpreds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM--Train data evaluation Metrics\n",
    "seas_svm_unilabel_h1n1_vacc_train_acc = accuracy_score(y_seas_vacc_train, svm_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_svm_unilabel_h1n1_vacc_train_recall = recall_score(y_seas_vacc_train, svm_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_svm_unilabel_h1n1_vacc_train_precision = precision_score(y_seas_vacc_train, svm_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_svm_unilabel_h1n1_vacc_train_f1 = f1_score(y_seas_vacc_train, svm_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_svm_unilabel_h1n1_vacc_train_roc = roc_auc_score(y_seas_vacc_train, svm_unilabel_h1n1_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_train, svm_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_train, svm_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_train, svm_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_train, svm_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_train, svm_unilabel_h1n1_vacc_trainpreds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logreg--Test data evaluation Metrics\n",
    "seas_logreg_unilabel_h1n1_vacc_test_acc = accuracy_score(y_seas_vacc_test, logreg_unilabel_h1n1_vacc_testpreds)\n",
    "seas_logreg_unilabel_h1n1_vacc_test_recall = recall_score(y_seas_vacc_test, logreg_unilabel_h1n1_vacc_testpreds)\n",
    "seas_logreg_unilabel_h1n1_vacc_test_precision = precision_score(y_seas_vacc_test, logreg_unilabel_h1n1_vacc_testpreds)\n",
    "seas_logreg_unilabel_h1n1_vacc_test_f1 = f1_score(y_seas_vacc_test, logreg_unilabel_h1n1_vacc_testpreds)\n",
    "seas_logreg_unilabel_h1n1_vacc_test_roc = roc_auc_score(y_seas_vacc_test, logreg_unilabel_h1n1_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_test, logreg_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_test, logreg_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_test, logreg_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_test, logreg_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_test, logreg_unilabel_h1n1_vacc_testpreds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN--Test data evaluation Metrics\n",
    "seas_knn_unilabel_h1n1_vacc_test_acc = accuracy_score(y_seas_vacc_test, knn_unilabel_h1n1_vacc_testpreds)\n",
    "seas_knn_unilabel_h1n1_vacc_test_recall = recall_score(y_seas_vacc_test, knn_unilabel_h1n1_vacc_testpreds)\n",
    "seas_knn_unilabel_h1n1_vacc_test_precision = precision_score(y_seas_vacc_test, knn_unilabel_h1n1_vacc_testpreds)\n",
    "seas_knn_unilabel_h1n1_vacc_test_f1 = f1_score(y_seas_vacc_test, knn_unilabel_h1n1_vacc_testpreds)\n",
    "seas_knn_unilabel_h1n1_vacc_test_roc = roc_auc_score(y_seas_vacc_test, knn_unilabel_h1n1_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_test, knn_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_test, knn_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_test, knn_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_test, knn_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_test, knn_unilabel_h1n1_vacc_testpreds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest--Test data evaluation Metrics\n",
    "#check if these metrics are changing compared to previous results\n",
    "seas_rand_forst_unilabel_h1n1_vacc_test_acc = accuracy_score(y_seas_vacc_test, rand_forst_unilabel_h1n1_vacc_testpreds)\n",
    "seas_rand_forst_unilabel_h1n1_vacc_test_recall = recall_score(y_seas_vacc_test, rand_forst_unilabel_h1n1_vacc_testpreds)\n",
    "seas_rand_forst_unilabel_h1n1_vacc_test_precision = precision_score(y_seas_vacc_test, rand_forst_unilabel_h1n1_vacc_testpreds)\n",
    "seas_rand_forst_unilabel_h1n1_vacc_test_f1 = f1_score(y_seas_vacc_test, rand_forst_unilabel_h1n1_vacc_testpreds)\n",
    "seas_rand_forst_unilabel_h1n1_vacc_test_roc = roc_auc_score(y_seas_vacc_test, rand_forst_unilabel_h1n1_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_test, rand_forst_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_test, rand_forst_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_test, rand_forst_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_test, rand_forst_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_test, rand_forst_unilabel_h1n1_vacc_testpreds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM--Test data evaluation Metrics\n",
    "seas_svm_unilabel_h1n1_vacc_test_acc = accuracy_score(y_seas_vacc_test, svm_unilabel_h1n1_vacc_testpreds)\n",
    "seas_svm_unilabel_h1n1_vacc_test_recall = recall_score(y_seas_vacc_test, svm_unilabel_h1n1_vacc_testpreds)\n",
    "seas_svm_unilabel_h1n1_vacc_test_precision = precision_score(y_seas_vacc_test, svm_unilabel_h1n1_vacc_testpreds)\n",
    "seas_svm_unilabel_h1n1_vacc_test_f1 = f1_score(y_seas_vacc_test, svm_unilabel_h1n1_vacc_testpreds)\n",
    "seas_svm_unilabel_h1n1_vacc_test_roc = roc_auc_score(y_seas_vacc_test, svm_unilabel_h1n1_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_test, svm_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_test, svm_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_test, svm_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_test, svm_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_test, svm_unilabel_h1n1_vacc_testpreds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking the model with MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H1N1 vaccine output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_seasonal) #this needs to be adjusted for each experiment\n",
    "name = 'logreg_unilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"H1N1\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seas_logreg_unilabel_h1n1_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seas_logreg_unilabel_h1n1_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seas_logreg_unilabel_h1n1_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seas_logreg_unilabel_h1n1_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seas_logreg_unilabel_h1n1_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seas_logreg_unilabel_h1n1_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seas_logreg_unilabel_h1n1_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seas_logreg_unilabel_h1n1_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seas_logreg_unilabel_h1n1_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seas_logreg_unilabel_h1n1_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_seasonal)\n",
    "name = 'knn_unilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"H1N1\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seas_knn_unilabel_h1n1_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seas_knn_unilabel_h1n1_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seas_knn_unilabel_h1n1_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seas_knn_unilabel_h1n1_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seas_knn_unilabel_h1n1_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seas_knn_unilabel_h1n1_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seas_knn_unilabel_h1n1_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seas_knn_unilabel_h1n1_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seas_knn_unilabel_h1n1_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seas_knn_unilabel_h1n1_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_seasonal)\n",
    "name = 'rand_forst_unilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"H1N1\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seas_rand_forst_unilabel_h1n1_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seas_rand_forst_unilabel_h1n1_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seas_rand_forst_unilabel_h1n1_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seas_rand_forst_unilabel_h1n1_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seas_rand_forst_unilabel_h1n1_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seas_rand_forst_unilabel_h1n1_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seas_rand_forst_unilabel_h1n1_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seas_rand_forst_unilabel_h1n1_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seas_rand_forst_unilabel_h1n1_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seas_rand_forst_unilabel_h1n1_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_seasonal)\n",
    "name = 'svm_unilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Full dataset\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"H1N1\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seas_svm_unilabel_h1n1_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seas_svm_unilabel_h1n1_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seas_svm_unilabel_h1n1_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seas_svm_unilabel_h1n1_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seas_svm_unilabel_h1n1_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seas_svm_unilabel_h1n1_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seas_svm_unilabel_h1n1_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seas_svm_unilabel_h1n1_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seas_svm_unilabel_h1n1_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seas_svm_unilabel_h1n1_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c0c25dab8ee693e846481bd08863e7cb648266bb2d9a40c015c16febc8ddeeb0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}