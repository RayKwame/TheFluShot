{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Notes on MLFlow:\n",
    "- 'Run name' field: model name, type of output (multilabel vs unilabel), which vaccine (for multiclass only)\n",
    "- 'Parameters' field: methods applied for data (data cleaning, data balancing, hyperparameters)--insert feature engineering info here, if relevant?\n",
    "- 'Tags' field: details about the features used for the run (is one of the vaccines in the features?)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import sys\n",
    "# adding to the path variables the one folder higher (locally, not changing system variables)\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "#mlflow import\n",
    "import mlflow\n",
    "from modeling.config import EXPERIMENT_NAME_multilabel, EXPERIMENT_NAME_h1n1, EXPERIMENT_NAME_seasonal, EXPERIMENT_NAME_multiclass\n",
    "TRACKING_URI = open(\"../.mlflow_uri\").read().strip()\n",
    "\n",
    "RSEED = 42\n",
    "\n",
    "# Modeling Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "!pip install plotly\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, cross_validate\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: plotly in /Users/christinarudolf/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages (5.1.0)\n",
      "Requirement already satisfied: six in /Users/christinarudolf/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages (from plotly) (1.16.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/christinarudolf/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages (from plotly) (8.0.1)\n"
     ]
    }
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df_features = pd.read_csv('../data/Flu_Shot_Learning_Predict_H1N1_and_Seasonal_Flu_Vaccines_-_Training_Features.csv')"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df_features.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   respondent_id  h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\n",
       "0              0           1.0             0.0                        0.0   \n",
       "1              1           3.0             2.0                        0.0   \n",
       "2              2           1.0             1.0                        0.0   \n",
       "3              3           1.0             1.0                        0.0   \n",
       "4              4           2.0             1.0                        0.0   \n",
       "\n",
       "   behavioral_avoidance  behavioral_face_mask  behavioral_wash_hands  \\\n",
       "0                   0.0                   0.0                    0.0   \n",
       "1                   1.0                   0.0                    1.0   \n",
       "2                   1.0                   0.0                    0.0   \n",
       "3                   1.0                   0.0                    1.0   \n",
       "4                   1.0                   0.0                    1.0   \n",
       "\n",
       "   behavioral_large_gatherings  behavioral_outside_home  \\\n",
       "0                          0.0                      1.0   \n",
       "1                          0.0                      1.0   \n",
       "2                          0.0                      0.0   \n",
       "3                          1.0                      0.0   \n",
       "4                          1.0                      0.0   \n",
       "\n",
       "   behavioral_touch_face  ...             income_poverty  marital_status  \\\n",
       "0                    1.0  ...              Below Poverty     Not Married   \n",
       "1                    1.0  ...              Below Poverty     Not Married   \n",
       "2                    0.0  ...  <= $75,000, Above Poverty     Not Married   \n",
       "3                    0.0  ...              Below Poverty     Not Married   \n",
       "4                    1.0  ...  <= $75,000, Above Poverty         Married   \n",
       "\n",
       "   rent_or_own   employment_status  hhs_geo_region                census_msa  \\\n",
       "0          Own  Not in Labor Force        oxchjgsf                   Non-MSA   \n",
       "1         Rent            Employed        bhuqouqj  MSA, Not Principle  City   \n",
       "2          Own            Employed        qufhixun  MSA, Not Principle  City   \n",
       "3         Rent  Not in Labor Force        lrircsnp       MSA, Principle City   \n",
       "4          Own            Employed        qufhixun  MSA, Not Principle  City   \n",
       "\n",
       "   household_adults  household_children  employment_industry  \\\n",
       "0               0.0                 0.0                  NaN   \n",
       "1               0.0                 0.0             pxcmvdjn   \n",
       "2               2.0                 0.0             rucpziij   \n",
       "3               0.0                 0.0                  NaN   \n",
       "4               1.0                 0.0             wxleyezf   \n",
       "\n",
       "   employment_occupation  \n",
       "0                    NaN  \n",
       "1               xgwztkwe  \n",
       "2               xtkaffoo  \n",
       "3                    NaN  \n",
       "4               emcorrxb  \n",
       "\n",
       "[5 rows x 36 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>respondent_id</th>\n",
       "      <th>h1n1_concern</th>\n",
       "      <th>h1n1_knowledge</th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>behavioral_outside_home</th>\n",
       "      <th>behavioral_touch_face</th>\n",
       "      <th>...</th>\n",
       "      <th>income_poverty</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>rent_or_own</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>hhs_geo_region</th>\n",
       "      <th>census_msa</th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "      <th>employment_industry</th>\n",
       "      <th>employment_occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>oxchjgsf</td>\n",
       "      <td>Non-MSA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Employed</td>\n",
       "      <td>bhuqouqj</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pxcmvdjn</td>\n",
       "      <td>xgwztkwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;= $75,000, Above Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Employed</td>\n",
       "      <td>qufhixun</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rucpziij</td>\n",
       "      <td>xtkaffoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>lrircsnp</td>\n",
       "      <td>MSA, Principle City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;= $75,000, Above Poverty</td>\n",
       "      <td>Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Employed</td>\n",
       "      <td>qufhixun</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>wxleyezf</td>\n",
       "      <td>emcorrxb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df_target = pd.read_csv('../data/Flu_Shot_Learning_Predict_H1N1_and_Seasonal_Flu_Vaccines_-_Training_Labels.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Get info for the target\n",
    "df_target.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26707 entries, 0 to 26706\n",
      "Data columns (total 3 columns):\n",
      " #   Column            Non-Null Count  Dtype\n",
      "---  ------            --------------  -----\n",
      " 0   respondent_id     26707 non-null  int64\n",
      " 1   h1n1_vaccine      26707 non-null  int64\n",
      " 2   seasonal_vaccine  26707 non-null  int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 626.1 KB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df_features.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26707 entries, 0 to 26706\n",
      "Data columns (total 36 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   respondent_id                26707 non-null  int64  \n",
      " 1   h1n1_concern                 26615 non-null  float64\n",
      " 2   h1n1_knowledge               26591 non-null  float64\n",
      " 3   behavioral_antiviral_meds    26636 non-null  float64\n",
      " 4   behavioral_avoidance         26499 non-null  float64\n",
      " 5   behavioral_face_mask         26688 non-null  float64\n",
      " 6   behavioral_wash_hands        26665 non-null  float64\n",
      " 7   behavioral_large_gatherings  26620 non-null  float64\n",
      " 8   behavioral_outside_home      26625 non-null  float64\n",
      " 9   behavioral_touch_face        26579 non-null  float64\n",
      " 10  doctor_recc_h1n1             24547 non-null  float64\n",
      " 11  doctor_recc_seasonal         24547 non-null  float64\n",
      " 12  chronic_med_condition        25736 non-null  float64\n",
      " 13  child_under_6_months         25887 non-null  float64\n",
      " 14  health_worker                25903 non-null  float64\n",
      " 15  health_insurance             14433 non-null  float64\n",
      " 16  opinion_h1n1_vacc_effective  26316 non-null  float64\n",
      " 17  opinion_h1n1_risk            26319 non-null  float64\n",
      " 18  opinion_h1n1_sick_from_vacc  26312 non-null  float64\n",
      " 19  opinion_seas_vacc_effective  26245 non-null  float64\n",
      " 20  opinion_seas_risk            26193 non-null  float64\n",
      " 21  opinion_seas_sick_from_vacc  26170 non-null  float64\n",
      " 22  age_group                    26707 non-null  object \n",
      " 23  education                    25300 non-null  object \n",
      " 24  race                         26707 non-null  object \n",
      " 25  sex                          26707 non-null  object \n",
      " 26  income_poverty               22284 non-null  object \n",
      " 27  marital_status               25299 non-null  object \n",
      " 28  rent_or_own                  24665 non-null  object \n",
      " 29  employment_status            25244 non-null  object \n",
      " 30  hhs_geo_region               26707 non-null  object \n",
      " 31  census_msa                   26707 non-null  object \n",
      " 32  household_adults             26458 non-null  float64\n",
      " 33  household_children           26458 non-null  float64\n",
      " 34  employment_industry          13377 non-null  object \n",
      " 35  employment_occupation        13237 non-null  object \n",
      "dtypes: float64(23), int64(1), object(12)\n",
      "memory usage: 7.3+ MB\n"
     ]
    }
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "df_features.isnull().sum(axis = 0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "respondent_id                      0\n",
       "h1n1_concern                      92\n",
       "h1n1_knowledge                   116\n",
       "behavioral_antiviral_meds         71\n",
       "behavioral_avoidance             208\n",
       "behavioral_face_mask              19\n",
       "behavioral_wash_hands             42\n",
       "behavioral_large_gatherings       87\n",
       "behavioral_outside_home           82\n",
       "behavioral_touch_face            128\n",
       "doctor_recc_h1n1                2160\n",
       "doctor_recc_seasonal            2160\n",
       "chronic_med_condition            971\n",
       "child_under_6_months             820\n",
       "health_worker                    804\n",
       "health_insurance               12274\n",
       "opinion_h1n1_vacc_effective      391\n",
       "opinion_h1n1_risk                388\n",
       "opinion_h1n1_sick_from_vacc      395\n",
       "opinion_seas_vacc_effective      462\n",
       "opinion_seas_risk                514\n",
       "opinion_seas_sick_from_vacc      537\n",
       "age_group                          0\n",
       "education                       1407\n",
       "race                               0\n",
       "sex                                0\n",
       "income_poverty                  4423\n",
       "marital_status                  1408\n",
       "rent_or_own                     2042\n",
       "employment_status               1463\n",
       "hhs_geo_region                     0\n",
       "census_msa                         0\n",
       "household_adults                 249\n",
       "household_children               249\n",
       "employment_industry            13330\n",
       "employment_occupation          13470\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- express missing values as %\n",
    "\n",
    "Options:\n",
    "- modelling for imputation (withput using our target variable!)\n",
    "- or use prediction models that don't care about missing values\n",
    "- or impute so that the overall distribution stays the same (based on statistics of this data set)\n",
    "- or impute using a hypothesis (e.g. people who have missing values don't have health insurance?)\n",
    "- for imputation we can try several approaches and see what gives best results :)\n",
    "\n",
    "- remember--when we impute, we want to base assumptions based on the test set of a train-test split:\n",
    "    - if we do multiple models, test-train split for each\n",
    "    - create functions for imputation\n",
    "\n",
    "- remember modelling for understanding (EDA style) =/= modelling for prediction\n",
    "\n",
    "library for visualising missing values:\n",
    "https://github.com/ResidentMario/missingno"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# We are concatenating both dataframes into one \n",
    "\n",
    "df = pd.merge(df_target, df_features, on=['respondent_id'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will drop the following columns for our first iteration:    \n",
    "- health_insurance, employment_industry, employment_occupation, income_poverty, marital_status, employment_status"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "What are the values in the features that have a lot of missing data?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "df_features.health_insurance.value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0    12697\n",
       "0.0     1736\n",
       "Name: health_insurance, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Binary variable; 12% do not have health insurance, the rest do"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "df_features.employment_industry.value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "fcxhlnwr    2468\n",
       "wxleyezf    1804\n",
       "ldnlellj    1231\n",
       "pxcmvdjn    1037\n",
       "atmlpfrs     926\n",
       "arjwrbjb     871\n",
       "xicduogh     851\n",
       "mfikgejo     614\n",
       "vjjrobsf     527\n",
       "rucpziij     523\n",
       "xqicxuve     511\n",
       "saaquncn     338\n",
       "cfqqtusy     325\n",
       "nduyfdeo     286\n",
       "mcubkhph     275\n",
       "wlfvacwt     215\n",
       "dotnnunm     201\n",
       "haxffmxo     148\n",
       "msuufmds     124\n",
       "phxvnwax      89\n",
       "qnlwzans      13\n",
       "Name: employment_industry, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Anonymised variable with 21 values"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "df_features.employment_occupation.value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "xtkaffoo    1778\n",
       "mxkfnird    1509\n",
       "emcorrxb    1270\n",
       "cmhcxjea    1247\n",
       "xgwztkwe    1082\n",
       "hfxkjkmi     766\n",
       "qxajmpny     548\n",
       "xqwwgdyp     485\n",
       "kldqjyjy     469\n",
       "uqqtjvyb     452\n",
       "tfqavkke     388\n",
       "ukymxvdu     372\n",
       "vlluhbov     354\n",
       "oijqvulv     344\n",
       "ccgxvspp     341\n",
       "bxpfxfdn     331\n",
       "haliazsg     296\n",
       "rcertsgn     276\n",
       "xzmlyyjv     248\n",
       "dlvbwzss     227\n",
       "hodpvpew     208\n",
       "dcjcmpih     148\n",
       "pvmttkik      98\n",
       "Name: employment_occupation, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Anonymised variable with 23 values"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data cleaning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dropping of features with too many missing values:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "col_drop = ['health_insurance', 'employment_industry', 'employment_occupation', 'income_poverty', 'marital_status', 'employment_status']\n",
    "\n",
    "df.drop(col_drop, axis=1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dropping of all rows with null values:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "df.dropna(inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check that all null values have been dropped:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "df.isnull().sum(axis = 0)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "respondent_id                  0\n",
       "h1n1_vaccine                   0\n",
       "seasonal_vaccine               0\n",
       "h1n1_concern                   0\n",
       "h1n1_knowledge                 0\n",
       "behavioral_antiviral_meds      0\n",
       "behavioral_avoidance           0\n",
       "behavioral_face_mask           0\n",
       "behavioral_wash_hands          0\n",
       "behavioral_large_gatherings    0\n",
       "behavioral_outside_home        0\n",
       "behavioral_touch_face          0\n",
       "doctor_recc_h1n1               0\n",
       "doctor_recc_seasonal           0\n",
       "chronic_med_condition          0\n",
       "child_under_6_months           0\n",
       "health_worker                  0\n",
       "opinion_h1n1_vacc_effective    0\n",
       "opinion_h1n1_risk              0\n",
       "opinion_h1n1_sick_from_vacc    0\n",
       "opinion_seas_vacc_effective    0\n",
       "opinion_seas_risk              0\n",
       "opinion_seas_sick_from_vacc    0\n",
       "age_group                      0\n",
       "education                      0\n",
       "race                           0\n",
       "sex                            0\n",
       "rent_or_own                    0\n",
       "hhs_geo_region                 0\n",
       "census_msa                     0\n",
       "household_adults               0\n",
       "household_children             0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "df.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 21853 entries, 0 to 26706\n",
      "Data columns (total 32 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   respondent_id                21853 non-null  int64  \n",
      " 1   h1n1_vaccine                 21853 non-null  int64  \n",
      " 2   seasonal_vaccine             21853 non-null  int64  \n",
      " 3   h1n1_concern                 21853 non-null  float64\n",
      " 4   h1n1_knowledge               21853 non-null  float64\n",
      " 5   behavioral_antiviral_meds    21853 non-null  float64\n",
      " 6   behavioral_avoidance         21853 non-null  float64\n",
      " 7   behavioral_face_mask         21853 non-null  float64\n",
      " 8   behavioral_wash_hands        21853 non-null  float64\n",
      " 9   behavioral_large_gatherings  21853 non-null  float64\n",
      " 10  behavioral_outside_home      21853 non-null  float64\n",
      " 11  behavioral_touch_face        21853 non-null  float64\n",
      " 12  doctor_recc_h1n1             21853 non-null  float64\n",
      " 13  doctor_recc_seasonal         21853 non-null  float64\n",
      " 14  chronic_med_condition        21853 non-null  float64\n",
      " 15  child_under_6_months         21853 non-null  float64\n",
      " 16  health_worker                21853 non-null  float64\n",
      " 17  opinion_h1n1_vacc_effective  21853 non-null  float64\n",
      " 18  opinion_h1n1_risk            21853 non-null  float64\n",
      " 19  opinion_h1n1_sick_from_vacc  21853 non-null  float64\n",
      " 20  opinion_seas_vacc_effective  21853 non-null  float64\n",
      " 21  opinion_seas_risk            21853 non-null  float64\n",
      " 22  opinion_seas_sick_from_vacc  21853 non-null  float64\n",
      " 23  age_group                    21853 non-null  object \n",
      " 24  education                    21853 non-null  object \n",
      " 25  race                         21853 non-null  object \n",
      " 26  sex                          21853 non-null  object \n",
      " 27  rent_or_own                  21853 non-null  object \n",
      " 28  hhs_geo_region               21853 non-null  object \n",
      " 29  census_msa                   21853 non-null  object \n",
      " 30  household_adults             21853 non-null  float64\n",
      " 31  household_children           21853 non-null  float64\n",
      "dtypes: float64(22), int64(3), object(7)\n",
      "memory usage: 5.5+ MB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "df.reset_index(inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We dropped all rows with missing values\n",
    "- Maybe later on, we will want to refine this approach."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    " # We are looking for unique values in order to identify whether we have duplicates\n",
    "\n",
    "df['respondent_id'].nunique()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "21853"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "All values are unique, no duplicates. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## EDA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# checking for balance in data\n",
    "\n",
    "print(df.h1n1_vaccine.value_counts())\n",
    "print(df.seasonal_vaccine.value_counts())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0    16906\n",
      "1     4947\n",
      "Name: h1n1_vaccine, dtype: int64\n",
      "0    11371\n",
      "1    10482\n",
      "Name: seasonal_vaccine, dtype: int64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "23% vaccination rate for H1N1 and 52% vaccination rate for seasonal flu\n",
    "The H1N1 vaccine outcome appears to be unbalanced (almost 17k vs 5k) (read lit--what is considered unbalanced?)\n",
    "The seasonal vaccine outcome appears to be fairly balanced\n",
    "\n",
    "We may want to deal with the lack of balance later"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# Understanding observations and rows\n",
    "\n",
    "df.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21853 entries, 0 to 21852\n",
      "Data columns (total 33 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   index                        21853 non-null  int64  \n",
      " 1   respondent_id                21853 non-null  int64  \n",
      " 2   h1n1_vaccine                 21853 non-null  int64  \n",
      " 3   seasonal_vaccine             21853 non-null  int64  \n",
      " 4   h1n1_concern                 21853 non-null  float64\n",
      " 5   h1n1_knowledge               21853 non-null  float64\n",
      " 6   behavioral_antiviral_meds    21853 non-null  float64\n",
      " 7   behavioral_avoidance         21853 non-null  float64\n",
      " 8   behavioral_face_mask         21853 non-null  float64\n",
      " 9   behavioral_wash_hands        21853 non-null  float64\n",
      " 10  behavioral_large_gatherings  21853 non-null  float64\n",
      " 11  behavioral_outside_home      21853 non-null  float64\n",
      " 12  behavioral_touch_face        21853 non-null  float64\n",
      " 13  doctor_recc_h1n1             21853 non-null  float64\n",
      " 14  doctor_recc_seasonal         21853 non-null  float64\n",
      " 15  chronic_med_condition        21853 non-null  float64\n",
      " 16  child_under_6_months         21853 non-null  float64\n",
      " 17  health_worker                21853 non-null  float64\n",
      " 18  opinion_h1n1_vacc_effective  21853 non-null  float64\n",
      " 19  opinion_h1n1_risk            21853 non-null  float64\n",
      " 20  opinion_h1n1_sick_from_vacc  21853 non-null  float64\n",
      " 21  opinion_seas_vacc_effective  21853 non-null  float64\n",
      " 22  opinion_seas_risk            21853 non-null  float64\n",
      " 23  opinion_seas_sick_from_vacc  21853 non-null  float64\n",
      " 24  age_group                    21853 non-null  object \n",
      " 25  education                    21853 non-null  object \n",
      " 26  race                         21853 non-null  object \n",
      " 27  sex                          21853 non-null  object \n",
      " 28  rent_or_own                  21853 non-null  object \n",
      " 29  hhs_geo_region               21853 non-null  object \n",
      " 30  census_msa                   21853 non-null  object \n",
      " 31  household_adults             21853 non-null  float64\n",
      " 32  household_children           21853 non-null  float64\n",
      "dtypes: float64(22), int64(4), object(7)\n",
      "memory usage: 5.5+ MB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "#columns to drop because they're little use\n",
    "col_drop = ['index', 'respondent_id']\n",
    "\n",
    "df.drop(col_drop, axis=1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- our target variables are h1n1_vaccine and seasonal_vaccine\n",
    "- at the moment we are working with 28 feature variables--all categorical (refer to challenge documentation for description; we will need to transfer this info to the README)\n",
    "- seven of the variables are strings--we will convert these to numeric encoding so we can look at correlations in Profiler\n",
    "household_adults and household_children are 'top-coded' up to 3--that means that household with 3+ adults (or children) will fall into the '3' group\n",
    "- 'hhs_geo_region' is an anonymised string\n",
    "- we should remember that the current column names (which would be used as labels in the graphs) are not really human-readable--we need to keep this in mind when we're making plots (either rename the columns beforehand, or include a plotting command to change the labels)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "24  age_group                    21853 non-null  object \n",
    " 25  education                    21853 non-null  object \n",
    " 26  race                         21853 non-null  object \n",
    " 27  sex                          21853 non-null  object \n",
    " 28  rent_or_own                  21853 non-null  object \n",
    " 29  hhs_geo_region               21853 non-null  object \n",
    " 30  census_msa                   21853 non-null  object "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "24  age_group                    21853 non-null  object \n",
    " 25  education                    21853 non-null  object \n",
    " 26  race                         21853 non-null  object \n",
    " 27  sex                          21853 non-null  object \n",
    " 28  rent_or_own                  21853 non-null  object \n",
    " 29  hhs_geo_region               21853 non-null  object \n",
    " 30  census_msa                   21853 non-null  object "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Conversion of string variables to numeric (so these variables het displayed in Profiler properly) vie manual numeric encoding:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "#a separate dataframe is made for the Profiler; the original dataframe will be retained for one-hot encoding (so the column headings we get during one-hot encoding remain meaningful)\n",
    "df[\"age_group\"].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "65+ Years        5393\n",
       "55 - 64 Years    4655\n",
       "45 - 54 Years    4390\n",
       "18 - 34 Years    4277\n",
       "35 - 44 Years    3138\n",
       "Name: age_group, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "df[\"education\"].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "College Graduate    8839\n",
       "Some College        6123\n",
       "12 Years            4963\n",
       "< 12 Years          1928\n",
       "Name: education, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "df[\"race\"].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "White                17485\n",
       "Black                 1670\n",
       "Hispanic              1428\n",
       "Other or Multiple     1270\n",
       "Name: race, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "df[\"sex\"].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Female    13105\n",
       "Male       8748\n",
       "Name: sex, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "df[\"rent_or_own\"].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Own     16647\n",
       "Rent     5206\n",
       "Name: rent_or_own, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "df[\"hhs_geo_region\"].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "lzgpxyit    3481\n",
       "fpwskwrf    2626\n",
       "qufhixun    2588\n",
       "bhuqouqj    2373\n",
       "oxchjgsf    2356\n",
       "kbazzjca    2299\n",
       "mlyzmhmf    1832\n",
       "atmpeygn    1694\n",
       "lrircsnp    1686\n",
       "dqpwygqj     918\n",
       "Name: hhs_geo_region, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "df[\"census_msa\"].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MSA, Not Principle  City    9558\n",
       "MSA, Principle City         6362\n",
       "Non-MSA                     5933\n",
       "Name: census_msa, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "cleanup = {\"age_group\": {\"18 - 34 Years\": 1, \"35 - 44 Years\": 2, \"45 - 54 Years\": 3, \"55 - 64 Years\": 4,\n",
    "                                  \"65+ Years\": 5},\n",
    "            \"education\": {\"< 12 Years\": 1, \"12 Years\": 2, \"Some College\": 3, \"College Graduate\": 4},\n",
    "            \"race\": {\"White\": 1, \"Black\": 2, \"Hispanic\": 3, \"Other or Multiple\": 4},\n",
    "            \"sex\" : {\"Female\": 1, \"Male\": 2},\n",
    "            \"rent_or_own\" : {\"Own\": 1, \"Rent\": 2},\n",
    "            \"hhs_geo_region\" : {\"lzgpxyit\": 1, \"fpwskwrf\": 2, \"qufhixun\": 3, \"bhuqouqj\": 4, \"oxchjgsf\": 5, \"kbazzjca\": 6, \"mlyzmhmf\": 7, \"atmpeygn\": 8, \"lrircsnp\": 9, \"dqpwygqj\": 10},\n",
    "            \"census_msa\" : {\"MSA, Not Principle  City\": 1, \"MSA, Principle City\": 2, \"Non-MSA\": 3}\n",
    "                                  }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "df_for_profiler = df.replace(cleanup)\n",
    "df_for_profiler.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   h1n1_vaccine  seasonal_vaccine  h1n1_concern  h1n1_knowledge  \\\n",
       "0             0                 0           1.0             0.0   \n",
       "1             0                 1           3.0             2.0   \n",
       "2             0                 1           1.0             1.0   \n",
       "3             0                 0           2.0             1.0   \n",
       "4             0                 0           3.0             1.0   \n",
       "\n",
       "   behavioral_antiviral_meds  behavioral_avoidance  behavioral_face_mask  \\\n",
       "0                        0.0                   0.0                   0.0   \n",
       "1                        0.0                   1.0                   0.0   \n",
       "2                        0.0                   1.0                   0.0   \n",
       "3                        0.0                   1.0                   0.0   \n",
       "4                        0.0                   1.0                   0.0   \n",
       "\n",
       "   behavioral_wash_hands  behavioral_large_gatherings  \\\n",
       "0                    0.0                          0.0   \n",
       "1                    1.0                          0.0   \n",
       "2                    1.0                          1.0   \n",
       "3                    1.0                          1.0   \n",
       "4                    1.0                          0.0   \n",
       "\n",
       "   behavioral_outside_home  ...  opinion_seas_sick_from_vacc  age_group  \\\n",
       "0                      1.0  ...                          2.0          4   \n",
       "1                      1.0  ...                          4.0          2   \n",
       "2                      0.0  ...                          1.0          5   \n",
       "3                      0.0  ...                          4.0          3   \n",
       "4                      0.0  ...                          4.0          5   \n",
       "\n",
       "   education  race  sex  rent_or_own  hhs_geo_region  census_msa  \\\n",
       "0          1     1    1            1               5           3   \n",
       "1          2     1    2            2               4           1   \n",
       "2          2     1    1            2               9           2   \n",
       "3          3     1    1            1               3           1   \n",
       "4          2     1    2            1               8           2   \n",
       "\n",
       "   household_adults  household_children  \n",
       "0               0.0                 0.0  \n",
       "1               0.0                 0.0  \n",
       "2               0.0                 0.0  \n",
       "3               1.0                 0.0  \n",
       "4               2.0                 3.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h1n1_vaccine</th>\n",
       "      <th>seasonal_vaccine</th>\n",
       "      <th>h1n1_concern</th>\n",
       "      <th>h1n1_knowledge</th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>behavioral_outside_home</th>\n",
       "      <th>...</th>\n",
       "      <th>opinion_seas_sick_from_vacc</th>\n",
       "      <th>age_group</th>\n",
       "      <th>education</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>rent_or_own</th>\n",
       "      <th>hhs_geo_region</th>\n",
       "      <th>census_msa</th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Run Profiler to explore the data:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "#import Profiler\n",
    "#!pip install pandas-profiling==2.11.0\n",
    "#from pandas_profiling import ProfileReport"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "#profile = ProfileReport(df_for_profiler, title=\"Pandas Profiling Report\", explorative=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "#profile"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Possible multicollinearity (between features) based on heatmap:**\n",
    "- behavioral_large_gatherings vs behavioral_outside_home\n",
    "- doctor_recc_h1n1 vs doctor_recc_seasonal\n",
    "- opinion_h1n1_risk vs opinion_seas_risk\n",
    "- household_children vs age_group"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Possible outliers and features to be aware of:**\n",
    "- behavioral_antiviral_meds : very unbalanced between categories; the people taking anviral meds could have something else going on (e.g. already sick, or worried about getting flu and taking meds profilactically)--be careful about this variable\n",
    "- behavioral_face_mask\n",
    "- behavioral_wash_hands\n",
    "-child_under_6_months\n",
    "- health_worker\n",
    "- opinion_h1n1_vacc_effective and opinion_seasonal_vacc_effective (1.0 group)\n",
    "- race (not many non-white respondents)\n",
    "- household_adults and household_children (3.0 groups pretty small)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Set up for modelling (stays the same for all experiemnts)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set up of pipeline preprocessor:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# Pipeline for categorical features\n",
    "# This stays the same for everything\n",
    "cat_pipeline = Pipeline([\n",
    "    ('1hot', OneHotEncoder(handle_unknown='error', drop='first'))\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "cat_features = list(df.columns)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instantiating the models:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "# for Logistic Regression\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# for KNN\n",
    "knn= KNeighborsClassifier()\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst= RandomForestClassifier()\n",
    "\n",
    "\n",
    "# for SVM\n",
    "svm= svm.SVC(kernel='rbf')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TheFluShot_multilabel: Multilabel prediction (both vaccinations)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Removal of target variables from cat_features list (this needs to be adjusted for each dataset):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "cat_features_no_vacc = cat_features.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "cat_features_no_vacc.remove('h1n1_vaccine')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "cat_features_no_vacc.remove('seasonal_vaccine')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "cat_features"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['h1n1_vaccine',\n",
       " 'seasonal_vaccine',\n",
       " 'h1n1_concern',\n",
       " 'h1n1_knowledge',\n",
       " 'behavioral_antiviral_meds',\n",
       " 'behavioral_avoidance',\n",
       " 'behavioral_face_mask',\n",
       " 'behavioral_wash_hands',\n",
       " 'behavioral_large_gatherings',\n",
       " 'behavioral_outside_home',\n",
       " 'behavioral_touch_face',\n",
       " 'doctor_recc_h1n1',\n",
       " 'doctor_recc_seasonal',\n",
       " 'chronic_med_condition',\n",
       " 'child_under_6_months',\n",
       " 'health_worker',\n",
       " 'opinion_h1n1_vacc_effective',\n",
       " 'opinion_h1n1_risk',\n",
       " 'opinion_h1n1_sick_from_vacc',\n",
       " 'opinion_seas_vacc_effective',\n",
       " 'opinion_seas_risk',\n",
       " 'opinion_seas_sick_from_vacc',\n",
       " 'age_group',\n",
       " 'education',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'rent_or_own',\n",
       " 'hhs_geo_region',\n",
       " 'census_msa',\n",
       " 'household_adults',\n",
       " 'household_children']"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Rename the features and target to 'X' and 'y', to make the test-train split easier:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "y_both_vacc = df[['h1n1_vaccine', 'seasonal_vaccine']].copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "y_both_vacc = y_both_vacc.to_numpy()\n",
    "y_both_vacc"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       ...,\n",
       "       [0, 0],\n",
       "       [0, 1],\n",
       "       [0, 0]])"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "#NB: dropping the 'h1n1_vaccine' and 'seasonal_vaccine' columns\n",
    "X_no_vacc = df.drop(columns=['h1n1_vaccine', 'seasonal_vaccine'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Performing test-train split (the same data can be used for each model in multilabelling):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "\n",
    "X_no_vacc_train, X_no_vacc_test, y_both_vacc_train, y_both_vacc_test = train_test_split(X_no_vacc, y_both_vacc, stratify = y_both_vacc, test_size=0.2, random_state=RSEED)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "print('X_no_vacc_train shape:', X_no_vacc_train.shape)\n",
    "print('X_no_vacc_test shape:', X_no_vacc_test.shape)\n",
    "print('y_both_vacc_train:', y_both_vacc_train.shape)\n",
    "print('y_both_vacc_test:', y_both_vacc_test.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X_no_vacc_train shape: (17482, 29)\n",
      "X_no_vacc_test shape: (4371, 29)\n",
      "y_both_vacc_train: (17482, 2)\n",
      "y_both_vacc_test: (4371, 2)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setting up the preprocessor (the same one can be used for each modelling in multilabelling):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', cat_pipeline, cat_features_no_vacc)\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setting up the multilabel estimators for each model:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "# for logistic regression\n",
    "multilabel_est_logreg = MultiOutputClassifier(\n",
    "    estimator=logreg\n",
    ")\n",
    "\n",
    "# for KNN\n",
    "multilabel_est_knn= MultiOutputClassifier(\n",
    "    estimator=knn\n",
    ")\n",
    "\n",
    "# for Random Forest\n",
    "multilabel_est_rand_forst= MultiOutputClassifier(\n",
    "    estimator=rand_forst\n",
    ")\n",
    "\n",
    "\n",
    "# for SVM\n",
    "multilabel_est_SVC= MultiOutputClassifier(\n",
    "    estimator=svm\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setting up the pipeline for each model:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "# for logreg\n",
    "logreg_multilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", multilabel_est_logreg),\n",
    "])\n",
    "\n",
    "# for KNN\n",
    "knn_multilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", multilabel_est_knn),\n",
    "])\n",
    "\n",
    "# for Random Forest\n",
    "\n",
    "rand_forst_multilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", multilabel_est_rand_forst),\n",
    "])\n",
    "\n",
    "#for SVM\n",
    "svm_multilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", multilabel_est_SVC),\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training the models:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "# for logreg\n",
    "logreg_multilabel = logreg_multilabel_pipeline.fit(X_no_vacc_train,  y_both_vacc_train)\n",
    "\n",
    "# for KNN\n",
    "knn_multilabel = knn_multilabel_pipeline.fit(X_no_vacc_train,  y_both_vacc_train)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_multilabel = rand_forst_multilabel_pipeline.fit(X_no_vacc_train,  y_both_vacc_train)\n",
    "\n",
    "#for SVM\n",
    "svm_multilabel = svm_multilabel_pipeline.fit(X_no_vacc_train,  y_both_vacc_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "# Figure out later what this does and if we want to use it\n",
    "\n",
    "\n",
    "#y_train_predicted = cross_val_predict(full_pipeline, X_train, y_train, cv=5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Making predictions based on train and test data:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "# for logreg\n",
    "logreg_multilabel_trainpreds = logreg_multilabel.predict(X_no_vacc_train)\n",
    "logreg_multilabel_testpreds = logreg_multilabel.predict(X_no_vacc_test)\n",
    "\n",
    "# for KNN\n",
    "knn_multilabel_trainpreds = knn_multilabel.predict(X_no_vacc_train)\n",
    "knn_multilabel_testpreds = knn_multilabel.predict(X_no_vacc_test)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_multilabel_trainpreds = rand_forst_multilabel.predict(X_no_vacc_train)\n",
    "rand_forst_multilabel_testpreds = rand_forst_multilabel.predict(X_no_vacc_test)\n",
    "\n",
    "# for SVM\n",
    "svm_multilabel_trainpreds = svm_multilabel.predict(X_no_vacc_train)\n",
    "svm_multilabel_testpreds = svm_multilabel.predict(X_no_vacc_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model evaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "# Logreg--Train data evaluation Metrics for H1N1 Vaccines\n",
    "h1n1_logreg_multilabel_train_acc = accuracy_score(y_both_vacc_train[:, 0], logreg_multilabel_trainpreds[:, 0])\n",
    "h1n1_logreg_multilabel_train_recall = recall_score(y_both_vacc_train[:, 0], logreg_multilabel_trainpreds[:, 0])\n",
    "h1n1_logreg_multilabel_train_precision = precision_score(y_both_vacc_train[:, 0], logreg_multilabel_trainpreds[:, 0])\n",
    "h1n1_logreg_multilabel_train_f1 = f1_score(y_both_vacc_train[:, 0], logreg_multilabel_trainpreds[:, 0])\n",
    "h1n1_logreg_multilabel_train_roc = roc_auc_score(y_both_vacc_train[:, 0], logreg_multilabel_trainpreds[:, 0])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_train[:, 0], logreg_multilabel_trainpreds[:, 0])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_train[:, 0], logreg_multilabel_trainpreds[:, 0])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_train[:, 0], logreg_multilabel_trainpreds[:, 0])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_train[:, 0], logreg_multilabel_trainpreds[:, 0])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_train[:, 0], logreg_multilabel_trainpreds[:, 0])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "# Logreg--Train data Evaluation Metrics for seasonal Vaccines\n",
    "seasonal_logreg_multilabel_train_acc = accuracy_score(y_both_vacc_train[:, 1], logreg_multilabel_trainpreds[:, 1])\n",
    "seasonal_logreg_multilabel_train_recall = recall_score(y_both_vacc_train[:, 1], logreg_multilabel_trainpreds[:, 1])\n",
    "seasonal_logreg_multilabel_train_precision = precision_score(y_both_vacc_train[:, 1], logreg_multilabel_trainpreds[:, 1])\n",
    "seasonal_logreg_multilabel_train_f1 = f1_score(y_both_vacc_train[:, 1], logreg_multilabel_trainpreds[:, 1])\n",
    "seasonal_logreg_multilabel_train_roc = roc_auc_score(y_both_vacc_train[:, 1], logreg_multilabel_trainpreds[:, 1])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_train[:, 1], logreg_multilabel_trainpreds[:, 1])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_train[:, 1], logreg_multilabel_trainpreds[:, 1])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_train[:, 1], logreg_multilabel_trainpreds[:, 1])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_train[:, 1], logreg_multilabel_trainpreds[:, 1])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_train[:, 1], logreg_multilabel_trainpreds[:, 1])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "# KNN--Train data evaluation Metrics for H1N1 Vaccines\n",
    "h1n1_knn_multilabel_train_acc = accuracy_score(y_both_vacc_train[:, 0], knn_multilabel_trainpreds[:, 0])\n",
    "h1n1_knn_multilabel_train_recall = recall_score(y_both_vacc_train[:, 0], knn_multilabel_trainpreds[:, 0])\n",
    "h1n1_knn_multilabel_train_precision = precision_score(y_both_vacc_train[:, 0], knn_multilabel_trainpreds[:, 0])\n",
    "h1n1_knn_multilabel_train_f1 = f1_score(y_both_vacc_train[:, 0], knn_multilabel_trainpreds[:, 0])\n",
    "h1n1_knn_multilabel_train_roc = roc_auc_score(y_both_vacc_train[:, 0], knn_multilabel_trainpreds[:, 0])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_train[:, 0], knn_multilabel_trainpreds[:, 0])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_train[:, 0], knn_multilabel_trainpreds[:, 0])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_train[:, 0], knn_multilabel_trainpreds[:, 0])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_train[:, 0], knn_multilabel_trainpreds[:, 0])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_train[:, 0], knn_multilabel_trainpreds[:, 0])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "# KNN--Train data Evaluation Metrics for seasonal Vaccines\n",
    "seasonal_knn_multilabel_train_acc = accuracy_score(y_both_vacc_train[:, 1], knn_multilabel_trainpreds[:, 1])\n",
    "seasonal_knn_multilabel_train_recall = recall_score(y_both_vacc_train[:, 1], knn_multilabel_trainpreds[:, 1])\n",
    "seasonal_knn_multilabel_train_precision = precision_score(y_both_vacc_train[:, 1], knn_multilabel_trainpreds[:, 1])\n",
    "seasonal_knn_multilabel_train_f1 = f1_score(y_both_vacc_train[:, 1], knn_multilabel_trainpreds[:, 1])\n",
    "seasonal_knn_multilabel_train_roc = roc_auc_score(y_both_vacc_train[:, 1], knn_multilabel_trainpreds[:, 1])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_train[:, 1], knn_multilabel_trainpreds[:, 1])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_train[:, 1], knn_multilabel_trainpreds[:, 1])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_train[:, 1], knn_multilabel_trainpreds[:, 1])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_train[:, 1], knn_multilabel_trainpreds[:, 1])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_train[:, 1], knn_multilabel_trainpreds[:, 1])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "# Random Forest--Train data evaluation Metrics for H1N1 Vaccines\n",
    "# THESE RESULTS ARE SLIGHTLY OFF FROM PREVIOUS NOTEBOOK (BY 0.01)--CHECK WHAT'S AT PLAY. VARIATION COMING FROM TEST-TRAIN SPLIT? EXPORT TEST-TRAIN DATA AS CSV AND TRY AGAIN\n",
    "#IS IT BECAUSE IT'S RANDOM FOREST? DIFFERENT STARTING STUMP EACH TIME?\n",
    "h1n1_rand_forst_multilabel_train_acc = accuracy_score(y_both_vacc_train[:, 0], rand_forst_multilabel_trainpreds[:, 0])\n",
    "h1n1_rand_forst_multilabel_train_recall = recall_score(y_both_vacc_train[:, 0], rand_forst_multilabel_trainpreds[:, 0])\n",
    "h1n1_rand_forst_multilabel_train_precision = precision_score(y_both_vacc_train[:, 0], rand_forst_multilabel_trainpreds[:, 0])\n",
    "h1n1_rand_forst_multilabel_train_f1 = f1_score(y_both_vacc_train[:, 0], rand_forst_multilabel_trainpreds[:, 0])\n",
    "h1n1_rand_forst_multilabel_train_roc = roc_auc_score(y_both_vacc_train[:, 0], rand_forst_multilabel_trainpreds[:, 0])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_train[:, 0], rand_forst_multilabel_trainpreds[:, 0])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_train[:, 0], rand_forst_multilabel_trainpreds[:, 0])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_train[:, 0], rand_forst_multilabel_trainpreds[:, 0])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_train[:, 0], rand_forst_multilabel_trainpreds[:, 0])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_train[:, 0], rand_forst_multilabel_trainpreds[:, 0])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "# Random Forest--Train data Evaluation Metrics for seasonal Vaccines\n",
    "# THESE RESULTS ARE SLIGHTLY OFF FROM PREVIOUS NOTEBOOK (BY 0.01)--CHECK WHAT'S AT PLAY. VARIATION COMING FROM TEST-TRAIN SPLIT? EXPORT TEST-TRAIN DATA AS CSV AND TRY AGAIN\n",
    "#IS IT BECAUSE IT'S RANDOM FOREST? DIFFERENT STARTING STUMP EACH TIME?\n",
    "seasonal_rand_forst_multilabel_train_acc = accuracy_score(y_both_vacc_train[:, 1], rand_forst_multilabel_trainpreds[:, 1])\n",
    "seasonal_rand_forst_multilabel_train_recall = recall_score(y_both_vacc_train[:, 1], rand_forst_multilabel_trainpreds[:, 1])\n",
    "seasonal_rand_forst_multilabel_train_precision = precision_score(y_both_vacc_train[:, 1], rand_forst_multilabel_trainpreds[:, 1])\n",
    "seasonal_rand_forst_multilabel_train_f1 = f1_score(y_both_vacc_train[:, 1], rand_forst_multilabel_trainpreds[:, 1])\n",
    "seasonal_rand_forst_multilabel_train_roc = roc_auc_score(y_both_vacc_train[:, 1], rand_forst_multilabel_trainpreds[:, 1])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_train[:, 1], rand_forst_multilabel_trainpreds[:, 1])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_train[:, 1], rand_forst_multilabel_trainpreds[:, 1])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_train[:, 1], rand_forst_multilabel_trainpreds[:, 1])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_train[:, 1], rand_forst_multilabel_trainpreds[:, 1])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_train[:, 1], rand_forst_multilabel_trainpreds[:, 1])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "# SVM--Train data evaluation Metrics for H1N1 Vaccines\n",
    "h1n1_svm_multilabel_train_acc = accuracy_score(y_both_vacc_train[:, 0], svm_multilabel_trainpreds[:, 0])\n",
    "h1n1_svm_multilabel_train_recall = recall_score(y_both_vacc_train[:, 0], svm_multilabel_trainpreds[:, 0])\n",
    "h1n1_svm_multilabel_train_precision = precision_score(y_both_vacc_train[:, 0], svm_multilabel_trainpreds[:, 0])\n",
    "h1n1_svm_multilabel_train_f1 = f1_score(y_both_vacc_train[:, 0], svm_multilabel_trainpreds[:, 0])\n",
    "h1n1_svm_multilabel_train_roc = roc_auc_score(y_both_vacc_train[:, 0], svm_multilabel_trainpreds[:, 0])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_train[:, 0], svm_multilabel_trainpreds[:, 0])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_train[:, 0], svm_multilabel_trainpreds[:, 0])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_train[:, 0], svm_multilabel_trainpreds[:, 0])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_train[:, 0], svm_multilabel_trainpreds[:, 0])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_train[:, 0], svm_multilabel_trainpreds[:, 0])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "# SVM--Train data Evaluation Metrics for seasonal Vaccines\n",
    "seasonal_svm_multilabel_train_acc = accuracy_score(y_both_vacc_train[:, 1], svm_multilabel_trainpreds[:, 1])\n",
    "seasonal_svm_multilabel_train_recall = recall_score(y_both_vacc_train[:, 1], svm_multilabel_trainpreds[:, 1])\n",
    "seasonal_svm_multilabel_train_precision = precision_score(y_both_vacc_train[:, 1], svm_multilabel_trainpreds[:, 1])\n",
    "seasonal_svm_multilabel_train_f1 = f1_score(y_both_vacc_train[:, 1], svm_multilabel_trainpreds[:, 1])\n",
    "seasonal_svm_multilabel_train_roc = roc_auc_score(y_both_vacc_train[:, 1], svm_multilabel_trainpreds[:, 1])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_train[:, 1], svm_multilabel_trainpreds[:, 1])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_train[:, 1], svm_multilabel_trainpreds[:, 1])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_train[:, 1], svm_multilabel_trainpreds[:, 1])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_train[:, 1], svm_multilabel_trainpreds[:, 1])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_train[:, 1], svm_multilabel_trainpreds[:, 1])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Test data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "# Logreg--Test data evaluation Metrics for H1N1 Vaccines\n",
    "h1n1_logreg_multilabel_test_acc = accuracy_score(y_both_vacc_test[:, 0], logreg_multilabel_testpreds[:, 0])\n",
    "h1n1_logreg_multilabel_test_recall = recall_score(y_both_vacc_test[:, 0], logreg_multilabel_testpreds[:, 0])\n",
    "h1n1_logreg_multilabel_test_precision = precision_score(y_both_vacc_test[:, 0], logreg_multilabel_testpreds[:, 0])\n",
    "h1n1_logreg_multilabel_test_f1 = f1_score(y_both_vacc_test[:, 0], logreg_multilabel_testpreds[:, 0])\n",
    "h1n1_logreg_multilabel_test_roc = roc_auc_score(y_both_vacc_test[:, 0], logreg_multilabel_testpreds[:, 0])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_test[:, 0], logreg_multilabel_testpreds[:, 0])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_test[:, 0], logreg_multilabel_testpreds[:, 0])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_test[:, 0], logreg_multilabel_testpreds[:, 0])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_test[:, 0], logreg_multilabel_testpreds[:, 0])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_test[:, 0], logreg_multilabel_testpreds[:, 0])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "# Logreg--Test data Evaluation Metrics for seasonal Vaccines\n",
    "seasonal_logreg_multilabel_test_acc = accuracy_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])\n",
    "seasonal_logreg_multilabel_test_recall = recall_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])\n",
    "seasonal_logreg_multilabel_test_precision = precision_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])\n",
    "seasonal_logreg_multilabel_test_f1 = f1_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])\n",
    "seasonal_logreg_multilabel_test_roc = roc_auc_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "# KNN--Test data evaluation Metrics for H1N1 Vaccines\n",
    "h1n1_knn_multilabel_test_acc = accuracy_score(y_both_vacc_test[:, 0], knn_multilabel_testpreds[:, 0])\n",
    "h1n1_knn_multilabel_test_recall = recall_score(y_both_vacc_test[:, 0], knn_multilabel_testpreds[:, 0])\n",
    "h1n1_knn_multilabel_test_precision = precision_score(y_both_vacc_test[:, 0], knn_multilabel_testpreds[:, 0])\n",
    "h1n1_knn_multilabel_test_f1 = f1_score(y_both_vacc_test[:, 0], knn_multilabel_testpreds[:, 0])\n",
    "h1n1_knn_multilabel_test_roc = roc_auc_score(y_both_vacc_test[:, 0], knn_multilabel_testpreds[:, 0])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_test[:, 0], knn_multilabel_testpreds[:, 0])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_test[:, 0], knn_multilabel_testpreds[:, 0])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_test[:, 0], knn_multilabel_testpreds[:, 0])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_test[:, 0], knn_multilabel_testpreds[:, 0])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_test[:, 0], knn_multilabel_testpreds[:, 0])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "# KNN--Test data Evaluation Metrics for seasonal Vaccines\n",
    "seasonal_knn_multilabel_test_acc = accuracy_score(y_both_vacc_test[:, 1], knn_multilabel_testpreds[:, 1])\n",
    "seasonal_knn_multilabel_test_recall = recall_score(y_both_vacc_test[:, 1], knn_multilabel_testpreds[:, 1])\n",
    "seasonal_knn_multilabel_test_precision = precision_score(y_both_vacc_test[:, 1], knn_multilabel_testpreds[:, 1])\n",
    "seasonal_knn_multilabel_test_f1 = f1_score(y_both_vacc_test[:, 1], knn_multilabel_testpreds[:, 1])\n",
    "seasonal_knn_multilabel_test_roc = roc_auc_score(y_both_vacc_test[:, 1], knn_multilabel_testpreds[:, 1])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_test[:, 1], knn_multilabel_testpreds[:, 1])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_test[:, 1], knn_multilabel_testpreds[:, 1])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_test[:, 1], knn_multilabel_testpreds[:, 1])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_test[:, 1], knn_multilabel_testpreds[:, 1])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_test[:, 1], knn_multilabel_testpreds[:, 1])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "# Random Forest--Test data evaluation Metrics for H1N1 Vaccines\n",
    "# THESE RESULTS ARE SLIGHTLY OFF FROM PREVIOUS NOTEBOOK (BY 0.01)--CHECK WHAT'S AT PLAY. VARIATION COMING FROM TEST-TRAIN SPLIT? EXPORT TEST-TRAIN DATA AS CSV AND TRY AGAIN\n",
    "#IS IT BECAUSE IT'S RANDOM FOREST? DIFFERENT STARTING STUMP EACH TIME?\n",
    "h1n1_rand_forst_multilabel_test_acc = accuracy_score(y_both_vacc_test[:, 0], rand_forst_multilabel_testpreds[:, 0])\n",
    "h1n1_rand_forst_multilabel_test_recall = recall_score(y_both_vacc_test[:, 0], rand_forst_multilabel_testpreds[:, 0])\n",
    "h1n1_rand_forst_multilabel_test_precision = precision_score(y_both_vacc_test[:, 0], rand_forst_multilabel_testpreds[:, 0])\n",
    "h1n1_rand_forst_multilabel_test_f1 = f1_score(y_both_vacc_test[:, 0], rand_forst_multilabel_testpreds[:, 0])\n",
    "h1n1_rand_forst_multilabel_test_roc = roc_auc_score(y_both_vacc_test[:, 0], rand_forst_multilabel_testpreds[:, 0])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_test[:, 0], rand_forst_multilabel_testpreds[:, 0])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_test[:, 0], rand_forst_multilabel_testpreds[:, 0])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_test[:, 0], rand_forst_multilabel_testpreds[:, 0])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_test[:, 0], rand_forst_multilabel_testpreds[:, 0])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_test[:, 0], rand_forst_multilabel_testpreds[:, 0])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "# Random Forest--Test data Evaluation Metrics for seasonal Vaccines\n",
    "# THESE RESULTS ARE SLIGHTLY OFF FROM PREVIOUS NOTEBOOK (BY 0.01)--CHECK WHAT'S AT PLAY. VARIATION COMING FROM TEST-TRAIN SPLIT? EXPORT TEST-TRAIN DATA AS CSV AND TRY AGAIN\n",
    "#IS IT BECAUSE IT'S RANDOM FOREST? DIFFERENT STARTING STUMP EACH TIME?\n",
    "seasonal_rand_forst_multilabel_test_acc = accuracy_score(y_both_vacc_test[:, 1], rand_forst_multilabel_testpreds[:, 1])\n",
    "seasonal_rand_forst_multilabel_test_recall = recall_score(y_both_vacc_test[:, 1], rand_forst_multilabel_testpreds[:, 1])\n",
    "seasonal_rand_forst_multilabel_test_precision = precision_score(y_both_vacc_test[:, 1], rand_forst_multilabel_testpreds[:, 1])\n",
    "seasonal_rand_forst_multilabel_test_f1 = f1_score(y_both_vacc_test[:, 1], rand_forst_multilabel_testpreds[:, 1])\n",
    "seasonal_rand_forst_multilabel_test_roc = roc_auc_score(y_both_vacc_test[:, 1], rand_forst_multilabel_testpreds[:, 1])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_test[:, 1], rand_forst_multilabel_testpreds[:, 1])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_test[:, 1], rand_forst_multilabel_testpreds[:, 1])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_test[:, 1], rand_forst_multilabel_testpreds[:, 1])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_test[:, 1], rand_forst_multilabel_testpreds[:, 1])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_test[:, 1], rand_forst_multilabel_testpreds[:, 1])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "# SVM--Test data evaluation Metrics for H1N1 Vaccines\n",
    "h1n1_svm_multilabel_test_acc = accuracy_score(y_both_vacc_test[:, 0], svm_multilabel_testpreds[:, 0])\n",
    "h1n1_svm_multilabel_test_recall = recall_score(y_both_vacc_test[:, 0], svm_multilabel_testpreds[:, 0])\n",
    "h1n1_svm_multilabel_test_precision = precision_score(y_both_vacc_test[:, 0], svm_multilabel_testpreds[:, 0])\n",
    "h1n1_svm_multilabel_test_f1 = f1_score(y_both_vacc_test[:, 0], svm_multilabel_testpreds[:, 0])\n",
    "h1n1_svm_multilabel_test_roc = roc_auc_score(y_both_vacc_test[:, 0], svm_multilabel_testpreds[:, 0])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_test[:, 0], svm_multilabel_testpreds[:, 0])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_test[:, 0], svm_multilabel_testpreds[:, 0])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_test[:, 0], svm_multilabel_testpreds[:, 0])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_test[:, 0], svm_multilabel_testpreds[:, 0])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_test[:, 0], svm_multilabel_testpreds[:, 0])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "# SVM--Test data Evaluation Metrics for seasonal Vaccines\n",
    "seasonal_svm_multilabel_test_acc = accuracy_score(y_both_vacc_test[:, 1], svm_multilabel_testpreds[:, 1])\n",
    "seasonal_svm_multilabel_test_recall = recall_score(y_both_vacc_test[:, 1], svm_multilabel_testpreds[:, 1])\n",
    "seasonal_svm_multilabel_test_precision = precision_score(y_both_vacc_test[:, 1], svm_multilabel_testpreds[:, 1])\n",
    "seasonal_svm_multilabel_test_f1 = f1_score(y_both_vacc_test[:, 1], svm_multilabel_testpreds[:, 1])\n",
    "seasonal_svm_multilabel_test_roc = roc_auc_score(y_both_vacc_test[:, 1], svm_multilabel_testpreds[:, 1])\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_both_vacc_test[:, 1], logreg_multilabel_testpreds[:, 1])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tracking the model with MLFlow"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### H1N1 vaccine output"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Logistic regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_multilabel) #this needs to be adjusted for each experiment\n",
    "name = 'logreg_multilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Active run_id: 729a56eea9814086a02a5b290c445eef\n"
     ]
    }
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Drop all nulls\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_logreg_multilabel_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_logreg_multilabel_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_logreg_multilabel_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_logreg_multilabel_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_logreg_multilabel_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_logreg_multilabel_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_logreg_multilabel_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_logreg_multilabel_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_logreg_multilabel_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_logreg_multilabel_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<Run: data=<RunData: metrics={'test -ROC': 0.6908088321028654,\n",
       " 'test -accuracy': 0.825440402653855,\n",
       " 'test -f1': 0.5356055995130858,\n",
       " 'test -precision': 0.672782874617737,\n",
       " 'test -recall': 0.4448938321536906,\n",
       " 'train -ROC': 0.7053562554709693,\n",
       " 'train -accuracy': 0.833485871181787,\n",
       " 'train -f1': 0.5616624002409276,\n",
       " 'train -precision': 0.6951174058889303,\n",
       " 'train -recall': 0.4711975745325922}, params={'Data balancing': 'None',\n",
       " 'Data cleaning': 'Drop all nulls',\n",
       " 'Hyperparameters': 'None'}, tags={'Vaccines in features': 'None',\n",
       " 'mlflow.runName': 'logreg_multilabel_h1n1',\n",
       " 'mlflow.source.git.commit': '4d215498c00f64a529b2e337703b17da7ed152e1',\n",
       " 'mlflow.source.name': '/Users/christinarudolf/Documents/neuefische_ds/TheFluShot/.venv/lib/python3.8/site-packages/ipykernel_launcher.py',\n",
       " 'mlflow.source.type': 'LOCAL',\n",
       " 'mlflow.user': 'christinarudolf'}>, info=<RunInfo: artifact_uri='s3://neuefische-mlflow/mlflow-artifacts/24/729a56eea9814086a02a5b290c445eef/artifacts', end_time=1627032405861, experiment_id='24', lifecycle_stage='active', run_id='729a56eea9814086a02a5b290c445eef', run_uuid='729a56eea9814086a02a5b290c445eef', start_time=1627032404322, status='FINISHED', user_id='christinarudolf'>>"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### KNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_multilabel)\n",
    "name = 'knn_multilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Active run_id: 56850378a81a46b8b0664cdf0c1aa89c\n"
     ]
    }
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Drop all nulls\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_knn_multilabel_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_knn_multilabel_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_knn_multilabel_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_knn_multilabel_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_knn_multilabel_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_knn_multilabel_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_knn_multilabel_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_knn_multilabel_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_knn_multilabel_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_knn_multilabel_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_multilabel)\n",
    "name = 'rand_forst_multilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Active run_id: d28944cba4ff481ab0d0ab9d62087f4d\n"
     ]
    }
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Drop all nulls\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_rand_forst_multilabel_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_rand_forst_multilabel_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_rand_forst_multilabel_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_rand_forst_multilabel_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_rand_forst_multilabel_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_rand_forst_multilabel_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_rand_forst_multilabel_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_rand_forst_multilabel_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_rand_forst_multilabel_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_rand_forst_multilabel_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### SVM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_multilabel)\n",
    "name = 'svm_multilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Active run_id: cefe0a77981840d7b3202b14e2292328\n"
     ]
    }
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Drop all nulls\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_svm_multilabel_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_svm_multilabel_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_svm_multilabel_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_svm_multilabel_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_svm_multilabel_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_svm_multilabel_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_svm_multilabel_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_svm_multilabel_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_svm_multilabel_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_svm_multilabel_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Seasonal vaccine output"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Logistic regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_multilabel)\n",
    "name = 'logreg_multilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Active run_id: 6bcacfa13e25436d90c7eeb215d17529\n"
     ]
    }
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Drop all nulls\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seasonal_logreg_multilabel_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seasonal_logreg_multilabel_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seasonal_logreg_multilabel_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seasonal_logreg_multilabel_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seasonal_logreg_multilabel_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seasonal_logreg_multilabel_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seasonal_logreg_multilabel_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seasonal_logreg_multilabel_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seasonal_logreg_multilabel_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seasonal_logreg_multilabel_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### KNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_multilabel)\n",
    "name = 'knn_multilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Active run_id: 200f3615147a46fca7470af1d1993900\n"
     ]
    }
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Drop all nulls\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seasonal_knn_multilabel_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seasonal_knn_multilabel_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seasonal_knn_multilabel_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seasonal_knn_multilabel_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seasonal_knn_multilabel_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seasonal_knn_multilabel_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seasonal_knn_multilabel_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seasonal_knn_multilabel_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seasonal_knn_multilabel_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seasonal_knn_multilabel_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_multilabel)\n",
    "name = 'rand_forst_multilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Active run_id: 5c97e669ffd24b27adefb7144d080d01\n"
     ]
    }
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Drop all nulls\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seasonal_rand_forst_multilabel_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seasonal_rand_forst_multilabel_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seasonal_rand_forst_multilabel_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seasonal_rand_forst_multilabel_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seasonal_rand_forst_multilabel_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seasonal_rand_forst_multilabel_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seasonal_rand_forst_multilabel_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seasonal_rand_forst_multilabel_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seasonal_rand_forst_multilabel_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seasonal_rand_forst_multilabel_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### SVM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_multilabel)\n",
    "name = 'svm_multilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Active run_id: f797b63dc0624a8ca34f6e919d7e166c\n"
     ]
    }
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Drop all nulls\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seasonal_svm_multilabel_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seasonal_svm_multilabel_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seasonal_svm_multilabel_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seasonal_svm_multilabel_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seasonal_svm_multilabel_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seasonal_svm_multilabel_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seasonal_svm_multilabel_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seasonal_svm_multilabel_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seasonal_svm_multilabel_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seasonal_svm_multilabel_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TheFluShot_H1N1: Single Label Modelling, output H1N1 vaccine"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Single Label Modelling, output H1N1 vaccine -> Seasonal Flu Vaccine not in features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The cat_features_no_vacc and X_no_vacc variables and the preprocessor remain the same from the multilabel modelling:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set up the target variable:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "y_h1n1_vacc = df[['h1n1_vaccine']].copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "source": [
    "y_h1n1_vacc = y_h1n1_vacc.to_numpy()\n",
    "y_h1n1_vacc"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "metadata": {},
     "execution_count": 108
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Performing test-train split:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "source": [
    "X_no_vacc_train, X_no_vacc_test, y_h1n1_vacc_train, y_h1n1_vacc_test = train_test_split(X_no_vacc, y_h1n1_vacc, stratify = y_h1n1_vacc, test_size=0.2, random_state=RSEED)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "source": [
    "print('X_no_vacc_train shape:', X_no_vacc_train.shape)\n",
    "print('X_no_vacc_test shape:', X_no_vacc_test.shape)\n",
    "print('y_h1n1_vacc_train:', y_h1n1_vacc_train.shape)\n",
    "print('y_h1n1_vacc_test:', y_h1n1_vacc_test.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X_no_vacc_train shape: (17482, 29)\n",
      "X_no_vacc_test shape: (4371, 29)\n",
      "y_h1n1_vacc_train: (17482, 1)\n",
      "y_h1n1_vacc_test: (4371, 1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setting up the pipeline for each model:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "# for logreg\n",
    "logreg_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", logreg),\n",
    "])\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", knn),\n",
    "])\n",
    "\n",
    "# for Random Forest\n",
    "\n",
    "rand_forst_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", rand_forst),\n",
    "])\n",
    "\n",
    "#for SVM\n",
    "svm_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", svm),\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training the models:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "# for logreg\n",
    "logreg_unilabel_no_vacc = logreg_unilabel_pipeline.fit(X_no_vacc_train, y_h1n1_vacc_train)\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_no_vacc = knn_unilabel_pipeline.fit(X_no_vacc_train, y_h1n1_vacc_train)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_unilabel_no_vacc = rand_forst_unilabel_pipeline.fit(X_no_vacc_train, y_h1n1_vacc_train)\n",
    "\n",
    "#for SVM\n",
    "svm_unilabel_no_vacc = svm_unilabel_pipeline.fit(X_no_vacc_train, y_h1n1_vacc_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "source": [
    "# Figure out later what this does and if we want to use it\n",
    "\n",
    "\n",
    "#y_train_predicted = cross_val_predict(full_pipeline, X_train, y_train, cv=5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Making predictions based on train and test data:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "source": [
    "# for logreg\n",
    "logreg_unilabel_no_vacc_trainpreds = logreg_unilabel_no_vacc.predict(X_no_vacc_train)\n",
    "logreg_unilabel_no_vacc_testpreds = logreg_unilabel_no_vacc.predict(X_no_vacc_test)\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_no_vacc_trainpreds = knn_unilabel_no_vacc.predict(X_no_vacc_train)\n",
    "knn_unilabel_no_vacc_testpreds = knn_unilabel_no_vacc.predict(X_no_vacc_test)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_unilabel_no_vacc_trainpreds = rand_forst_unilabel_no_vacc.predict(X_no_vacc_train)\n",
    "rand_forst_unilabel_no_vacc_testpreds = rand_forst_unilabel_no_vacc.predict(X_no_vacc_test)\n",
    "\n",
    "# for SVM\n",
    "svm_unilabel_no_vacc_trainpreds = svm_unilabel_no_vacc.predict(X_no_vacc_train)\n",
    "svm_unilabel_no_vacc_testpreds = svm_unilabel_no_vacc.predict(X_no_vacc_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model evaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "source": [
    "# Logreg--Train data evaluation Metrics\n",
    "h1n1_logreg_unilabel_no_vacc_train_acc = accuracy_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_trainpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_train_recall = recall_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_trainpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_train_precision = precision_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_trainpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_train_f1 = f1_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_trainpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_train_roc = roc_auc_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_train, logreg_unilabel_no_vacc_trainpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "source": [
    "# KNN--Train data evaluation Metrics\n",
    "h1n1_knn_unilabel_no_vacc_train_acc = accuracy_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_trainpreds)\n",
    "h1n1_knn_unilabel_no_vacc_train_recall = recall_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_trainpreds)\n",
    "h1n1_knn_unilabel_no_vacc_train_precision = precision_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_trainpreds)\n",
    "h1n1_knn_unilabel_no_vacc_train_f1 = f1_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_trainpreds)\n",
    "h1n1_knn_unilabel_no_vacc_train_roc = roc_auc_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_train, knn_unilabel_no_vacc_trainpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "source": [
    "# Random Forest--Train data evaluation Metrics\n",
    "#check if these metrics are changing compared to previous results\n",
    "h1n1_rand_forst_unilabel_no_vacc_train_acc = accuracy_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_train_recall = recall_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_train_precision = precision_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_train_f1 = f1_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_train_roc = roc_auc_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "source": [
    "# SVM--Train data evaluation Metrics\n",
    "h1n1_svm_unilabel_no_vacc_train_acc = accuracy_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_trainpreds)\n",
    "h1n1_svm_unilabel_no_vacc_train_recall = recall_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_trainpreds)\n",
    "h1n1_svm_unilabel_no_vacc_train_precision = precision_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_trainpreds)\n",
    "h1n1_svm_unilabel_no_vacc_train_f1 = f1_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_trainpreds)\n",
    "h1n1_svm_unilabel_no_vacc_train_roc = roc_auc_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_train, svm_unilabel_no_vacc_trainpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Test data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "# Logreg--Test data evaluation Metrics\n",
    "h1n1_logreg_unilabel_no_vacc_test_acc = accuracy_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_testpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_test_recall = recall_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_testpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_test_precision = precision_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_testpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_test_f1 = f1_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_testpreds)\n",
    "h1n1_logreg_unilabel_no_vacc_test_roc = roc_auc_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_test, logreg_unilabel_no_vacc_testpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "source": [
    "# KNN--Test data evaluation Metrics\n",
    "h1n1_knn_unilabel_no_vacc_test_acc = accuracy_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_testpreds)\n",
    "h1n1_knn_unilabel_no_vacc_test_recall = recall_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_testpreds)\n",
    "h1n1_knn_unilabel_no_vacc_test_precision = precision_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_testpreds)\n",
    "h1n1_knn_unilabel_no_vacc_test_f1 = f1_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_testpreds)\n",
    "h1n1_knn_unilabel_no_vacc_test_roc = roc_auc_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_test, knn_unilabel_no_vacc_testpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "# Random Forest--Test data evaluation Metrics\n",
    "#check if these metrics are changing compared to previous results\n",
    "h1n1_rand_forst_unilabel_no_vacc_test_acc = accuracy_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_testpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_test_recall = recall_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_testpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_test_precision = precision_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_testpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_test_f1 = f1_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_testpreds)\n",
    "h1n1_rand_forst_unilabel_no_vacc_test_roc = roc_auc_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_test, rand_forst_unilabel_no_vacc_testpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "# SVM--Test data evaluation Metrics\n",
    "h1n1_svm_unilabel_no_vacc_test_acc = accuracy_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_testpreds)\n",
    "h1n1_svm_unilabel_no_vacc_test_recall = recall_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_testpreds)\n",
    "h1n1_svm_unilabel_no_vacc_test_precision = precision_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_testpreds)\n",
    "h1n1_svm_unilabel_no_vacc_test_f1 = f1_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_testpreds)\n",
    "h1n1_svm_unilabel_no_vacc_test_roc = roc_auc_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_test, svm_unilabel_no_vacc_testpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tracking the model with MLFlow"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### H1N1 vaccine output"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Logistic regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_h1n1) #this needs to be adjusted for each experiment\n",
    "name = 'logreg_unilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Active run_id: 34a92dec6ec84aa5850d4a1ff7f82709\n"
     ]
    }
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Drop all nulls\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_logreg_unilabel_no_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_logreg_unilabel_no_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_logreg_unilabel_no_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_logreg_unilabel_no_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_logreg_unilabel_no_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_logreg_unilabel_no_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_logreg_unilabel_no_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_logreg_unilabel_no_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_logreg_unilabel_no_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_logreg_unilabel_no_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### KNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_h1n1)\n",
    "name = 'knn_unilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Active run_id: 504f12cbfe6146009549b907d0d7fc0f\n"
     ]
    }
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Drop all nulls\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_knn_unilabel_no_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_knn_unilabel_no_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_knn_unilabel_no_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_knn_unilabel_no_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_knn_unilabel_no_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_knn_unilabel_no_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_knn_unilabel_no_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_knn_unilabel_no_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_knn_unilabel_no_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_knn_unilabel_no_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_h1n1)\n",
    "name = 'rand_forst_unilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Active run_id: 9edf7207fd0a4a90996538735a4d6789\n"
     ]
    }
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Drop all nulls\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_rand_forst_unilabel_no_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_rand_forst_unilabel_no_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_rand_forst_unilabel_no_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_rand_forst_unilabel_no_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_rand_forst_unilabel_no_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_rand_forst_unilabel_no_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_rand_forst_unilabel_no_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_rand_forst_unilabel_no_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_rand_forst_unilabel_no_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_rand_forst_unilabel_no_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### SVM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_h1n1)\n",
    "name = 'svm_unilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Active run_id: d532f870cd69491d9dd87a50b0a1d70b\n"
     ]
    }
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Drop all nulls\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_svm_unilabel_no_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_svm_unilabel_no_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_svm_unilabel_no_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_svm_unilabel_no_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_svm_unilabel_no_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_svm_unilabel_no_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_svm_unilabel_no_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_svm_unilabel_no_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_svm_unilabel_no_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_svm_unilabel_no_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Single Label Modelling, output H1N1 vaccine -> Seasonal Flu Vaccine is in features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The y_h1n1_vacc remains the same from the previous model; the X feature and cat_features (for the preprocessor) need to be adjusted:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "source": [
    "cat_features_seas_vacc = cat_features.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "source": [
    "cat_features_seas_vacc.remove('h1n1_vaccine')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "source": [
    "#NB: dropping the 'h1n1_vaccine' and 'seasonal_vaccine' columns\n",
    "X_seas_vacc = df.drop(columns=['h1n1_vaccine'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "source": [
    "X_seas_vacc.columns"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['seasonal_vaccine', 'h1n1_concern', 'h1n1_knowledge',\n",
       "       'behavioral_antiviral_meds', 'behavioral_avoidance',\n",
       "       'behavioral_face_mask', 'behavioral_wash_hands',\n",
       "       'behavioral_large_gatherings', 'behavioral_outside_home',\n",
       "       'behavioral_touch_face', 'doctor_recc_h1n1', 'doctor_recc_seasonal',\n",
       "       'chronic_med_condition', 'child_under_6_months', 'health_worker',\n",
       "       'opinion_h1n1_vacc_effective', 'opinion_h1n1_risk',\n",
       "       'opinion_h1n1_sick_from_vacc', 'opinion_seas_vacc_effective',\n",
       "       'opinion_seas_risk', 'opinion_seas_sick_from_vacc', 'age_group',\n",
       "       'education', 'race', 'sex', 'rent_or_own', 'hhs_geo_region',\n",
       "       'census_msa', 'household_adults', 'household_children'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 146
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Performing test-train split (the same data can be used for each model in multilabelling):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "source": [
    "X_seas_vacc_train, X_seas_vacc_test, y_h1n1_vacc_train, y_h1n1_vacc_test = train_test_split(X_seas_vacc, y_h1n1_vacc, stratify = y_h1n1_vacc, test_size=0.2, random_state=RSEED)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "source": [
    "print('X_seas_vacc_train shape:', X_seas_vacc_train.shape)\n",
    "print('X_seas_vacc_test shape:', X_seas_vacc_test.shape)\n",
    "print('y_h1n1_vacc_train:', y_h1n1_vacc_train.shape)\n",
    "print('y_h1n1_vacc_test:', y_h1n1_vacc_test.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X_seas_vacc_train shape: (17482, 30)\n",
      "X_seas_vacc_test shape: (4371, 30)\n",
      "y_h1n1_vacc_train: (17482, 1)\n",
      "y_h1n1_vacc_test: (4371, 1)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preprocessor is adjusted:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "source": [
    "preprocessor_seas_vacc = ColumnTransformer([\n",
    "    ('cat', cat_pipeline, cat_features_seas_vacc)\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pipeline is adjusted:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "source": [
    "# for logreg\n",
    "logreg_seas_vacc_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_seas_vacc),\n",
    "    (\"estimators\", logreg),\n",
    "])\n",
    "\n",
    "# for KNN\n",
    "knn_seas_vacc_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_seas_vacc),\n",
    "    (\"estimators\", knn),\n",
    "])\n",
    "\n",
    "# for Random Forest\n",
    "\n",
    "rand_forst_seas_vacc_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_seas_vacc),\n",
    "    (\"estimators\", rand_forst),\n",
    "])\n",
    "\n",
    "#for SVM\n",
    "svm_seas_vacc_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor_seas_vacc),\n",
    "    (\"estimators\", svm),\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training the models:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "source": [
    "# for logreg\n",
    "logreg_unilabel_seas_vacc = logreg_seas_vacc_unilabel_pipeline.fit(X_seas_vacc_train, y_h1n1_vacc_train)\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_seas_vacc = knn_seas_vacc_unilabel_pipeline.fit(X_seas_vacc_train, y_h1n1_vacc_train)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_unilabel_seas_vacc = rand_forst_seas_vacc_unilabel_pipeline.fit(X_seas_vacc_train, y_h1n1_vacc_train)\n",
    "\n",
    "#for SVM\n",
    "svm_unilabel_seas_vacc = svm_seas_vacc_unilabel_pipeline.fit(X_seas_vacc_train, y_h1n1_vacc_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Figure out later what this does and if we want to use it\n",
    "\n",
    "\n",
    "#y_train_predicted = cross_val_predict(full_pipeline, X_train, y_train, cv=5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Making predictions based on train and test data:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "source": [
    "# for logreg\n",
    "logreg_unilabel_seas_vacc_trainpreds = logreg_unilabel_seas_vacc.predict(X_seas_vacc_train)\n",
    "logreg_unilabel_seas_vacc_testpreds = logreg_unilabel_seas_vacc.predict(X_seas_vacc_test)\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_seas_vacc_trainpreds = knn_unilabel_seas_vacc.predict(X_seas_vacc_train)\n",
    "knn_unilabel_seas_vacc_testpreds = knn_unilabel_seas_vacc.predict(X_seas_vacc_test)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_unilabel_seas_vacc_trainpreds = rand_forst_unilabel_seas_vacc.predict(X_seas_vacc_train)\n",
    "rand_forst_unilabel_seas_vacc_testpreds = rand_forst_unilabel_seas_vacc.predict(X_seas_vacc_test)\n",
    "\n",
    "# for SVM\n",
    "svm_unilabel_seas_vacc_trainpreds = svm_unilabel_seas_vacc.predict(X_seas_vacc_train)\n",
    "svm_unilabel_seas_vacc_testpreds = svm_unilabel_seas_vacc.predict(X_seas_vacc_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model evaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "source": [
    "# Logreg--Train data evaluation Metrics\n",
    "h1n1_logreg_unilabel_seas_vacc_train_acc = accuracy_score(y_h1n1_vacc_train, logreg_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_logreg_unilabel_seas_vacc_train_recall = recall_score(y_h1n1_vacc_train, logreg_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_logreg_unilabel_seas_vacc_train_precision = precision_score(y_h1n1_vacc_train, logreg_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_logreg_unilabel_seas_vacc_train_f1 = f1_score(y_h1n1_vacc_train, logreg_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_logreg_unilabel_seas_vacc_train_roc = roc_auc_score(y_h1n1_vacc_train, logreg_unilabel_seas_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_train, logreg_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_train, logreg_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_train, logreg_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_train, logreg_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_train, logreg_unilabel_seas_vacc_trainpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "source": [
    "# KNN--Train data evaluation Metrics\n",
    "h1n1_knn_unilabel_seas_vacc_train_acc = accuracy_score(y_h1n1_vacc_train, knn_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_knn_unilabel_seas_vacc_train_recall = recall_score(y_h1n1_vacc_train, knn_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_knn_unilabel_seas_vacc_train_precision = precision_score(y_h1n1_vacc_train, knn_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_knn_unilabel_seas_vacc_train_f1 = f1_score(y_h1n1_vacc_train, knn_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_knn_unilabel_seas_vacc_train_roc = roc_auc_score(y_h1n1_vacc_train, knn_unilabel_seas_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_train, knn_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_train, knn_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_train, knn_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_train, knn_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_train, knn_unilabel_seas_vacc_trainpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "source": [
    "# Random Forest--Train data evaluation Metrics\n",
    "#check if these metrics are changing compared to previous results\n",
    "h1n1_rand_forst_unilabel_seas_vacc_train_acc = accuracy_score(y_h1n1_vacc_train, rand_forst_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_rand_forst_unilabel_seas_vacc_train_recall = recall_score(y_h1n1_vacc_train, rand_forst_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_rand_forst_unilabel_seas_vacc_train_precision = precision_score(y_h1n1_vacc_train, rand_forst_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_rand_forst_unilabel_seas_vacc_train_f1 = f1_score(y_h1n1_vacc_train, rand_forst_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_rand_forst_unilabel_seas_vacc_train_roc = roc_auc_score(y_h1n1_vacc_train, rand_forst_unilabel_seas_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_train, rand_forst_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_train, rand_forst_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_train, rand_forst_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_train, rand_forst_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_train, rand_forst_unilabel_seas_vacc_trainpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "source": [
    "# SVM--Train data evaluation Metrics\n",
    "h1n1_svm_unilabel_seas_vacc_train_acc = accuracy_score(y_h1n1_vacc_train, svm_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_svm_unilabel_seas_vacc_train_recall = recall_score(y_h1n1_vacc_train, svm_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_svm_unilabel_seas_vacc_train_precision = precision_score(y_h1n1_vacc_train, svm_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_svm_unilabel_seas_vacc_train_f1 = f1_score(y_h1n1_vacc_train, svm_unilabel_seas_vacc_trainpreds)\n",
    "h1n1_svm_unilabel_seas_vacc_train_roc = roc_auc_score(y_h1n1_vacc_train, svm_unilabel_seas_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_train, svm_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_train, svm_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_train, svm_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_train, svm_unilabel_seas_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_train, svm_unilabel_seas_vacc_trainpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Test data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "source": [
    "# Logreg--Test data evaluation Metrics\n",
    "h1n1_logreg_unilabel_seas_vacc_test_acc = accuracy_score(y_h1n1_vacc_test, logreg_unilabel_seas_vacc_testpreds)\n",
    "h1n1_logreg_unilabel_seas_vacc_test_recall = recall_score(y_h1n1_vacc_test, logreg_unilabel_seas_vacc_testpreds)\n",
    "h1n1_logreg_unilabel_seas_vacc_test_precision = precision_score(y_h1n1_vacc_test, logreg_unilabel_seas_vacc_testpreds)\n",
    "h1n1_logreg_unilabel_seas_vacc_test_f1 = f1_score(y_h1n1_vacc_test, logreg_unilabel_seas_vacc_testpreds)\n",
    "h1n1_logreg_unilabel_seas_vacc_test_roc = roc_auc_score(y_h1n1_vacc_test, logreg_unilabel_seas_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_test, logreg_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_test, logreg_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_test, logreg_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_test, logreg_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_test, logreg_unilabel_seas_vacc_testpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "source": [
    "# KNN--Test data evaluation Metrics\n",
    "h1n1_knn_unilabel_seas_vacc_test_acc = accuracy_score(y_h1n1_vacc_test, knn_unilabel_seas_vacc_testpreds)\n",
    "h1n1_knn_unilabel_seas_vacc_test_recall = recall_score(y_h1n1_vacc_test, knn_unilabel_seas_vacc_testpreds)\n",
    "h1n1_knn_unilabel_seas_vacc_test_precision = precision_score(y_h1n1_vacc_test, knn_unilabel_seas_vacc_testpreds)\n",
    "h1n1_knn_unilabel_seas_vacc_test_f1 = f1_score(y_h1n1_vacc_test, knn_unilabel_seas_vacc_testpreds)\n",
    "h1n1_knn_unilabel_seas_vacc_test_roc = roc_auc_score(y_h1n1_vacc_test, knn_unilabel_seas_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_test, knn_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_test, knn_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_test, knn_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_test, knn_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_test, knn_unilabel_seas_vacc_testpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "source": [
    "# Random Forest--Test data evaluation Metrics\n",
    "#check if these metrics are changing compared to previous results\n",
    "h1n1_rand_forst_unilabel_seas_vacc_test_acc = accuracy_score(y_h1n1_vacc_test, rand_forst_unilabel_seas_vacc_testpreds)\n",
    "h1n1_rand_forst_unilabel_seas_vacc_test_recall = recall_score(y_h1n1_vacc_test, rand_forst_unilabel_seas_vacc_testpreds)\n",
    "h1n1_rand_forst_unilabel_seas_vacc_test_precision = precision_score(y_h1n1_vacc_test, rand_forst_unilabel_seas_vacc_testpreds)\n",
    "h1n1_rand_forst_unilabel_seas_vacc_test_f1 = f1_score(y_h1n1_vacc_test, rand_forst_unilabel_seas_vacc_testpreds)\n",
    "h1n1_rand_forst_unilabel_seas_vacc_test_roc = roc_auc_score(y_h1n1_vacc_test, rand_forst_unilabel_seas_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_test, rand_forst_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_test, rand_forst_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_test, rand_forst_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_test, rand_forst_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_test, rand_forst_unilabel_seas_vacc_testpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "source": [
    "# SVM--Test data evaluation Metrics\n",
    "h1n1_svm_unilabel_seas_vacc_test_acc = accuracy_score(y_h1n1_vacc_test, svm_unilabel_seas_vacc_testpreds)\n",
    "h1n1_svm_unilabel_seas_vacc_test_recall = recall_score(y_h1n1_vacc_test, svm_unilabel_seas_vacc_testpreds)\n",
    "h1n1_svm_unilabel_seas_vacc_test_precision = precision_score(y_h1n1_vacc_test, svm_unilabel_seas_vacc_testpreds)\n",
    "h1n1_svm_unilabel_seas_vacc_test_f1 = f1_score(y_h1n1_vacc_test, svm_unilabel_seas_vacc_testpreds)\n",
    "h1n1_svm_unilabel_seas_vacc_test_roc = roc_auc_score(y_h1n1_vacc_test, svm_unilabel_seas_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_h1n1_vacc_test, svm_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_h1n1_vacc_test, svm_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_h1n1_vacc_test, svm_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_h1n1_vacc_test, svm_unilabel_seas_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_h1n1_vacc_test, svm_unilabel_seas_vacc_testpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tracking the model with MLFlow"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### H1N1 vaccine output"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Logistic regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_h1n1) #this needs to be adjusted for each experiment\n",
    "name = 'logreg_unilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Active run_id: 0f5307b0a6504ac8b0ae80e1427892e0\n"
     ]
    }
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Drop all nulls\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"Seasonal\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_logreg_unilabel_seas_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_logreg_unilabel_seas_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_logreg_unilabel_seas_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_logreg_unilabel_seas_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_logreg_unilabel_seas_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_logreg_unilabel_seas_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_logreg_unilabel_seas_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_logreg_unilabel_seas_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_logreg_unilabel_seas_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_logreg_unilabel_seas_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### KNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_h1n1)\n",
    "name = 'knn_unilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Active run_id: 8625e38c36be4f639df526499c91f974\n"
     ]
    }
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Drop all nulls\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"Seasonal\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_knn_unilabel_seas_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_knn_unilabel_seas_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_knn_unilabel_seas_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_knn_unilabel_seas_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_knn_unilabel_seas_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_knn_unilabel_seas_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_knn_unilabel_seas_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_knn_unilabel_seas_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_knn_unilabel_seas_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_knn_unilabel_seas_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_h1n1)\n",
    "name = 'rand_forst_unilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Active run_id: d0dadf7a5b7f4b748a9889977b2cb503\n"
     ]
    }
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Drop all nulls\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"Seasonal\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_rand_forst_unilabel_seas_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_rand_forst_unilabel_seas_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_rand_forst_unilabel_seas_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_rand_forst_unilabel_seas_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_rand_forst_unilabel_seas_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_rand_forst_unilabel_seas_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_rand_forst_unilabel_seas_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_rand_forst_unilabel_seas_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_rand_forst_unilabel_seas_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_rand_forst_unilabel_seas_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### SVM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_h1n1)\n",
    "name = 'svm_unilabel_h1n1' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Active run_id: 441de9f5927b40bba0a64ca3c409a1d5\n"
     ]
    }
   ],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Drop all nulls\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"Seasonal\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", h1n1_svm_unilabel_seas_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", h1n1_svm_unilabel_seas_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", h1n1_svm_unilabel_seas_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", h1n1_svm_unilabel_seas_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", h1n1_svm_unilabel_seas_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", h1n1_svm_unilabel_seas_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", h1n1_svm_unilabel_seas_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", h1n1_svm_unilabel_seas_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", h1n1_svm_unilabel_seas_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", h1n1_svm_unilabel_seas_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TheFluShot_seasonal: Single Label Modelling, output seasonal vaccine"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Single Label Modelling, output seasonal vaccine -> H1N1 Flu Vaccine not in features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The cat_features_no_vacc and X_no_vacc variables and the preprocessor remain the same from the multilabel modelling:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Set up the target variable:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_seas_vacc = df[['seasonal_vaccine']].copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_seas_vacc = y_seas_vacc.to_numpy()\n",
    "y_seas_vacc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Performing test-train split:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_no_vacc_train, X_no_vacc_test, y_seas_vacc_train, y_seas_vacc_test = train_test_split(X_no_vacc, y_seas_vacc, stratify = y_seas_vacc, test_size=0.2, random_state=RSEED)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('X_no_vacc_train shape:', X_no_vacc_train.shape)\n",
    "print('X_no_vacc_test shape:', X_no_vacc_test.shape)\n",
    "print('y_seas_vacc_train:', y_seas_vacc_train.shape)\n",
    "print('y_seas_vacc_test:', y_seas_vacc_test.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setting up the pipeline for each model:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for logreg\n",
    "logreg_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", logreg),\n",
    "])\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", knn),\n",
    "])\n",
    "\n",
    "# for Random Forest\n",
    "\n",
    "rand_forst_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", rand_forst),\n",
    "])\n",
    "\n",
    "#for SVM\n",
    "svm_unilabel_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", svm),\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training the models:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for logreg\n",
    "logreg_unilabel_no_vacc = logreg_unilabel_pipeline.fit(X_no_vacc_train, y_seas_vacc_train)\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_no_vacc = knn_unilabel_pipeline.fit(X_no_vacc_train, y_seas_vacc_train)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_unilabel_no_vacc = rand_forst_unilabel_pipeline.fit(X_no_vacc_train, y_seas_vacc_train)\n",
    "\n",
    "#for SVM\n",
    "svm_unilabel_no_vacc = svm_unilabel_pipeline.fit(X_no_vacc_train, y_seas_vacc_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Figure out later what this does and if we want to use it\n",
    "\n",
    "\n",
    "#y_train_predicted = cross_val_predict(full_pipeline, X_train, y_train, cv=5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Making predictions based on train and test data:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for logreg\n",
    "logreg_unilabel_no_vacc_trainpreds = logreg_unilabel_no_vacc.predict(X_no_vacc_train)\n",
    "logreg_unilabel_no_vacc_testpreds = logreg_unilabel_no_vacc.predict(X_no_vacc_test)\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_no_vacc_trainpreds = knn_unilabel_no_vacc.predict(X_no_vacc_train)\n",
    "knn_unilabel_no_vacc_testpreds = knn_unilabel_no_vacc.predict(X_no_vacc_test)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_unilabel_no_vacc_trainpreds = rand_forst_unilabel_no_vacc.predict(X_no_vacc_train)\n",
    "rand_forst_unilabel_no_vacc_testpreds = rand_forst_unilabel_no_vacc.predict(X_no_vacc_test)\n",
    "\n",
    "# for SVM\n",
    "svm_unilabel_no_vacc_trainpreds = svm_unilabel_no_vacc.predict(X_no_vacc_train)\n",
    "svm_unilabel_no_vacc_testpreds = svm_unilabel_no_vacc.predict(X_no_vacc_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model evaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Logreg--Train data evaluation Metrics\n",
    "seas_logreg_unilabel_no_vacc_train_acc = accuracy_score(y_seas_vacc_train, logreg_unilabel_no_vacc_trainpreds)\n",
    "seas_logreg_unilabel_no_vacc_train_recall = recall_score(y_seas_vacc_train, logreg_unilabel_no_vacc_trainpreds)\n",
    "seas_logreg_unilabel_no_vacc_train_precision = precision_score(y_seas_vacc_train, logreg_unilabel_no_vacc_trainpreds)\n",
    "seas_logreg_unilabel_no_vacc_train_f1 = f1_score(y_seas_vacc_train, logreg_unilabel_no_vacc_trainpreds)\n",
    "seas_logreg_unilabel_no_vacc_train_roc = roc_auc_score(y_seas_vacc_train, logreg_unilabel_no_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_train, logreg_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_train, logreg_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_train, logreg_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_train, logreg_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_train, logreg_unilabel_no_vacc_trainpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# KNN--Train data evaluation Metrics\n",
    "seas_knn_unilabel_no_vacc_train_acc = accuracy_score(y_seas_vacc_train, knn_unilabel_no_vacc_trainpreds)\n",
    "seas_knn_unilabel_no_vacc_train_recall = recall_score(y_seas_vacc_train, knn_unilabel_no_vacc_trainpreds)\n",
    "seas_knn_unilabel_no_vacc_train_precision = precision_score(y_seas_vacc_train, knn_unilabel_no_vacc_trainpreds)\n",
    "seas_knn_unilabel_no_vacc_train_f1 = f1_score(y_seas_vacc_train, knn_unilabel_no_vacc_trainpreds)\n",
    "seas_knn_unilabel_no_vacc_train_roc = roc_auc_score(y_seas_vacc_train, knn_unilabel_no_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_train, knn_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_train, knn_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_train, knn_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_train, knn_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_train, knn_unilabel_no_vacc_trainpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Random Forest--Train data evaluation Metrics\n",
    "#check if these metrics are changing compared to previous results\n",
    "seas_rand_forst_unilabel_no_vacc_train_acc = accuracy_score(y_seas_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)\n",
    "seas_rand_forst_unilabel_no_vacc_train_recall = recall_score(y_seas_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)\n",
    "seas_rand_forst_unilabel_no_vacc_train_precision = precision_score(y_seas_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)\n",
    "seas_rand_forst_unilabel_no_vacc_train_f1 = f1_score(y_seas_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)\n",
    "seas_rand_forst_unilabel_no_vacc_train_roc = roc_auc_score(y_seas_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_train, rand_forst_unilabel_no_vacc_trainpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SVM--Train data evaluation Metrics\n",
    "seas_svm_unilabel_no_vacc_train_acc = accuracy_score(y_seas_vacc_train, svm_unilabel_no_vacc_trainpreds)\n",
    "seas_svm_unilabel_no_vacc_train_recall = recall_score(y_seas_vacc_train, svm_unilabel_no_vacc_trainpreds)\n",
    "seas_svm_unilabel_no_vacc_train_precision = precision_score(y_seas_vacc_train, svm_unilabel_no_vacc_trainpreds)\n",
    "seas_svm_unilabel_no_vacc_train_f1 = f1_score(y_seas_vacc_train, svm_unilabel_no_vacc_trainpreds)\n",
    "seas_svm_unilabel_no_vacc_train_roc = roc_auc_score(y_seas_vacc_train, svm_unilabel_no_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_train, svm_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_train, svm_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_train, svm_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_train, svm_unilabel_no_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_train, svm_unilabel_no_vacc_trainpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Test data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Logreg--Test data evaluation Metrics\n",
    "seas_logreg_unilabel_no_vacc_test_acc = accuracy_score(y_seas_vacc_test, logreg_unilabel_no_vacc_testpreds)\n",
    "seas_logreg_unilabel_no_vacc_test_recall = recall_score(y_seas_vacc_test, logreg_unilabel_no_vacc_testpreds)\n",
    "seas_logreg_unilabel_no_vacc_test_precision = precision_score(y_seas_vacc_test, logreg_unilabel_no_vacc_testpreds)\n",
    "seas_logreg_unilabel_no_vacc_test_f1 = f1_score(y_seas_vacc_test, logreg_unilabel_no_vacc_testpreds)\n",
    "seas_logreg_unilabel_no_vacc_test_roc = roc_auc_score(y_seas_vacc_test, logreg_unilabel_no_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_test, logreg_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_test, logreg_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_test, logreg_unilabel_no_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_test, logreg_unilabel_no_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_test, logreg_unilabel_no_vacc_testpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# KNN--Test data evaluation Metrics\n",
    "seas_knn_unilabel_no_vacc_test_acc = accuracy_score(y_seas_vacc_test, knn_unilabel_no_vacc_testpreds)\n",
    "seas_knn_unilabel_no_vacc_test_recall = recall_score(y_seas_vacc_test, knn_unilabel_no_vacc_testpreds)\n",
    "seas_knn_unilabel_no_vacc_test_precision = precision_score(y_seas_vacc_test, knn_unilabel_no_vacc_testpreds)\n",
    "seas_knn_unilabel_no_vacc_test_f1 = f1_score(y_seas_vacc_test, knn_unilabel_no_vacc_testpreds)\n",
    "seas_knn_unilabel_no_vacc_test_roc = roc_auc_score(y_seas_vacc_test, knn_unilabel_no_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_test, knn_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_test, knn_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_test, knn_unilabel_no_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_test, knn_unilabel_no_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_test, knn_unilabel_no_vacc_testpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Random Forest--Test data evaluation Metrics\n",
    "#check if these metrics are changing compared to previous results\n",
    "seas_rand_forst_unilabel_no_vacc_test_acc = accuracy_score(y_seas_vacc_test, rand_forst_unilabel_no_vacc_testpreds)\n",
    "seas_rand_forst_unilabel_no_vacc_test_recall = recall_score(y_seas_vacc_test, rand_forst_unilabel_no_vacc_testpreds)\n",
    "seas_rand_forst_unilabel_no_vacc_test_precision = precision_score(y_seas_vacc_test, rand_forst_unilabel_no_vacc_testpreds)\n",
    "seas_rand_forst_unilabel_no_vacc_test_f1 = f1_score(y_seas_vacc_test, rand_forst_unilabel_no_vacc_testpreds)\n",
    "seas_rand_forst_unilabel_no_vacc_test_roc = roc_auc_score(y_seas_vacc_test, rand_forst_unilabel_no_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_test, rand_forst_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_test, rand_forst_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_test, rand_forst_unilabel_no_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_test, rand_forst_unilabel_no_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_test, rand_forst_unilabel_no_vacc_testpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SVM--Test data evaluation Metrics\n",
    "seas_svm_unilabel_no_vacc_test_acc = accuracy_score(y_seas_vacc_test, svm_unilabel_no_vacc_testpreds)\n",
    "seas_svm_unilabel_no_vacc_test_recall = recall_score(y_seas_vacc_test, svm_unilabel_no_vacc_testpreds)\n",
    "seas_svm_unilabel_no_vacc_test_precision = precision_score(y_seas_vacc_test, svm_unilabel_no_vacc_testpreds)\n",
    "seas_svm_unilabel_no_vacc_test_f1 = f1_score(y_seas_vacc_test, svm_unilabel_no_vacc_testpreds)\n",
    "seas_svm_unilabel_no_vacc_test_roc = roc_auc_score(y_seas_vacc_test, svm_unilabel_no_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_test, svm_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_test, svm_unilabel_no_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_test, svm_unilabel_no_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_test, svm_unilabel_no_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_test, svm_unilabel_no_vacc_testpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tracking the model with MLFlow"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Seasonal vaccine output"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Logistic regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_seasonal) #this needs to be adjusted for each experiment\n",
    "name = 'logreg_unilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Drop all nulls\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seas_logreg_unilabel_no_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seas_logreg_unilabel_no_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seas_logreg_unilabel_no_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seas_logreg_unilabel_no_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seas_logreg_unilabel_no_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seas_logreg_unilabel_no_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seas_logreg_unilabel_no_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seas_logreg_unilabel_no_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seas_logreg_unilabel_no_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seas_logreg_unilabel_no_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### KNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_seasonal)\n",
    "name = 'knn_unilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Drop all nulls\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seas_knn_unilabel_no_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seas_knn_unilabel_no_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seas_knn_unilabel_no_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seas_knn_unilabel_no_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seas_knn_unilabel_no_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seas_knn_unilabel_no_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seas_knn_unilabel_no_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seas_knn_unilabel_no_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seas_knn_unilabel_no_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seas_knn_unilabel_no_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_seasonal)\n",
    "name = 'rand_forst_unilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Drop all nulls\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seas_rand_forst_unilabel_no_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seas_rand_forst_unilabel_no_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seas_rand_forst_unilabel_no_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seas_rand_forst_unilabel_no_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seas_rand_forst_unilabel_no_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seas_rand_forst_unilabel_no_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seas_rand_forst_unilabel_no_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seas_rand_forst_unilabel_no_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seas_rand_forst_unilabel_no_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seas_rand_forst_unilabel_no_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### SVM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_seasonal)\n",
    "name = 'svm_unilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Drop all nulls\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"None\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seas_svm_unilabel_no_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seas_svm_unilabel_no_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seas_svm_unilabel_no_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seas_svm_unilabel_no_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seas_svm_unilabel_no_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seas_svm_unilabel_no_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seas_svm_unilabel_no_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seas_svm_unilabel_no_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seas_svm_unilabel_no_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seas_svm_unilabel_no_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Single Label Modelling, output seasonal vaccine -> H1N1 Flu Vaccine is in features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The y_seas_vacc remains the same from the previous model; the X feature and cat_features (for the preprocessor) need to be adjusted:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cat_features_h1n1_vacc = cat_features.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cat_features_h1n1_vacc.remove('seasonal_vaccine')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#NB: dropping the 'h1n1_vaccine' and 'seasonal_vaccine' columns\n",
    "X_h1n1_vacc = df.drop(columns=['seasonal_vaccine'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Performing test-train split (the same data can be used for each model in multilabelling):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_h1n1_vacc_train, X_h1n1_vacc_test, y_seas_vacc_train, y_seas_vacc_test = train_test_split(X_h1n1_vacc, y_seas_vacc, stratify = y_seas_vacc, test_size=0.2, random_state=RSEED)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print('X_h1n1_vacc_train shape:', X_h1n1_vacc_train.shape)\n",
    "print('X_h1n1_vacc_test shape:', X_h1n1_vacc_test.shape)\n",
    "print('y_seas_vacc_train:', y_seas_vacc_train.shape)\n",
    "print('y_seas_vacc_test:', y_seas_vacc_test.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The pipeline stays the same as the model above"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training the models:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for logreg\n",
    "logreg_unilabel_h1n1_vacc = logreg_unilabel_pipeline.fit(X_h1n1_vacc_train, y_seas_vacc_train)\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_h1n1_vacc = knn_unilabel_pipeline.fit(X_h1n1_vacc_train, y_seas_vacc_train)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_unilabel_h1n1_vacc = rand_forst_unilabel_pipeline.fit(X_h1n1_vacc_train, y_seas_vacc_train)\n",
    "\n",
    "#for SVM\n",
    "svm_unilabel_h1n1_vacc = svm_unilabel_pipeline.fit(X_h1n1_vacc_train, y_seas_vacc_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Figure out later what this does and if we want to use it\n",
    "\n",
    "\n",
    "#y_train_predicted = cross_val_predict(full_pipeline, X_train, y_train, cv=5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Making predictions based on train and test data:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for logreg\n",
    "logreg_unilabel_h1n1_vacc_trainpreds = logreg_unilabel_h1n1_vacc.predict(X_h1n1_vacc_train)\n",
    "logreg_unilabel_h1n1_vacc_testpreds = logreg_unilabel_h1n1_vacc.predict(X_h1n1_vacc_test)\n",
    "\n",
    "# for KNN\n",
    "knn_unilabel_h1n1_vacc_trainpreds = knn_unilabel_h1n1_vacc.predict(X_h1n1_vacc_train)\n",
    "knn_unilabel_h1n1_vacc_testpreds = knn_unilabel_h1n1_vacc.predict(X_h1n1_vacc_test)\n",
    "\n",
    "# for Random Forest\n",
    "rand_forst_unilabel_h1n1_vacc_trainpreds = rand_forst_unilabel_h1n1_vacc.predict(X_h1n1_vacc_train)\n",
    "rand_forst_unilabel_h1n1_vacc_testpreds = rand_forst_unilabel_h1n1_vacc.predict(X_h1n1_vacc_test)\n",
    "\n",
    "# for SVM\n",
    "svm_unilabel_h1n1_vacc_trainpreds = svm_unilabel_h1n1_vacc.predict(X_h1n1_vacc_train)\n",
    "svm_unilabel_h1n1_vacc_testpreds = svm_unilabel_h1n1_vacc.predict(X_h1n1_vacc_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model evaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Logreg--Train data evaluation Metrics\n",
    "seas_logreg_unilabel_h1n1_vacc_train_acc = accuracy_score(y_seas_vacc_train, logreg_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_logreg_unilabel_h1n1_vacc_train_recall = recall_score(y_seas_vacc_train, logreg_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_logreg_unilabel_h1n1_vacc_train_precision = precision_score(y_seas_vacc_train, logreg_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_logreg_unilabel_h1n1_vacc_train_f1 = f1_score(y_seas_vacc_train, logreg_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_logreg_unilabel_h1n1_vacc_train_roc = roc_auc_score(y_seas_vacc_train, logreg_unilabel_h1n1_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_train, logreg_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_train, logreg_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_train, logreg_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_train, logreg_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_train, logreg_unilabel_h1n1_vacc_trainpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# KNN--Train data evaluation Metrics\n",
    "seas_knn_unilabel_h1n1_vacc_train_acc = accuracy_score(y_seas_vacc_train, knn_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_knn_unilabel_h1n1_vacc_train_recall = recall_score(y_seas_vacc_train, knn_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_knn_unilabel_h1n1_vacc_train_precision = precision_score(y_seas_vacc_train, knn_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_knn_unilabel_h1n1_vacc_train_f1 = f1_score(y_seas_vacc_train, knn_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_knn_unilabel_h1n1_vacc_train_roc = roc_auc_score(y_seas_vacc_train, knn_unilabel_h1n1_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_train, knn_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_train, knn_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_train, knn_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_train, knn_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_train, knn_unilabel_h1n1_vacc_trainpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Random Forest--Train data evaluation Metrics\n",
    "#check if these metrics are changing compared to previous results\n",
    "seas_rand_forst_unilabel_h1n1_vacc_train_acc = accuracy_score(y_seas_vacc_train, rand_forst_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_rand_forst_unilabel_h1n1_vacc_train_recall = recall_score(y_seas_vacc_train, rand_forst_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_rand_forst_unilabel_h1n1_vacc_train_precision = precision_score(y_seas_vacc_train, rand_forst_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_rand_forst_unilabel_h1n1_vacc_train_f1 = f1_score(y_seas_vacc_train, rand_forst_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_rand_forst_unilabel_h1n1_vacc_train_roc = roc_auc_score(y_seas_vacc_train, rand_forst_unilabel_h1n1_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_train, rand_forst_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_train, rand_forst_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_train, rand_forst_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_train, rand_forst_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_train, rand_forst_unilabel_h1n1_vacc_trainpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SVM--Train data evaluation Metrics\n",
    "seas_svm_unilabel_h1n1_vacc_train_acc = accuracy_score(y_seas_vacc_train, svm_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_svm_unilabel_h1n1_vacc_train_recall = recall_score(y_seas_vacc_train, svm_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_svm_unilabel_h1n1_vacc_train_precision = precision_score(y_seas_vacc_train, svm_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_svm_unilabel_h1n1_vacc_train_f1 = f1_score(y_seas_vacc_train, svm_unilabel_h1n1_vacc_trainpreds)\n",
    "seas_svm_unilabel_h1n1_vacc_train_roc = roc_auc_score(y_seas_vacc_train, svm_unilabel_h1n1_vacc_trainpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_train, svm_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_train, svm_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_train, svm_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_train, svm_unilabel_h1n1_vacc_trainpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_train, svm_unilabel_h1n1_vacc_trainpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Test data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Logreg--Test data evaluation Metrics\n",
    "seas_logreg_unilabel_h1n1_vacc_test_acc = accuracy_score(y_seas_vacc_test, logreg_unilabel_h1n1_vacc_testpreds)\n",
    "seas_logreg_unilabel_h1n1_vacc_test_recall = recall_score(y_seas_vacc_test, logreg_unilabel_h1n1_vacc_testpreds)\n",
    "seas_logreg_unilabel_h1n1_vacc_test_precision = precision_score(y_seas_vacc_test, logreg_unilabel_h1n1_vacc_testpreds)\n",
    "seas_logreg_unilabel_h1n1_vacc_test_f1 = f1_score(y_seas_vacc_test, logreg_unilabel_h1n1_vacc_testpreds)\n",
    "seas_logreg_unilabel_h1n1_vacc_test_roc = roc_auc_score(y_seas_vacc_test, logreg_unilabel_h1n1_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_test, logreg_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_test, logreg_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_test, logreg_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_test, logreg_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_test, logreg_unilabel_h1n1_vacc_testpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# KNN--Test data evaluation Metrics\n",
    "seas_knn_unilabel_h1n1_vacc_test_acc = accuracy_score(y_seas_vacc_test, knn_unilabel_h1n1_vacc_testpreds)\n",
    "seas_knn_unilabel_h1n1_vacc_test_recall = recall_score(y_seas_vacc_test, knn_unilabel_h1n1_vacc_testpreds)\n",
    "seas_knn_unilabel_h1n1_vacc_test_precision = precision_score(y_seas_vacc_test, knn_unilabel_h1n1_vacc_testpreds)\n",
    "seas_knn_unilabel_h1n1_vacc_test_f1 = f1_score(y_seas_vacc_test, knn_unilabel_h1n1_vacc_testpreds)\n",
    "seas_knn_unilabel_h1n1_vacc_test_roc = roc_auc_score(y_seas_vacc_test, knn_unilabel_h1n1_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_test, knn_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_test, knn_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_test, knn_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_test, knn_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_test, knn_unilabel_h1n1_vacc_testpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Random Forest--Test data evaluation Metrics\n",
    "#check if these metrics are changing compared to previous results\n",
    "seas_rand_forst_unilabel_h1n1_vacc_test_acc = accuracy_score(y_seas_vacc_test, rand_forst_unilabel_h1n1_vacc_testpreds)\n",
    "seas_rand_forst_unilabel_h1n1_vacc_test_recall = recall_score(y_seas_vacc_test, rand_forst_unilabel_h1n1_vacc_testpreds)\n",
    "seas_rand_forst_unilabel_h1n1_vacc_test_precision = precision_score(y_seas_vacc_test, rand_forst_unilabel_h1n1_vacc_testpreds)\n",
    "seas_rand_forst_unilabel_h1n1_vacc_test_f1 = f1_score(y_seas_vacc_test, rand_forst_unilabel_h1n1_vacc_testpreds)\n",
    "seas_rand_forst_unilabel_h1n1_vacc_test_roc = roc_auc_score(y_seas_vacc_test, rand_forst_unilabel_h1n1_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_test, rand_forst_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_test, rand_forst_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_test, rand_forst_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_test, rand_forst_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_test, rand_forst_unilabel_h1n1_vacc_testpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SVM--Test data evaluation Metrics\n",
    "seas_svm_unilabel_h1n1_vacc_test_acc = accuracy_score(y_seas_vacc_test, svm_unilabel_h1n1_vacc_testpreds)\n",
    "seas_svm_unilabel_h1n1_vacc_test_recall = recall_score(y_seas_vacc_test, svm_unilabel_h1n1_vacc_testpreds)\n",
    "seas_svm_unilabel_h1n1_vacc_test_precision = precision_score(y_seas_vacc_test, svm_unilabel_h1n1_vacc_testpreds)\n",
    "seas_svm_unilabel_h1n1_vacc_test_f1 = f1_score(y_seas_vacc_test, svm_unilabel_h1n1_vacc_testpreds)\n",
    "seas_svm_unilabel_h1n1_vacc_test_roc = roc_auc_score(y_seas_vacc_test, svm_unilabel_h1n1_vacc_testpreds)\n",
    "\n",
    "#print(\"Accuracy: {:.2f}\".format(accuracy_score(y_seas_vacc_test, svm_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"Recall: {:.2f}\".format(recall_score(y_seas_vacc_test, svm_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"Precision: {:.2f}\".format(precision_score(y_seas_vacc_test, svm_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"F1: {:.2f}\".format(f1_score(y_seas_vacc_test, svm_unilabel_h1n1_vacc_testpreds)))\n",
    "#print(\"ROC: {:.2f}\".format(roc_auc_score(y_seas_vacc_test, svm_unilabel_h1n1_vacc_testpreds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tracking the model with MLFlow"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### H1N1 vaccine output"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Logistic regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_seasonal) #this needs to be adjusted for each experiment\n",
    "name = 'logreg_unilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Drop all nulls\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"H1N1\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seas_logreg_unilabel_h1n1_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seas_logreg_unilabel_h1n1_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seas_logreg_unilabel_h1n1_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seas_logreg_unilabel_h1n1_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seas_logreg_unilabel_h1n1_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seas_logreg_unilabel_h1n1_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seas_logreg_unilabel_h1n1_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seas_logreg_unilabel_h1n1_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seas_logreg_unilabel_h1n1_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seas_logreg_unilabel_h1n1_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### KNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_seasonal)\n",
    "name = 'knn_unilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Drop all nulls\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"H1N1\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seas_knn_unilabel_h1n1_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seas_knn_unilabel_h1n1_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seas_knn_unilabel_h1n1_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seas_knn_unilabel_h1n1_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seas_knn_unilabel_h1n1_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seas_knn_unilabel_h1n1_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seas_knn_unilabel_h1n1_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seas_knn_unilabel_h1n1_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seas_knn_unilabel_h1n1_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seas_knn_unilabel_h1n1_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_seasonal)\n",
    "name = 'rand_forst_unilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Drop all nulls\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"H1N1\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seas_rand_forst_unilabel_h1n1_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seas_rand_forst_unilabel_h1n1_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seas_rand_forst_unilabel_h1n1_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seas_rand_forst_unilabel_h1n1_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seas_rand_forst_unilabel_h1n1_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seas_rand_forst_unilabel_h1n1_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seas_rand_forst_unilabel_h1n1_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seas_rand_forst_unilabel_h1n1_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seas_rand_forst_unilabel_h1n1_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seas_rand_forst_unilabel_h1n1_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### SVM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_seasonal)\n",
    "name = 'svm_unilabel_seasonal' #specify the run name here; name it with model used\n",
    "mlflow.start_run(run_name = name) \n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#parameters are to keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model, etc)\n",
    "#to be adjusted as needed\n",
    "params = {\n",
    "    \"Data cleaning\": \"Drop all nulls\",\n",
    "    \"Data balancing\": \"None\",\n",
    "    \"Hyperparameters\": \"None\"\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "#tags = data used\n",
    "mlflow.set_tag(\"Vaccines in features\", \"H1N1\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", seas_svm_unilabel_h1n1_vacc_train_roc)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", seas_svm_unilabel_h1n1_vacc_test_roc)\n",
    "mlflow.log_metric(\"train -\" + \"accuracy\", seas_svm_unilabel_h1n1_vacc_train_acc)\n",
    "mlflow.log_metric(\"test -\" + \"accuracy\", seas_svm_unilabel_h1n1_vacc_test_acc)\n",
    "mlflow.log_metric(\"train -\" + \"recall\", seas_svm_unilabel_h1n1_vacc_train_recall)\n",
    "mlflow.log_metric(\"test -\" + \"recall\", seas_svm_unilabel_h1n1_vacc_test_recall)\n",
    "mlflow.log_metric(\"train -\" + \"precision\", seas_svm_unilabel_h1n1_vacc_train_precision)\n",
    "mlflow.log_metric(\"test -\" + \"precision\", seas_svm_unilabel_h1n1_vacc_test_precision)\n",
    "mlflow.log_metric(\"train -\" + \"f1\", seas_svm_unilabel_h1n1_vacc_train_f1)\n",
    "mlflow.log_metric(\"test -\" + \"f1\", seas_svm_unilabel_h1n1_vacc_test_f1)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# THE CODE BELOW HAS NOT BEEN REVIEWED!\n",
    "***\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Single Label Modelling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# pipeline for the single label\n",
    "\n",
    "full_pipeline_1 = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", LogisticRegression()),\n",
    "    \n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predicting h1n1_vaccine  with Seasonal Flu Vaccine not in features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y = df['h1n1_vaccine'].copy() # for h1n1_vaccine only"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y = y.to_numpy()\n",
    "y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#NB: the H1N1 vaccine and seasonal vaccine are left in, otherwise the pipeline doesn't run properly\n",
    "#X = df\n",
    "\n",
    "#NB: dropping the 'h1n1_vaccine' and 'seasonal_vaccine' columns\n",
    "#X = df.drop(columns=['seasonal_vaccine'])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size=0.2, random_state=RSEED) # split for h1n1_vaccine"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "full_pipeline_1.fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "preds = full_pipeline_1.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluation Metrices for H1N1 Vaccines\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_test, preds)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_test, preds)))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_test, preds)))\n",
    "print(\"F1: {:.2f}\".format(f1_score(y_test, preds)))\n",
    "print(\"ROC: {:.2f}\".format(roc_auc_score(y_test, preds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predicting Seasonal Flu Vaccine with h1n1_vaccine not in features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y = df['seasonal_vaccine'].copy() # for seasonal_vaccine only"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y = y.to_numpy()\n",
    "y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size=0.2, random_state=RSEED) # split for seasonal_vaccine"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "full_pipeline_1.fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "preds = full_pipeline_1.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluation Metrices for H1N1 Vaccines\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_test, preds)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_test, preds)))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_test, preds)))\n",
    "print(\"F1: {:.2f}\".format(f1_score(y_test, preds)))\n",
    "print(\"ROC: {:.2f}\".format(roc_auc_score(y_test, preds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predicting Seasonal Flu Vaccine with h1n1_vaccine in features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cat_features_new = list(df.columns)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cat_features_new.remove('seasonal_vaccine')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#NB: dropping the 'h1n1_vaccine' and 'seasonal_vaccine' columns\n",
    "X = df.drop(columns=['seasonal_vaccine'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y = df['seasonal_vaccine'].copy()\n",
    "y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y = y.to_numpy()\n",
    "y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', cat_pipeline, cat_features_new)\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "full_pipeline_1 = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", LogisticRegression()),\n",
    "    \n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size=0.2, random_state=RSEED) # split for Seasonal_vaccine"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "full_pipeline_1.fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "preds = full_pipeline_1.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluation Metrices for Seasonal Vaccines\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_test, preds)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_test, preds)))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_test, preds)))\n",
    "print(\"F1: {:.2f}\".format(f1_score(y_test, preds)))\n",
    "print(\"ROC: {:.2f}\".format(roc_auc_score(y_test, preds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predicting h1n1_vaccine with Seasonal Flu Vaccine  in features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cat_features_new = list(df.columns)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cat_features_new.remove('h1n1_vaccine')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#NB: dropping the 'h1n1_vaccine' and 'seasonal_vaccine' columns\n",
    "X = df.drop(columns=['h1n1_vaccine'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y = df['h1n1_vaccine'].copy()\n",
    "y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', cat_pipeline, cat_features_new)\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "full_pipeline_1 = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", LogisticRegression()),\n",
    "    \n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size=0.2, random_state=RSEED) # split for H1N1_vaccine"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "full_pipeline_1.fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "preds = full_pipeline_1.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluation Metrices for H1N1 Vaccines\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_test, preds)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_test, preds)))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_test, preds)))\n",
    "print(\"F1: {:.2f}\".format(f1_score(y_test, preds)))\n",
    "print(\"ROC: {:.2f}\".format(roc_auc_score(y_test, preds)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modelling Algorithms"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In addition to Logistic regression, we are trying four different models to compare performance in terms of predicting the Vaccine Intake:\n",
    "\n",
    "- K nearest neighbours\n",
    "- Random Forest\n",
    "- Support Vector Machine\n",
    "- Naive Bayes"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instantiate the models:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "knn_model = KNeighborsClassifier()\n",
    "rand_forst_model = RandomForestClassifier()\n",
    "svm_model = svm.SVC(kernel='rbf') \n",
    "#svm_model = svm.SVC(kernel='linear', C=1E10) \n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create Pipeline for each:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for KNN\n",
    "estimators_knn= MultiOutputClassifier(\n",
    "    estimator=knn_model\n",
    ")\n",
    "\n",
    "# for Random Forest\n",
    "estimators_rand_forst= MultiOutputClassifier(\n",
    "    estimator=rand_forst_model\n",
    ")\n",
    "\n",
    "\n",
    "# for SVM\n",
    "\n",
    "estimators_SVC= MultiOutputClassifier(\n",
    "    estimator=svm_model\n",
    ")\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cat_features = list(df.columns)\n",
    "cat_features.remove('h1n1_vaccine')\n",
    "cat_features.remove('seasonal_vaccine')\n",
    "#cat_features"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', cat_pipeline, cat_features)\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for KNN\n",
    "full_pipeline_knn = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", estimators_knn),\n",
    "])\n",
    "\n",
    "# for Random Forest\n",
    "\n",
    "full_pipeline_rand_forst= Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", estimators_rand_forst),\n",
    "])\n",
    "\n",
    "#for SVM\n",
    "\n",
    "full_pipeline_SVM= Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", estimators_SVC),\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y = df[['h1n1_vaccine', 'seasonal_vaccine']].copy()\n",
    "y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y = y.to_numpy()\n",
    "y\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#NB: dropping the 'h1n1_vaccine' and 'seasonal_vaccine' columns\n",
    "X = df.drop(columns=['h1n1_vaccine', 'seasonal_vaccine'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size=0.2, random_state=RSEED)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fit the data:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "full_pipeline_SVM.fit(X_train, y_train)\n",
    "full_pipeline_knn.fit(X_train, y_train)\n",
    "full_pipeline_rand_forst.fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get predictions:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#KNN\n",
    "knn_train_pred = full_pipeline_knn.predict(X_train)\n",
    "knn_test_pred = full_pipeline_knn.predict(X_test)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Random forest\n",
    "\n",
    "rand_forst_train_pred = full_pipeline_rand_forst.predict(X_train)\n",
    "rand_forst_test_pred = full_pipeline_rand_forst.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#SVM\n",
    "svm_train_pred = full_pipeline_SVM.predict(X_train)\n",
    "svm_test_pred = full_pipeline_SVM.predict(X_test)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluating model performance for Multilabel"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "KNN:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluation Metrices for H1N1 Vaccines\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_test[:, 0], knn_test_pred[:, 0])))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_test[:, 0], knn_test_pred[:, 0])))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_test[:, 0], knn_test_pred[:, 0])))\n",
    "print(\"F1: {:.2f}\".format(f1_score(y_test[:, 0], knn_test_pred[:, 0])))\n",
    "print(\"ROC: {:.2f}\".format(roc_auc_score(y_test[:, 0], knn_test_pred[:, 0])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluation Metrices for Seasonal Flu Vaccines\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_test[:, 1], knn_test_pred[:, 1])))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_test[:, 1], knn_test_pred[:, 1])))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_test[:, 1], knn_test_pred[:, 1])))\n",
    "print(\"F1: {:.2f}\".format(f1_score(y_test[:, 1], knn_test_pred[:, 1])))\n",
    "print(\"ROC: {:.2f}\".format(roc_auc_score(y_test[:, 1], knn_test_pred[:, 1])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Random Forest:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluation Metrices for H1N1 Vaccines\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_test[:, 0], rand_forst_test_pred[:, 0])))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_test[:, 0], rand_forst_test_pred[:, 0])))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_test[:, 0], rand_forst_test_pred[:, 0])))\n",
    "print(\"F1: {:.2f}\".format(f1_score(y_test[:, 0], rand_forst_test_pred[:, 0])))\n",
    "print(\"ROC: {:.2f}\".format(roc_auc_score(y_test[:, 0], rand_forst_test_pred[:, 0])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluation Metrices for Seasonal Flu Vaccines\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_test[:, 1], rand_forst_test_pred[:, 1])))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_test[:, 1], rand_forst_test_pred[:, 1])))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_test[:, 1], rand_forst_test_pred[:, 1])))\n",
    "print(\"F1: {:.2f}\".format(f1_score(y_test[:, 1], rand_forst_test_pred[:, 1])))\n",
    "print(\"ROC: {:.2f}\".format(roc_auc_score(y_test[:, 1], rand_forst_test_pred[:, 1])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Support Vector Machine:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluation Metrices for H1N1 Vaccines\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_test[:, 0], svm_test_pred[:, 0])))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_test[:, 0], svm_test_pred[:, 0])))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_test[:, 0], svm_test_pred[:, 0])))\n",
    "print(\"F1: {:.2f}\".format(f1_score(y_test[:, 0], svm_test_pred[:, 0])))\n",
    "print(\"ROC: {:.2f}\".format(roc_auc_score(y_test[:, 0], svm_test_pred[:, 0])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluation Metrices for Seasonal Flu Vaccines\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_test[:, 1], svm_test_pred[:, 1])))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_test[:, 1], svm_test_pred[:, 1])))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_test[:, 1], svm_test_pred[:, 1])))\n",
    "print(\"F1: {:.2f}\".format(f1_score(y_test[:, 1], svm_test_pred[:, 1])))\n",
    "print(\"ROC: {:.2f}\".format(roc_auc_score(y_test[:, 1], svm_test_pred[:, 1])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Single Label Modelling of the four other algorithms"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predicting h1n1_vaccine  with Seasonal Flu Vaccine not in features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y = df['h1n1_vaccine'].copy() # for h1n1_vaccine only\n",
    "y = y.to_numpy()\n",
    "y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size=0.2, random_state=RSEED) # split for h1n1_vaccine"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Pipeline for the single label"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for KNN\n",
    "full_pipeline_knn = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", knn_model),\n",
    "])\n",
    "\n",
    "# for Random Forest\n",
    "\n",
    "full_pipeline_rand_forst= Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", rand_forst_model),\n",
    "    ])\n",
    "\n",
    "# for SVM\n",
    "\n",
    "full_pipeline_svm= Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", svm_model),\n",
    "    ]) \n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "full_pipeline_svm.fit(X_train, y_train)\n",
    "full_pipeline_knn.fit(X_train, y_train)\n",
    "full_pipeline_rand_forst.fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#KNN\n",
    "knn_train_pred = full_pipeline_knn.predict(X_train)\n",
    "knn_test_pred = full_pipeline_knn.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Random forest\n",
    "\n",
    "rand_forst_train_pred = full_pipeline_rand_forst.predict(X_train)\n",
    "rand_forst_test_pred = full_pipeline_rand_forst.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#SVM\n",
    "\n",
    "SVM_train_pred = full_pipeline_svm.predict(X_train)\n",
    "SVM_forst_test_pred = full_pipeline_svm.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluating model performance for Multilabel"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "KNN:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluation Metrices for H1N1 Vaccines\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_test, knn_test_pred)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_test, knn_test_pred)))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_test, knn_test_pred)))\n",
    "print(\"F1: {:.2f}\".format(f1_score(y_test, knn_test_pred)))\n",
    "print(\"ROC: {:.2f}\".format(roc_auc_score(y_test, knn_test_pred)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Random Forest:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluation Metrices for H1N1 Vaccines\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_test, rand_forst_test_pred)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_test, rand_forst_test_pred)))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_test, rand_forst_test_pred)))\n",
    "print(\"F1: {:.2f}\".format(f1_score(y_test, rand_forst_test_pred)))\n",
    "print(\"ROC: {:.2f}\".format(roc_auc_score(y_test, rand_forst_test_pred)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "SVM:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluation Metrices for H1N1 Vaccines\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_test, SVM_forst_test_pred)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_test, SVM_forst_test_pred)))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_test, SVM_forst_test_pred)))\n",
    "print(\"F1: {:.2f}\".format(f1_score(y_test, SVM_forst_test_pred)))\n",
    "print(\"ROC: {:.2f}\".format(roc_auc_score(y_test, SVM_forst_test_pred)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predicting Seasonal Flu Vaccine with h1n1_vaccine not in features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y = df['seasonal_vaccine'].copy() # seasonal_vaccine only\n",
    "y = y.to_numpy()\n",
    "y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size=0.2, random_state=RSEED) # split for seasonal_vaccine"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fitting Pipeline for the single label "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "full_pipeline_svm.fit(X_train, y_train)\n",
    "full_pipeline_knn.fit(X_train, y_train)\n",
    "full_pipeline_rand_forst.fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#KNN\n",
    "knn_train_pred = full_pipeline_knn.predict(X_train)\n",
    "knn_test_pred = full_pipeline_knn.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Random forest\n",
    "\n",
    "rand_forst_train_pred = full_pipeline_rand_forst.predict(X_train)\n",
    "rand_forst_test_pred = full_pipeline_rand_forst.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "SVM:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#SVM\n",
    "SVM_train_pred = full_pipeline_svm.predict(X_train)\n",
    "SVM_forst_test_pred = full_pipeline_svm.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "KNN:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluation Metrices for H1N1 Vaccines\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_test, knn_test_pred)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_test, knn_test_pred)))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_test, knn_test_pred)))\n",
    "print(\"F1: {:.2f}\".format(f1_score(y_test, knn_test_pred)))\n",
    "print(\"ROC: {:.2f}\".format(roc_auc_score(y_test, knn_test_pred)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Random Forest:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluation Metrices for H1N1 Vaccines\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_test, rand_forst_test_pred)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_test, rand_forst_test_pred)))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_test, rand_forst_test_pred)))\n",
    "print(\"F1: {:.2f}\".format(f1_score(y_test, rand_forst_test_pred)))\n",
    "print(\"ROC: {:.2f}\".format(roc_auc_score(y_test, rand_forst_test_pred)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "SVM:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluation Metrices for H1N1 Vaccines\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_test, SVM_forst_test_pred)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_test, SVM_forst_test_pred)))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_test, SVM_forst_test_pred)))\n",
    "print(\"F1: {:.2f}\".format(f1_score(y_test, SVM_forst_test_pred)))\n",
    "print(\"ROC: {:.2f}\".format(roc_auc_score(y_test, SVM_forst_test_pred)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predicting h1n1_vaccine with Seasonal Flu Vaccine  in features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y = df['h1n1_vaccine'].copy() # for h1n1_vaccine only\n",
    "y = y.to_numpy()\n",
    "y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cat_features = list(df.columns)\n",
    "cat_features.remove('h1n1_vaccine')\n",
    "\n",
    "#cat_features"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#NB: dropping the 'h1n1_vaccine' column\n",
    "X = df.drop(columns=['h1n1_vaccine'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size=0.2, random_state=RSEED)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', cat_pipeline, cat_features)\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for KNN\n",
    "full_pipeline_knn = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", knn_model),\n",
    "])\n",
    "\n",
    "# for Random Forest\n",
    "\n",
    "full_pipeline_rand_forst= Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", rand_forst_model),\n",
    "    ])\n",
    "\n",
    "    # for SVM\n",
    "\n",
    "full_pipeline_svm= Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", svm_model),\n",
    "    ]) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "full_pipeline_svm.fit(X_train, y_train)\n",
    "full_pipeline_knn.fit(X_train, y_train)\n",
    "full_pipeline_rand_forst.fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#KNN\n",
    "knn_train_pred = full_pipeline_knn.predict(X_train)\n",
    "knn_test_pred = full_pipeline_knn.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Random forest\n",
    "\n",
    "rand_forst_train_pred = full_pipeline_rand_forst.predict(X_train)\n",
    "rand_forst_test_pred = full_pipeline_rand_forst.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#SVM\n",
    "\n",
    "SVM_train_pred = full_pipeline_svm.predict(X_train)\n",
    "SVM_test_pred = full_pipeline_svm.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "KNN:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluation Metrices for H1N1 Vaccines\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_test, knn_test_pred)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_test, knn_test_pred)))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_test, knn_test_pred)))\n",
    "print(\"F1: {:.2f}\".format(f1_score(y_test, knn_test_pred)))\n",
    "print(\"ROC: {:.2f}\".format(roc_auc_score(y_test, knn_test_pred)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Random Forest:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluation Metrices for H1N1 Vaccines\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_test, rand_forst_test_pred)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_test, rand_forst_test_pred)))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_test, rand_forst_test_pred)))\n",
    "print(\"F1: {:.2f}\".format(f1_score(y_test, rand_forst_test_pred)))\n",
    "print(\"ROC: {:.2f}\".format(roc_auc_score(y_test, rand_forst_test_pred)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "SVM:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluation Metrices for H1N1 Vaccines\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_test, SVM_test_pred)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_test, SVM_test_pred)))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_test, SVM_test_pred)))\n",
    "print(\"F1: {:.2f}\".format(f1_score(y_test, SVM_test_pred)))\n",
    "print(\"ROC: {:.2f}\".format(roc_auc_score(y_test, SVM_test_pred)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predicting Seasonal Flu Vaccine with h1n1_vaccine in features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y = df['seasonal_vaccine'].copy() # seasonal_vaccine only\n",
    "y = y.to_numpy()\n",
    "y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cat_features = list(df.columns)\n",
    "\n",
    "cat_features.remove('seasonal_vaccine')\n",
    "#cat_features"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#NB: dropping the 'seasonal_vaccine' column\n",
    "X = df.drop(columns=['seasonal_vaccine'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size=0.2, random_state=RSEED)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', cat_pipeline, cat_features)\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for KNN\n",
    "full_pipeline_knn = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", knn_model),\n",
    "])\n",
    "\n",
    "# for Random Forest\n",
    "\n",
    "full_pipeline_rand_forst= Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", rand_forst_model),\n",
    "    ])\n",
    "\n",
    "#SVM\n",
    "\n",
    "full_pipeline_svm= Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"estimators\", svm_model),\n",
    "    ]) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "full_pipeline_svm.fit(X_train, y_train)\n",
    "full_pipeline_knn.fit(X_train, y_train)\n",
    "full_pipeline_rand_forst.fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#KNN\n",
    "knn_train_pred = full_pipeline_knn.predict(X_train)\n",
    "knn_test_pred = full_pipeline_knn.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Random forest\n",
    "\n",
    "rand_forst_train_pred = full_pipeline_rand_forst.predict(X_train)\n",
    "rand_forst_test_pred = full_pipeline_rand_forst.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#SVM\n",
    "\n",
    "SVM_train_pred = full_pipeline_svm.predict(X_train)\n",
    "SVM_test_pred = full_pipeline_svm.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#full_pipeline_knn.fit(X_train, y_train)\n",
    "#full_pipeline_rand_forst.fit(X_train, y_train)\n",
    "#svm_model.fit(X_train, y_train)\n",
    "#model_pipeline.fit(train.data, train.target)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "KNN:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluation Metrices for H1N1 Vaccines\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_test, knn_test_pred)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_test, knn_test_pred)))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_test, knn_test_pred)))\n",
    "print(\"F1: {:.2f}\".format(f1_score(y_test, knn_test_pred)))\n",
    "print(\"ROC: {:.2f}\".format(roc_auc_score(y_test, knn_test_pred)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Random Forest:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluation Metrices for H1N1 Vaccines\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_test, rand_forst_test_pred)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_test, rand_forst_test_pred)))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_test, rand_forst_test_pred)))\n",
    "print(\"F1: {:.2f}\".format(f1_score(y_test, rand_forst_test_pred)))\n",
    "print(\"ROC: {:.2f}\".format(roc_auc_score(y_test, rand_forst_test_pred)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "SVM:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluation Metrices for H1N1 Vaccines\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_test, SVM_test_pred)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_test, SVM_test_pred)))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_test, SVM_test_pred)))\n",
    "print(\"F1: {:.2f}\".format(f1_score(y_test, SVM_test_pred)))\n",
    "print(\"ROC: {:.2f}\".format(roc_auc_score(y_test, SVM_test_pred)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dummy classifier predicts everything to belong to the same class and thus has no discriminatory ability (between negative and positive class). Therefore, the AUC of 0.5 is expected."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Trainining the model and tracking with MLFlow"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting the MLFlow connection and experiment\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME_multiclass)\n",
    "mlflow.start_run()\n",
    "run = mlflow.active_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Active run_id: {}\".format(run.info.run_id))"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#training the model\n",
    "reg = full_pipeline.fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_train_pred = reg.predict(X_train)\n",
    "#mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "roc_train = roc_auc_score(y_train[:, 0], y_train_pred[:, 0])\n",
    "print(roc_train) #why does the ROC not match previous results that we had? Should be 0.71"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#data cleaning and engineering--not done\n",
    "#dropping Quakers column and unnamed\n",
    "#changing one of the altitude to log and droping the original\n",
    "'''X_test[\"altitude_mean_log\"] = np.log(X_test[\"altitude_mean_meters\"])\n",
    "X_test.drop(['altitude_mean_meters'], axis=1, inplace=True)\n",
    "X_test.drop(['Quakers'], axis=1, inplace=True)\n",
    "X_test.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "# fillna with mean.. \n",
    "X_test[\"altitude_low_meters\"] = X_test[\"altitude_low_meters\"].fillna(altitude_low_meters_mean)\n",
    "X_test[\"altitude_high_meters\"] = X_test[\"altitude_high_meters\"].fillna(altitude_high_meters_mean)\n",
    "X_test[\"altitude_mean_log\"] = X_test[\"altitude_mean_log\"].fillna(altitude_mean_log_mean)'''"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_test_pred = reg.predict(X_test)\n",
    "roc_test = roc_auc_score(y_test[:, 0], y_test_pred[:, 0])\n",
    "print(roc_test) #looks correct"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#keep track of everything for re-running the experiment (e.g. what features are being engineered, hyperparameters of model)\n",
    "params = {\n",
    "\n",
    "  }"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.log_params(params)\n",
    "mlflow.set_tag(\"running_from_jupyter\", \"True\") #set tags for more details of what we've done\n",
    "mlflow.log_metric(\"train -\" + \"ROC\", roc_train)\n",
    "mlflow.log_metric(\"test -\" + \"ROC\", roc_test)\n",
    "#mlflow.log_artifact(\"../models\")\n",
    "#mlflow.sklearn.log_model(reg, \"model\")\n",
    "mlflow.end_run()"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mlflow.get_run(run_id=run.info.run_id)"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Checking the experiments\n",
    "\n",
    "while the next cell is running you will not be able to run other cells in the notebook"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#use if running locally\n",
    "#!mlflow ui"
   ],
   "outputs": [],
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bdc0c931d2d4c1e254c9b407be81fb640f6c2f032b4d6ab78d09bb2272bcd9af"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('.venv')"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}